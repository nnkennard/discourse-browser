[{"rels": [[5, 33, 0, 5, "attribution"], [5, 12, 12, 33, "elaboration"], [12, 24, 24, 33, "comparison"], [0, 33, 33, 162, "elaboration"], [33, 44, 44, 162, "elaboration"], [44, 47, 47, 70, "purpose"], [47, 52, 52, 70, "list"], [52, 70, 47, 52, "list"], [52, 58, 58, 70, "purpose"], [44, 70, 70, 162, "elaboration"], [70, 96, 96, 162, "list"], [70, 74, 74, 78, "elaboration"], [70, 78, 78, 96, "elaboration"], [96, 162, 70, 96, "list"], [96, 105, 105, 113, "elaboration"], [107, 113, 105, 107, "attribution"], [96, 113, 113, 162, "elaboration"], [113, 127, 127, 162, "same_unit"], [113, 119, 119, 127, "elaboration"], [127, 162, 113, 127, "same_unit"], [127, 128, 128, 162, "elaboration"], [128, 139, 139, 162, "elaboration"], [139, 141, 141, 157, "elaboration"], [139, 157, 157, 162, "elaboration"]], "tokens": ["It", "has", "already", "been", "noted", "that", "GraphSAGE", "models", "can", "achieve", "superior", "results", "-LRB-", "20-30", "%", "improvement", "-RRB-", "with", "a", "different", "hyperparameter", "setting", "on", "PPI", "than", "what", "was", "reported", "in", "the", "original", "paper", ".", "It", "is", "even", "mentioned", "in", "the", "Arxiv", "version", "of", "GraphSAGE", ".", "It", "is", "unfair", "to", "report", "such", "low", "scores", "and", "I", "also", "encourage", "the", "authors", "to", "update", "DGI", "'s", "hyperparam", "setting", "correspondingly", "and", "report", "newer", "numbers", ".", "Hello", ",", "Thank", "you", "for", "your", "comment", "!", "All", "reported", "improvements", "in", "PPI", "results", "concern", "solely", "the", "fully", "supervised", "setup", ";", "not", "the", "unsupervised", "one", ".", "And", ",", "indeed", ",", "this", "is", "the", "supervised", "result", "we", "report", "--", "namely", ",", "the", "avg", ".", "pooling", "architecture", "from", "the", "GaAN", "paper", "-LRB-", "Zhang", "et", "al.", ",", "UAI", "2018", "-RRB-", ",", "which", "we", "report", ",", "is", "one", "example", "of", "a", "supervised", "result", "that", "substantially", "-LRB-", "30", "+", "%", "-RRB-", "improves", "on", "the", "supervised", "result", "reported", "in", "the", "original", "GraphSAGE", "paper", "-LRB-", "of", "0.612", "-RRB-", "."], "comment_id": "B1eoGoSQpX"}, {"rels": [[0, 12, 12, 18, "elaboration"], [0, 18, 18, 594, "elaboration"], [18, 22, 22, 32, "list"], [22, 32, 18, 22, "list"], [18, 32, 32, 594, "elaboration"], [32, 38, 38, 41, "purpose"], [32, 41, 41, 594, "elaboration"], [41, 51, 51, 75, "elaboration"], [52, 75, 51, 52, "attribution"], [52, 55, 55, 75, "circumstance"], [55, 67, 67, 75, "elaboration"], [41, 75, 75, 594, "elaboration"], [75, 96, 96, 594, "list"], [96, 594, 75, 96, "list"], [96, 100, 100, 594, "elaboration"], [100, 102, 102, 594, "elaboration"], [102, 114, 114, 594, "list"], [114, 594, 102, 114, "list"], [114, 264, 264, 594, "list"], [114, 116, 116, 264, "list"], [116, 264, 114, 116, "list"], [116, 127, 127, 264, "list"], [127, 264, 116, 127, "list"], [127, 139, 139, 148, "elaboration"], [127, 148, 148, 151, "elaboration"], [127, 151, 151, 264, "elaboration"], [151, 153, 153, 264, "elaboration"], [153, 156, 156, 157, "elaboration"], [153, 157, 157, 264, "elaboration"], [157, 160, 160, 264, "elaboration"], [160, 172, 172, 264, "elaboration"], [172, 181, 181, 264, "elaboration"], [181, 195, 195, 207, "elaboration"], [181, 207, 207, 221, "elaboration"], [207, 216, 216, 221, "elaboration"], [181, 221, 221, 264, "elaboration"], [221, 234, 234, 252, "elaboration"], [221, 252, 252, 264, "elaboration"], [252, 261, 261, 264, "circumstance"], [264, 594, 114, 264, "list"], [264, 266, 266, 594, "elaboration"], [266, 278, 278, 594, "list"], [278, 594, 266, 278, "list"], [278, 279, 279, 280, "elaboration"], [278, 280, 280, 290, "elaboration"], [280, 284, 284, 290, "elaboration"], [278, 290, 290, 594, "elaboration"], [290, 294, 294, 307, "purpose"], [294, 299, 299, 307, "elaboration"], [290, 307, 307, 594, "elaboration"], [309, 319, 307, 309, "attribution"], [307, 319, 319, 594, "elaboration"], [319, 341, 341, 594, "elaboration"], [341, 480, 480, 594, "list"], [341, 343, 343, 480, "list"], [343, 480, 341, 343, "list"], [343, 354, 354, 480, "list"], [354, 480, 343, 354, "list"], [354, 355, 355, 370, "elaboration"], [354, 370, 370, 480, "elaboration"], [376, 406, 370, 376, "attribution"], [376, 385, 385, 406, "elaboration"], [385, 395, 395, 406, "same_unit"], [385, 386, 386, 395, "elaboration"], [395, 406, 385, 395, "same_unit"], [395, 398, 398, 406, "elaboration"], [370, 406, 406, 480, "elaboration"], [408, 419, 406, 408, "attribution"], [406, 419, 419, 480, "elaboration"], [431, 469, 419, 431, "attribution"], [419, 430, 430, 431, "same_unit"], [419, 425, 425, 430, "elaboration"], [430, 431, 419, 430, "same_unit"], [431, 440, 440, 469, "concession"], [440, 459, 459, 469, "elaboration"], [419, 469, 469, 480, "elaboration"], [480, 594, 341, 480, "list"], [480, 482, 482, 594, "elaboration"], [482, 492, 492, 501, "elaboration"], [482, 501, 501, 504, "elaboration"], [482, 504, 504, 506, "elaboration"], [482, 506, 506, 594, "elaboration"], [506, 509, 509, 510, "elaboration"], [506, 510, 510, 594, "elaboration"], [510, 525, 525, 594, "list"], [510, 513, 513, 525, "elaboration"], [525, 594, 510, 525, "list"], [525, 527, 527, 539, "elaboration"], [527, 531, 531, 539, "elaboration"], [525, 539, 539, 549, "elaboration"], [525, 549, 549, 594, "elaboration"], [549, 556, 556, 594, "elaboration"], [556, 564, 564, 594, "elaboration"], [569, 575, 564, 569, "attribution"], [564, 575, 575, 594, "elaboration"], [575, 583, 583, 594, "list"], [583, 594, 575, 583, "list"]], "tokens": ["This", "paper", "analyzed", "the", "global", "convergence", "property", "of", "SGD", "in", "deep", "learning", "based", "on", "the", "star-convexity", "assumption", ".", "The", "claims", "seem", "correct", "and", "validated", "empirically", "with", "some", "observations", "in", "deep", "learning", ".", "The", "writing", "is", "good", "and", "easy", "to", "follow", ".", "My", "understanding", "of", "the", "analysis", "is", "that", "all", "the", "claims", "seem", "to", "be", "valid", "when", "the", "solution", "is", "in", "a", "wide", "valley", "of", "the", "loss", "surface", "where", "the", "star-convexity", "holds", ",", "in", "general", ".", "This", "has", "been", "observed", "empirically", "in", "previous", "work", ",", "and", "the", "experiments", "on", "cifar10", "in", "Fig.", "2", "support", "my", "hypothesis", ".", "My", "questions", "are", ":", "1", ".", "How", "to", "guarantee", "the", "star-convexity", "will", "be", "valid", "in", "deep", "learning", "?", "2", ".", "What", "network", "or", "data", "properties", "can", "lead", "to", "such", "assumption", "?", "Also", ",", "this", "is", "a", "missing", "related", "work", "from", "the", "algorithmic", "perspective", "to", "explore", "the", "global", "optimization", "in", "deep", "learning", ":", "Zhang", "et", ".", "al.", ".", "CVPR", "'", "18", ".", "TICKTICK", "BPGrad", ":", "Towards", "Global", "Optimality", "in", "Deep", "Learning", "via", "Branch", "and", "Pruning", "''", ".", "We", "thank", "the", "reviewer", "for", "the", "valuable", "feedbacks", ".", "This", "paper", "aims", "at", "reporting", "an", "interesting", "star-convex", "property", "of", "the", "SGD", "optimization", "path", "that", "has", "been", "observed", "in", "training", "a", "variety", "of", "DL", "models", ",", "including", "MLP", ",", "CNN", ",", "residual", "networks", "and", "RNN", "-LRB-", "verified", "recently", "-RRB-", ".", "Moreover", ",", "our", "theory", "is", "motivated", "by", "such", "a", "common", "observation", "and", "attempts", "to", "justify", "the", "role", "of", "this", "property", "plays", "in", "determining", "the", "convergence", "of", "the", "optimization", "in", "DL", ".", "Our", "response", "to", "the", "reviewer", "'s", "comments", "are", "provided", "as", "follows", ".", "1", ".", "How", "to", "guarantee", "the", "star-convexity", "will", "be", "valid", "in", "deep", "learning", "?", "Response", ":", "We", "thank", "the", "reviewer", "for", "pointing", "out", "this", "question", ".", "It", "is", "definitely", "interesting", "to", "explore", "the", "underlying", "mechanism", "that", "leads", "to", "such", "a", "common", "observation", ".", "We", "think", "that", "over-parameterization", "can", "be", "one", "of", "the", "important", "factors", ".", "We", "are", "currently", "investigating", "this", "issue", "theoretically", "on", "some", "simple", "networks", ",", "and", "our", "understanding", "so", "far", "favors", "such", "a", "direction", ".", "2", ".", "What", "network", "or", "data", "properties", "can", "lead", "to", "such", "assumption", "?", "Response", "All", "our", "experiments", "are", "conducted", "on", "practical", "neural", "network", "training", "tasks", "with", "real", "datasets", ".", "From", "the", "experiments", ",", "we", "find", "that", "the", "property", "holds", "for", "a", "variety", "of", "network", "architectures", "-LRB-", "MLP", ",", "CNN", ",", "Inception", ",", "RNN", "-RRB-", "and", "different", "datasets", "-LRB-", "image", ",", "text", ",", "etc", "-RRB-", ".", "We", "think", "that", "this", "can", "be", "an", "amenable", "property", "of", "over-parameterized", "network", ".", "In", "fact", ",", "several", "recent", "works", "-LRB-", "-LSB-", "1,2", "-RSB-", "-RRB-", "show", "that", "the", "optimization", "trajectories", "of", "SGD", "is", "generally", "smooth", "despite", "the", "nonconvexity", "and", "depth", "of", "the", "networks", ",", "and", "our", "star-convexity", "property", "can", "be", "viewed", "as", "another", "aspect", "that", "further", "promotes", "theoretical", "justification", "to", "deep", "learning", "optimization", ".", "We", "will", "explore", "these", "two", "questions", "more", "in", "future", "work", ".", "3", ".", "There", "is", "a", "missing", "related", "work", "from", "the", "algorithmic", "perspective", "to", "explore", "the", "global", "optimization", "in", "deep", "learning", ":", "Zhang", "et", ".", "al.", ".", "CVPR", "'", "18", ".", "TICKTICK", "BPGrad", ":", "Towards", "Global", "Optimality", "in", "Deep", "Learning", "via", "Branch", "and", "Pruning", "''", ".", "Response", ":", "We", "thank", "the", "reviewer", "for", "pointing", "out", "this", "interesting", "related", "work", ".", "We", "will", "cite", "this", "work", "in", "the", "upcoming", "revision", ".", "-LSB-", "1", "-RSB-", "Li", "et", "al.", ".", "Visualizing", "the", "loss", "landscape", "of", "neural", "nets", ".", "To", "appear", "in", "NIPS", "2018", "-LSB-", "2", "-RSB-", "Eliana", "Lorch", ".", "Visualizing", "deep", "network", "training", "trajectories", "with", "pca", ".", "In", "ICML", "Workshop", "on", "Visualization", "for", "Deep", "Learning", ",", "2016", "."], "comment_id": "B1equOGWCm"}, {"rels": [[0, 353, 353, 1854, "textualorganization"], [0, 2, 2, 13, "elaboration"], [0, 13, 13, 353, "elaboration"], [13, 36, 36, 230, "list"], [13, 18, 18, 36, "elaboration"], [36, 230, 13, 36, "list"], [36, 48, 48, 91, "elaboration"], [48, 67, 67, 91, "same_unit"], [48, 59, 59, 67, "elaboration"], [67, 91, 48, 67, "same_unit"], [67, 69, 69, 91, "elaboration"], [69, 77, 77, 91, "elaboration"], [36, 91, 91, 230, "elaboration"], [91, 106, 106, 107, "elaboration"], [91, 107, 107, 123, "purpose"], [107, 114, 114, 123, "elaboration"], [91, 123, 123, 230, "elaboration"], [123, 149, 149, 230, "list"], [123, 126, 126, 149, "purpose"], [136, 149, 126, 136, "attribution"], [149, 230, 123, 149, "list"], [149, 161, 161, 230, "list"], [149, 155, 155, 161, "elaboration"], [161, 230, 149, 161, "list"], [161, 170, 170, 230, "list"], [161, 163, 163, 170, "elaboration"], [170, 230, 161, 170, "list"], [170, 188, 188, 195, "elaboration"], [170, 195, 195, 203, "elaboration"], [170, 203, 203, 230, "elaboration"], [203, 205, 205, 230, "elaboration"], [205, 212, 212, 230, "same_unit"], [212, 230, 205, 212, "same_unit"], [212, 219, 219, 230, "elaboration"], [13, 230, 230, 353, "elaboration"], [230, 236, 236, 249, "elaboration"], [236, 242, 242, 249, "elaboration"], [230, 249, 249, 262, "elaboration"], [249, 253, 253, 262, "elaboration"], [230, 262, 262, 353, "elaboration"], [262, 266, 266, 353, "elaboration"], [266, 268, 268, 353, "elaboration"], [268, 275, 275, 353, "elaboration"], [275, 298, 298, 304, "list"], [298, 304, 275, 298, "list"], [275, 304, 304, 353, "elaboration"], [304, 321, 321, 353, "elaboration"], [321, 324, 324, 325, "elaboration"], [321, 325, 325, 353, "elaboration"], [325, 328, 328, 353, "elaboration"], [328, 337, 337, 353, "elaboration"], [337, 347, 347, 353, "elaboration"], [353, 1854, 0, 353, "textualorganization"], [353, 864, 864, 1854, "topic"], [354, 370, 353, 354, "attribution"], [353, 370, 370, 489, "elaboration"], [386, 387, 370, 386, "attribution"], [370, 387, 387, 489, "elaboration"], [387, 392, 392, 401, "elaboration"], [387, 401, 401, 489, "elaboration"], [401, 421, 421, 445, "elaboration"], [401, 445, 445, 489, "elaboration"], [445, 449, 449, 489, "elaboration"], [449, 463, 463, 489, "same_unit"], [449, 459, 459, 463, "elaboration"], [463, 489, 449, 463, "same_unit"], [463, 467, 467, 489, "elaboration"], [467, 475, 475, 489, "elaboration"], [353, 489, 489, 571, "elaboration"], [490, 522, 489, 490, "attribution"], [490, 508, 508, 522, "purpose"], [508, 511, 511, 522, "elaboration"], [518, 522, 511, 518, "attribution"], [511, 517, 517, 518, "same_unit"], [511, 512, 512, 517, "elaboration"], [517, 518, 511, 517, "same_unit"], [489, 522, 522, 571, "elaboration"], [522, 538, 538, 571, "elaboration"], [538, 544, 544, 571, "elaboration"], [353, 571, 571, 864, "elaboration"], [571, 576, 576, 592, "purpose"], [571, 592, 592, 864, "elaboration"], [592, 602, 602, 864, "elaboration"], [610, 623, 602, 610, "attribution"], [602, 623, 623, 864, "elaboration"], [623, 635, 635, 864, "elaboration"], [640, 665, 635, 640, "attribution"], [635, 665, 665, 864, "circumstance"], [665, 675, 675, 689, "elaboration"], [675, 683, 683, 689, "elaboration"], [683, 685, 685, 689, "list"], [685, 689, 683, 685, "list"], [665, 689, 689, 864, "elaboration"], [689, 700, 700, 739, "elaboration"], [700, 733, 733, 738, "elaboration"], [700, 738, 738, 739, "elaboration"], [689, 739, 739, 864, "elaboration"], [739, 740, 740, 757, "elaboration"], [740, 745, 745, 757, "elaboration"], [745, 753, 753, 757, "same_unit"], [745, 749, 749, 753, "elaboration"], [753, 757, 745, 753, "same_unit"], [739, 757, 757, 864, "elaboration"], [773, 780, 757, 773, "antithesis"], [757, 761, 761, 773, "elaboration"], [761, 767, 767, 773, "elaboration"], [757, 780, 780, 864, "elaboration"], [783, 801, 780, 783, "attribution"], [780, 801, 801, 864, "elaboration"], [801, 813, 813, 822, "contrast"], [813, 822, 801, 813, "contrast"], [801, 822, 822, 864, "elaboration"], [822, 827, 827, 836, "purpose"], [822, 836, 836, 864, "elaboration"], [836, 847, 847, 864, "elaboration"], [864, 1854, 353, 864, "topic"], [864, 1216, 1216, 1854, "textualorganization"], [864, 875, 875, 1216, "textualorganization"], [875, 1216, 864, 875, "textualorganization"], [875, 889, 889, 922, "elaboration"], [889, 913, 913, 922, "elaboration"], [875, 922, 922, 1216, "elaboration"], [922, 941, 941, 1216, "same_unit"], [922, 934, 934, 941, "elaboration"], [934, 935, 935, 941, "elaboration"], [941, 1216, 922, 941, "same_unit"], [941, 958, 958, 1216, "elaboration"], [958, 975, 975, 1216, "list"], [974, 975, 958, 974, "attribution"], [975, 1216, 958, 975, "list"], [975, 994, 994, 1216, "elaboration"], [994, 999, 999, 1018, "elaboration"], [994, 1018, 1018, 1216, "elaboration"], [1018, 1035, 1035, 1216, "elaboration"], [1035, 1040, 1040, 1216, "same_unit"], [1035, 1037, 1037, 1040, "purpose"], [1040, 1216, 1035, 1040, "same_unit"], [1040, 1045, 1045, 1216, "temporal"], [1045, 1053, 1053, 1216, "elaboration"], [1053, 1054, 1054, 1067, "list"], [1054, 1067, 1053, 1054, "list"], [1054, 1058, 1058, 1067, "elaboration"], [1053, 1067, 1067, 1216, "elaboration"], [1067, 1087, 1087, 1216, "elaboration"], [1087, 1111, 1111, 1216, "elaboration"], [1111, 1123, 1123, 1129, "circumstance"], [1111, 1129, 1129, 1216, "elaboration"], [1129, 1154, 1154, 1216, "elaboration"], [1154, 1165, 1165, 1172, "elaboration"], [1154, 1172, 1172, 1216, "elaboration"], [1172, 1176, 1176, 1216, "list"], [1173, 1176, 1172, 1173, "attribution"], [1176, 1216, 1172, 1176, "list"], [1176, 1190, 1190, 1216, "same_unit"], [1176, 1186, 1186, 1190, "elaboration"], [1190, 1216, 1176, 1190, "same_unit"], [1190, 1194, 1194, 1216, "elaboration"], [1194, 1202, 1202, 1216, "elaboration"], [1216, 1854, 864, 1216, "textualorganization"], [1217, 1249, 1216, 1217, "attribution"], [1217, 1235, 1235, 1249, "purpose"], [1235, 1238, 1238, 1249, "elaboration"], [1245, 1249, 1238, 1245, "attribution"], [1238, 1244, 1244, 1245, "same_unit"], [1238, 1239, 1239, 1244, "elaboration"], [1244, 1245, 1238, 1244, "same_unit"], [1216, 1249, 1249, 1854, "elaboration"], [1249, 1582, 1582, 1854, "topic"], [1249, 1265, 1265, 1582, "elaboration"], [1265, 1269, 1269, 1582, "elaboration"], [1269, 1277, 1277, 1318, "elaboration"], [1277, 1285, 1285, 1318, "elaboration"], [1269, 1318, 1318, 1582, "elaboration"], [1326, 1340, 1318, 1326, "attribution"], [1329, 1340, 1326, 1329, "attribution"], [1318, 1340, 1340, 1582, "elaboration"], [1353, 1379, 1340, 1353, "attribution"], [1340, 1379, 1379, 1549, "elaboration"], [1387, 1402, 1379, 1387, "attribution"], [1387, 1396, 1396, 1402, "elaboration"], [1396, 1399, 1399, 1402, "purpose"], [1379, 1402, 1402, 1549, "elaboration"], [1414, 1549, 1402, 1414, "attribution"], [1414, 1421, 1421, 1427, "elaboration"], [1414, 1427, 1427, 1440, "elaboration"], [1414, 1440, 1440, 1549, "elaboration"], [1440, 1452, 1452, 1467, "elaboration"], [1440, 1467, 1467, 1549, "elaboration"], [1467, 1512, 1512, 1549, "list"], [1467, 1468, 1468, 1512, "elaboration"], [1468, 1494, 1494, 1512, "elaboration"], [1494, 1506, 1506, 1512, "question"], [1494, 1500, 1500, 1506, "elaboration"], [1506, 1512, 1494, 1506, "question"], [1512, 1549, 1467, 1512, "list"], [1512, 1518, 1518, 1549, "reason"], [1518, 1531, 1531, 1549, "elaboration"], [1536, 1549, 1531, 1536, "attribution"], [1531, 1534, 1534, 1536, "purpose"], [1340, 1549, 1549, 1582, "elaboration"], [1555, 1582, 1549, 1555, "attribution"], [1555, 1564, 1564, 1582, "elaboration"], [1564, 1565, 1565, 1582, "elaboration"], [1565, 1570, 1570, 1582, "elaboration"], [1570, 1574, 1574, 1582, "elaboration"], [1574, 1578, 1578, 1582, "elaboration"], [1582, 1854, 1249, 1582, "topic"], [1582, 1739, 1739, 1854, "list"], [1582, 1598, 1598, 1605, "contrast"], [1582, 1586, 1586, 1598, "elaboration"], [1586, 1592, 1592, 1598, "elaboration"], [1598, 1605, 1582, 1598, "contrast"], [1582, 1605, 1605, 1739, "elaboration"], [1608, 1626, 1605, 1608, "attribution"], [1605, 1626, 1626, 1739, "elaboration"], [1626, 1631, 1631, 1665, "elaboration"], [1631, 1642, 1642, 1665, "elaboration"], [1643, 1665, 1642, 1643, "attribution"], [1655, 1665, 1643, 1655, "antithesis"], [1643, 1648, 1648, 1655, "elaboration"], [1655, 1661, 1661, 1665, "purpose"], [1663, 1665, 1661, 1663, "attribution"], [1626, 1665, 1665, 1739, "elaboration"], [1665, 1670, 1670, 1694, "elaboration"], [1670, 1689, 1689, 1694, "elaboration"], [1665, 1694, 1694, 1739, "elaboration"], [1697, 1723, 1694, 1697, "attribution"], [1697, 1706, 1706, 1723, "circumstance"], [1706, 1717, 1717, 1722, "elaboration"], [1706, 1722, 1722, 1723, "elaboration"], [1694, 1723, 1723, 1739, "elaboration"], [1739, 1854, 1582, 1739, "list"], [1739, 1750, 1750, 1854, "textualorganization"], [1750, 1854, 1739, 1750, "textualorganization"], [1750, 1764, 1764, 1797, "elaboration"], [1764, 1788, 1788, 1797, "elaboration"], [1750, 1797, 1797, 1854, "elaboration"], [1797, 1826, 1826, 1854, "elaboration"], [1826, 1834, 1834, 1842, "purpose"], [1826, 1842, 1842, 1854, "elaboration"]], "tokens": ["Summary", ":", "The", "authors", "study", "building", "models", "for", "edits", "in", "source", "code", ".", "The", "application", "is", "obvious", ":", "a", "system", "to", "accurately", "predict", "what", "the", "next", "edit", "should", "be", "would", "be", "very", "valuable", "for", "developers", ".", "Here", ",", "edits", "are", "modeled", "by", "two", "types", "of", "sequences", ":", "one", "that", "tracks", "the", "state", "of", "all", "edits", "at", "each", "time", "step", "-LRB-", "and", "is", "thus", "very", "long", "-RRB-", ",", "and", "one", "that", "contains", "the", "initial", "step", "and", "a", "changelist", "that", "contains", "the", "minimal", "information", "required", "to", "derive", "the", "state", "at", "any", "time", ".", "The", "authors", "train", "models", "on", "top", "of", "both", "of", "these", "representations", ",", "with", "the", "idea", "being", "to", "match", "the", "performance", "of", "the", "explicit", "-LRB-", "heavy", "-RRB-", "model", "with", "the", "implicit", "model", ".", "This", "is", "shown", "to", "be", "challenging", ",", "but", "a", "clever", "model", "is", "introduced", "that", "achieves", "this", ",", "and", "is", "thus", "the", "best", "of", "both", "worlds", ".", "There", "are", "synthetic", "and", "real-world", "code", "-LRB-", "text", "-RRB-", "edit", "experiments", ".", "Strengths", ":", "The", "problem", "is", "well-posed", "and", "well-motivated", ".", "There", "'s", "a", "nice", "application", "of", "powerful", "existing", "models", ",", "combined", "and", "tailored", "to", "the", "current", "work", ".", "The", "writing", "is", "generally", "quite", "clear", ".", "The", "number", "of", "experiments", "is", "quite", "solid", ".", "Weaknesses", ":", "The", "main", "flaw", "is", "that", "nothing", "here", "is", "really", "specifically", "for", "souce", "code", ";", "the", "authors", "are", "really", "just", "modeling", "edits", "in", "text", "sequences", ".", "There", "'s", "not", "an", "obvious", "way", "to", "integrate", "the", "kinds", "of", "constraints", "that", "source", "code", "typically", "satisfies", "either", ".", "There", "'s", "some", "confusion", "-LRB-", "for", "me", "-RRB-", "about", "the", "implicit/explicit", "representations", ".", "More", "questions", "below", ".", "Verdict", ":", "This", "is", "a", "pretty", "solid", "paper", ".", "It", "does", "n't", "quite", "match", "up", "to", "its", "title", ",", "but", "it", "sets", "out", "a", "clearly", "defined", "problem", ",", "achieves", "its", "aims", ",", "and", "introduces", "some", "nice", "tricks", ".", "Although", "it", "does", "n't", "produce", "anything", "genuinely", "groundbreaking", ",", "it", "seems", "like", "a", "nice", "step", "forward", ".", "Comments", "and", "Questions", ":", "-", "The", "problem", "is", "written", "in", "the", "context", "of", "source", "code", ",", "but", "it", "'s", "really", "setup", "just", "for", "text", "sequences", ",", "which", "is", "a", "broader", "problem", ".", "Is", "there", "a", "way", "the", "authors", "take", "can", "advantage", "of", "the", "structural", "requirements", "for", "source", "code", "?", "I", "do", "n't", "see", "an", "obvious", "way", ",", "but", "I", "'m", "curious", "what", "the", "authors", "think", ".", "-", "What", "'s", "the", "benefit", "of", "using", "the", "implicit", "representation", "for", "the", "positions", "?", "The", "explicit/implicit", "position", "forms", "are", "basically", "just", "using", "the", "permutation", "or", "the", "inverse", "permutation", "form", ",", "which", "are", "equivalent", ".", "I", "do", "n't", "see", "directly", "what", "'s", "saved", "here", ",", "the", "alphabet", "size", "and", "the", "number", "of", "integers", "to", "store", "is", "the", "same", ".", "-", "Similar", "question", ".", "The", "implicit", "likelihood", "is", "s", "^", "0", ",", "e", "^", "-LRB-", "1", "-RRB-", ",", "...", ",", "e", "^", "-LRB-", "t-1", "-RRB-", ",", "with", "the", "e", "^", "-LRB-", "i", "-RRB-", "'s", "being", "based", "on", "the", "implicit", "representations", "of", "the", "positions", ".", "Seems", "like", "you", "could", "do", "this", "with", "the", "*", "explicit", "*", "positions", "just", "fine", ",", "they", "carry", "enough", "information", "to", "derive", "s", "^", "-LRB-", "i", "-RRB-", "from", "s", "^", "-LRB-", "i-1", "-RRB-", ".", "That", "is", ",", "the", "explicit/implicit", "problems", "are", "not", "really", "related", "to", "the", "explicit/implicit", "position", "representations", ".", "-", "Just", "wanted", "to", "point", "out", "that", "this", "type", "of", "approach", "to", "sequences", "and", "edits", "has", "been", "studied", "pretty", "often", "in", "the", "information/coding", "theory", "communities", ",", "especially", "in", "the", "area", "of", "synchronization", ".", "There", ",", "the", "idea", "is", "to", "create", "the", "minimal", "TICKTICK", "changelist", "''", "of", "insertions/deletions", "from", "two", "versions", "of", "a", "file", ".", "This", "could", "come", "in", "handy", "when", "building", "the", "datasets", ".", "See", ",", "for", "example", ",", "Sala", "et", "al", "TICKTICK", "Synchronizing", "files", "from", "a", "large", "number", "of", "insertions", "and", "deletions", "''", ".", "-", "The", "problem", "statement", "should", "be", "stated", "a", "bit", "more", "rigorously", ".", "We", "'d", "like", "to", "say", "that", "the", "initial", "state", "is", "drawn", "from", "some", "distribution", "and", "that", "the", "state", "at", "each", "time", "forms", "a", "stochastic", "process", "with", "some", "transition", "law", ".", "As", "it", "stands", "the", "problem", "is", "n't", "well-defined", ",", "since", "with", "no", "probability", "distribution", ",", "there", "'s", "nothing", "to", "predict", "and", "no", "likelihood", ".", "-", "The", "TICKTICK", "analogical", "decoder", "''", "idea", "is", "really", "nice", ".", "-", "For", "the", "synthetic", "dataset", ",", "why", "are", "you", "selecting", "a", "random", "initial", "string", ",", "rather", "than", "using", "some", "existing", "generative", "text", "or", "source", "code", "model", ",", "which", "would", "get", "you", "synthetic", "data", "that", "more", "closely", "resembles", "code", "?", "-", "I", "really", "liked", "the", "idea", "of", "using", "an", "oracle", "that", "gives", "the", "position", "as", "upper", "bound", ".", "Would", "it", "make", "sense", "to", "also", "have", "the", "opposite", "oracle", "that", "gives", "the", "edit", "symbol", ",", "but", "does", "n't", "tell", "the", "location", "?", "I", "'m", "really", "curious", "which", "is", "the", "TICKTICK", "harder", "''", "task", ",", "predicting", "the", "next", "symbol", "or", "the", "next", "location", ".", "In", "the", "information-theory", "setting", ",", "these", "two", "are", "actually", "equally", "hard", ",", "but", "the", "real-world", "setting", "might", "be", "pretty", "different", ".", "It", "would", "also", "be", "interesting", "to", "train", "models", "on", "top", "of", "the", "POMP", ".", "That", "would", "produce", "genuine", "upper", "bounds", "to", "the", "model", "performances", ".", "-", "The", "explicit", "baseline", "model", "performs", "very", "well", "on", "all", "the", "edit", "types", "in", "Table", "1", ".", "Are", "there", "cases", "where", "even", "this", "explicit", "case", "works", "poorly", "?", "Is", "the", "improved", "implicit", "model", "*", "always", "*", "upper", "bounded", "by", "the", "explicit", "model", "-LRB-", "to", "me", "it", "seems", "like", "the", "answer", "should", "always", "be", "yes", ",", "but", "it", "would", "be", "interesting", "to", "check", "it", "out", "for", "cases", "where", "explicit", "is", "not", "very", "high", "accuracy", "-RRB-", ".", "Thanks", "for", "the", "positive", "review", "and", "the", "careful", "attention", "to", "detail", "!", "Questions", "are", "answered", "inline", "below", ".", ">", "Is", "there", "a", "way", "the", "authors", "take", "can", "advantage", "of", "the", "structural", "requirements", "for", "source", "code", "?", "I", "do", "n't", "see", "an", "obvious", "way", ",", "but", "I", "'m", "curious", "what", "the", "authors", "think", ".", "This", "is", "an", "excellent", "insight", ",", "and", "we", "have", "definitely", "considered", "extensions", "of", "our", "models", "to", "structured", "data", ".", "As", "this", "was", "a", "question", "that", "was", "highlighted", "by", "multiple", "reviewers", ",", "please", "see", "our", "response", "in", "the", "general", "comment", "to", "all", "reviewers", ".", "The", "short", "answer", "is", "that", "we", "do", "believe", "such", "extensions", "are", "possible", ",", "but", "in", "this", "work", "we", "wanted", "to", "stay", "focused", "on", "formulating", "the", "problem", "itself", "before", "taking", "advantage", "of", "more", "domain-specific", "structures", ".", ">", "What", "'s", "the", "benefit", "of", "using", "the", "implicit", "representation", "for", "the", "positions", "?", "The", "explicit/implicit", "position", "forms", "are", "basically", "just", "using", "the", "permutation", "or", "the", "inverse", "permutation", "form", ",", "which", "are", "equivalent", ".", "I", "do", "n't", "see", "directly", "what", "'s", "saved", "here", ",", "the", "alphabet", "size", "and", "the", "number", "of", "integers", "to", "store", "is", "the", "same", ".", "A", "key", "property", "of", "implicit", "positions", "is", "that", "they", "do", "n't", "change", "as", "more", "edits", "are", "made", ".", "This", "enables", "the", "training", "efficiency", "like", "in", "Vaswani", "et", "al", ",", "where", "we", "can", "train", "on", "all", "output", "steps", "with", "a", "single", "forward-backward", "pass", ".", "We", "would", "n't", "be", "able", "to", "do", "this", "with", "explicit", "positions", "that", "potentially", "changed", "after", "each", "edit", ".", ">", "Similar", "question", ".", "The", "implicit", "likelihood", "is", "s", "^", "0", ",", "e", "^", "-LRB-", "1", "-RRB-", ",", "...", ",", "e", "^", "-LRB-", "t-1", "-RRB-", ",", "with", "the", "e", "^", "-LRB-", "i", "-RRB-", "'s", "being", "based", "on", "the", "implicit", "representations", "of", "the", "positions", ".", "Seems", "like", "you", "could", "do", "this", "with", "the", "*", "explicit", "*", "positions", "just", "fine", ",", "they", "carry", "enough", "information", "to", "derive", "s", "^", "-LRB-", "i", "-RRB-", "from", "s", "^", "-LRB-", "i-1", "-RRB-", ".", "That", "is", ",", "the", "explicit/implicit", "problems", "are", "not", "really", "related", "to", "the", "explicit/implicit", "position", "representations", ".", "This", "is", "fair", ".", "It", "'s", "possible", "to", "derive", "the", "explicit", "positions", "given", "the", "previous", "edits", "in", "the", "implicit", "representation", "-LRB-", "like", "applying", "a", "diff", "-RRB-", ",", "and", "indeed", ",", "in", "the", "experiments", "we", "are", "leveraging", "the", "fact", "that", "it", "is", "valid", "to", "compare", "results", "between", "models", "trained", "on", "the", "different", "representations", ".", "The", "point", "we", "'re", "trying", "to", "make", "here", "is", "just", "one", "of", "how", "the", "data", "is", "presented", "to", "the", "neural", "network", ".", "In", "the", "implicit", "case", ",", "it", "'s", "up", "to", "the", "neural", "network", "to", "TICKTICK", "learn", "how", "to", "apply", "the", "diff", "''", "whereas", "in", "the", "explicit", "case", ",", "an", "external", "deterministic", "algorithm", "applies", "the", "diff", "for", "the", "neural", "network", ".", "So", "implicit", "vs", "explicit", "is", "more", "about", "distinguishing", "between", "what", "kinds", "of", "representations", "the", "network", "is", "given", "vs", "being", "forced", "to", "learn", ".", "We", "'ll", "clarify", "the", "wording", "in", "TICKTICK", "Problem", "Statement", "''", "to", "say", "that", "there", "is", "only", "one", "problem", ",", "which", "is", "to", "predict", "next", "edits", "given", "initial", "state", "and", "previous", "edits", ",", "but", "two", "families", "of", "architectures", ":", "explicit", "assumes", "an", "external", "algorithm", "applies", "the", "diffs", "to", "get", "explicit", "states", "that", "are", "fed", "into", "the", "network", ",", "and", "implicit", "works", "directly", "off", "the", "edits", ".", ">", "For", "the", "synthetic", "dataset", ",", "why", "are", "you", "selecting", "a", "random", "initial", "string", ",", "rather", "than", "using", "some", "existing", "generative", "text", "or", "source", "code", "model", ",", "which", "would", "get", "you", "synthetic", "data", "that", "more", "closely", "resembles", "code", "?", "It", "would", "certainly", "be", "possible", ".", "The", "random", "initial", "strings", "were", "simpler", "because", "we", "have", "control", "over", "the", "vocabulary", "size", "and", "length", "of", "sequences", ",", "which", "allowed", "us", "to", "control", "how", "long", "the", "initial", "strings", "were", "and", "how", "many", "edits", "were", "applied", ".", "With", "real", "code", ",", "we", "think", "it", "would", "introduce", "a", "few", "more", "confounding", "factors", ".", ">", "I", "really", "liked", "the", "idea", "of", "using", "an", "oracle", "that", "gives", "the", "position", "as", "upper", "bound", ".", "Would", "it", "make", "sense", "to", "also", "have", "the", "opposite", "oracle", "that", "gives", "the", "edit", "symbol", ",", "but", "does", "n't", "tell", "the", "location", "?", "I", "'m", "really", "curious", "which", "is", "the", "TICKTICK", "harder", "''", "task", ",", "predicting", "the", "next", "symbol", "or", "the", "next", "location", ".", "Thanks", "for", "the", "suggestion", ".", "It", "'s", "not", "100", "%", "clear", "to", "us", "what", "an", "oracle", "that", "TICKTICK", "pattern-matched", "''", "on", "position", "given", "edit", "symbol", "would", "look", "like", ",", "but", "we", "agree", "it", "'s", "interesting", "to", "think", "about", ".", "To", "answer", "the", "larger", "question", "of", "what", "the", "hardest", "part", "of", "the", "prediction", "is", ",", "we", "include", "some", "additional", "plots", "in", "Appendix", "B.", "3", "of", "an", "updated", "version", ".", "The", "plots", "show", "that", "the", "most", "difficult", "part", "is", "predicting", "the", "jumps", "when", "one", "pattern", "is", "completed", "and", "then", "the", "model", "must", "decide", "where", "to", "edit", "next", ".", ">", "The", "explicit", "baseline", "model", "performs", "very", "well", "on", "all", "the", "edit", "types", "in", "Table", "1", ".", "Are", "there", "cases", "where", "even", "this", "explicit", "case", "works", "poorly", "?", "Is", "the", "improved", "implicit", "model", "*", "always", "*", "upper", "bounded", "by", "the", "explicit", "model", "-LRB-", "to", "me", "it", "seems", "like", "the", "answer", "should", "always", "be", "yes", ",", "but", "it", "would", "be", "interesting", "to", "check", "it", "out", "for", "cases", "where", "explicit", "is", "not", "very", "high", "accuracy", "-RRB-", ".", "The", "implicit", "model", "gets", "slightly", "better", "results", "on", "the", "TICKTICK", "MultiTask", "''", "problem", "in", "Table", "1", ",", "so", "the", "explicit", "model", "is", "not", "*", "always", "*", "more", "accurate", ".", "However", ",", "we", "did", "find", "the", "explicit", "model", "to", "produce", "good", "accuracy", "across", "the", "board", ".", "The", "main", "issue", "with", "it", "is", "the", "memory", "and", "computational", "cost", "."], "comment_id": "B1e_Utl5CX"}, {"rels": [[0, 16, 16, 32, "same_unit"], [0, 5, 5, 16, "elaboration"], [16, 32, 0, 16, "same_unit"], [16, 29, 29, 32, "purpose"], [0, 32, 32, 39, "circumstance"], [0, 39, 39, 54, "elaboration"], [0, 54, 54, 543, "elaboration"], [54, 319, 319, 543, "topic"], [63, 68, 54, 63, "attribution"], [64, 68, 63, 64, "attribution"], [54, 68, 68, 319, "elaboration"], [68, 72, 72, 82, "purpose"], [68, 82, 82, 319, "elaboration"], [82, 94, 94, 319, "list"], [94, 319, 82, 94, "list"], [94, 125, 125, 319, "list"], [94, 119, 119, 125, "elaboration"], [125, 319, 94, 125, "list"], [125, 146, 146, 319, "list"], [125, 132, 132, 146, "same_unit"], [125, 128, 128, 132, "elaboration"], [132, 146, 125, 132, "same_unit"], [132, 140, 140, 146, "elaboration"], [146, 319, 125, 146, "list"], [146, 154, 154, 319, "list"], [154, 319, 146, 154, "list"], [154, 155, 155, 159, "elaboration"], [154, 159, 159, 165, "elaboration"], [154, 165, 165, 215, "elaboration"], [165, 169, 169, 215, "purpose"], [169, 177, 177, 215, "same_unit"], [169, 174, 174, 177, "elaboration"], [177, 215, 169, 177, "same_unit"], [177, 178, 178, 198, "elaboration"], [177, 198, 198, 215, "elaboration"], [198, 210, 210, 215, "elaboration"], [154, 215, 215, 319, "elaboration"], [220, 242, 215, 220, "attribution"], [220, 234, 234, 242, "elaboration"], [215, 242, 242, 319, "elaboration"], [242, 251, 251, 258, "elaboration"], [242, 258, 258, 265, "elaboration"], [258, 261, 261, 265, "same_unit"], [261, 265, 258, 261, "same_unit"], [242, 265, 265, 319, "elaboration"], [265, 274, 274, 276, "elaboration"], [265, 276, 276, 319, "elaboration"], [276, 279, 279, 293, "list"], [279, 293, 276, 279, "list"], [279, 292, 292, 293, "same_unit"], [279, 286, 286, 292, "elaboration"], [292, 293, 279, 292, "same_unit"], [276, 293, 293, 319, "elaboration"], [293, 301, 301, 319, "temporal"], [301, 311, 311, 319, "elaboration"], [319, 543, 54, 319, "topic"], [319, 338, 338, 345, "elaboration"], [319, 345, 345, 484, "elaboration"], [345, 359, 359, 372, "elaboration"], [359, 364, 364, 372, "elaboration"], [345, 372, 372, 387, "elaboration"], [372, 373, 373, 387, "list"], [373, 387, 372, 373, "list"], [373, 378, 378, 387, "elaboration"], [345, 387, 387, 396, "elaboration"], [392, 396, 387, 392, "attribution"], [345, 396, 396, 484, "elaboration"], [396, 398, 398, 417, "purpose"], [401, 417, 398, 401, "attribution"], [401, 409, 409, 417, "elaboration"], [409, 413, 413, 417, "elaboration"], [396, 417, 417, 484, "elaboration"], [417, 441, 441, 446, "elaboration"], [417, 446, 446, 484, "elaboration"], [446, 450, 450, 455, "elaboration"], [446, 455, 455, 484, "elaboration"], [455, 468, 468, 484, "same_unit"], [455, 457, 457, 468, "elaboration"], [468, 484, 455, 468, "same_unit"], [468, 471, 471, 484, "elaboration"], [319, 484, 484, 543, "means"], [484, 499, 499, 511, "elaboration"], [499, 506, 506, 511, "elaboration"], [484, 511, 511, 512, "elaboration"], [484, 512, 512, 525, "elaboration"], [512, 516, 516, 525, "list"], [516, 525, 512, 516, "list"], [484, 525, 525, 543, "elaboration"], [525, 536, 536, 543, "elaboration"], [538, 543, 536, 538, "attribution"]], "tokens": ["1", "-RRB-", "Implicit", "reparameterization", "gradients", "-LRB-", "Jankowiak", "&", "Obermeyer", "2018", ",", "Figurnov", "et", "al.", "2018", "-RRB-", "already", "show", "improvements", "over", "GRep", "and", "RSVI", ",", "so", "it", "would", "seem", "natural", "to", "use", "them", "as", "the", "baseline", "for", "Sec", "7.1", ".", "In", "this", "setting", ",", "what", "is", "the", "relationship", "between", "GO", "and", "Implicit", "Reparameterization", "Gradients", ".", "2", "-RRB-", "In", "Sec", "7.2", ",", "GO", "gradients", "require", "evaluating", "f", "many", "times", ".", "It", "would", "seem", "natural", "to", "compare", "to", "Local", "Expectation", "gradients", "in", "this", "case", ".", "What", "is", "the", "relationship", "between", "GO", "and", "LEgrad", "in", "this", "case", "?", "3", "-RRB-", "For", "the", "discrete", "case", ",", "because", "we", "are", "making", "many", "calls", "to", "f", ",", "would", "it", "make", "sense", "to", "compare", "to", "multisample", "techniques", "-LRB-", "e.g.", ",", "VIMCO", "-RRB-", "?", "4", "-RRB-", "ARM", "-LRB-", "Yin", "2018", "-RRB-", "is", "a", "recent", "technique", "for", "discrete", "random", "variables", "that", "uses", "multiple", "function", "evals", ".", "What", "is", "the", "relation", "with", "GO", "gradients", "?", "Thanks", "for", "your", "interest", ".", "Your", "comments", "are", "addressed", "below", ".", "-LRB-", "1", "-RRB-", "Similar", "to", "GO", ",", "Implicit", "Reparameterization", "-LRB-", "ImplicitRep", "-RRB-", "Gradients", "-LRB-", "Jankowiak", "&", "Obermeyer", "2018", ",", "Figurnov", "et", "al.", "2018", "-RRB-", "tried", "to", "exploit", "the", "gradient", "information", "of", "function", "f", "-LRB-", "z", "-RRB-", "for", "lower", "Monte", "Carlo", "variance", ",", "via", "a", "technique", "they", "termed", "implicit", "differentiation", ".", "Although", "seeming", "different", ",", "ImplicitRep", "is", "more", "or", "less", "a", "special", "case", "of", "GO", "in", "the", "single-layer", "continuous", "situation", "-LRB-", "thus", "no", "need", "for", "comparison", "-RRB-", ".", "One", "can", "reveal", "this", "by", "comparing", "their", "Eq", ".", "-LRB-", "5", "-RRB-", "with", "our", "Eq", ".", "-LRB-", "9", "-RRB-", "in", "Theorem", "1", ".", "The", "difference", "is", "that", "GO", "generalizes", "to", "discrete", "situations", "-LRB-", "Theorem", "1", "-RRB-", ",", "and", "also", "to", "deep", "probabilistic", "graphical", "models", "-LRB-", "Theorem", "2", "and", "3", "-RRB-", ".", "-LRB-", "2", "-RRB-", "As", "stated", "in", "the", "paragraph", "before", "Section", "4", ",", "we", "adopt", "the", "local", "expectation", "idea", "when", "it", "is", "applicable", "and", "computationally", "acceptable", ".", "In", "some", "specific", "cases", ",", "like", "discrete", "random", "variables", "with", "finite", "support", ",", "fully", "applying", "the", "local", "expectation", "idea", "will", "reduce", "GO", "to", "the", "LEgrad", ".", "However", ",", "GO", "has", "the", "advantages", "that", "it", "is", "applicable", "to", "discrete", "situations", "with", "-LRB-", "1", "-RRB-", "infinite", "support", "-LRB-", "where", "LEgrad", "may", "not", "be", "applicable", "-RRB-", ";", "-LRB-", "2", "-RRB-", "finite", "support", "-LRB-", "where", "LEgrad", "may", "be", "computationally", "expensive", "-RRB-", ".", "-LRB-", "3", "-RRB-", "Thank", "you", "for", "your", "suggestions", ".", "We", "plan", "to", "fully", "exploit", "-LRB-", "and", "potentially", "improve", "-RRB-", "GO", "under", "various", "-LRB-", "discrete", "-RRB-", "cases", "in", "the", "future", ".", "However", ",", "we", "consider", "it", "beyond", "the", "scope", "of", "this", "conference", "paper", ",", "which", "is", "meant", "for", "presenting", "the", "derivation", "of", "a", "unified", "gradient", "that", "is", "widely", "applicable", ".", "-LRB-", "4", "-RRB-", "ARM", "-LRB-", "Yin", "2018", "-RRB-", ",", "using", "techniques", "-LRB-", "including", "data", "augmentation", ",", "permutation", ",", "and", "variance", "reduction", "-RRB-", "to", "aid", "REINFORCE", "for", "gradient", "calculation", ",", "is", "applicable", "to", "discrete", "situations", "with", "finite", "support", ".", "By", "comparison", ",", "GO", ",", "motivated", "by", "the", "connection", "of", "REINFORCE", "and", "Rep", ",", "is", "-LRB-", "1", "-RRB-", "a", "widely", "applicable", "gradient", "-LRB-", "continuous", "or", "discrete", "-RRB-", ";", "-LRB-", "2", "-RRB-", "can", "be", "applied", "to", "discrete", "situations", "with", "infinite", "support", ".", "There", "might", "be", "some", "implicit", "relations", "between", "ARM", "and", "GO", ".", "We", "leave", "that", "as", "future", "work", "."], "comment_id": "B1ef1_Gg57"}, {"rels": [[0, 9, 9, 1691, "same_unit"], [0, 6, 6, 9, "elaboration"], [9, 1691, 0, 9, "same_unit"], [11, 25, 9, 11, "attribution"], [11, 15, 15, 25, "elaboration"], [9, 25, 25, 1691, "elaboration"], [25, 42, 42, 61, "elaboration"], [25, 61, 61, 1691, "elaboration"], [61, 81, 81, 1691, "elaboration"], [81, 95, 95, 108, "elaboration"], [95, 100, 100, 108, "elaboration"], [81, 108, 108, 1691, "elaboration"], [108, 116, 116, 137, "purpose"], [116, 124, 124, 129, "elaboration"], [116, 129, 129, 137, "elaboration"], [108, 137, 137, 1691, "elaboration"], [137, 155, 155, 161, "elaboration"], [137, 161, 161, 1691, "elaboration"], [161, 175, 175, 1691, "elaboration"], [175, 209, 209, 1691, "list"], [175, 182, 182, 209, "list"], [182, 209, 175, 182, "list"], [182, 192, 192, 209, "list"], [192, 209, 182, 192, "list"], [209, 1691, 175, 209, "list"], [209, 220, 220, 232, "contrast"], [209, 213, 213, 220, "elaboration"], [220, 232, 209, 220, "contrast"], [209, 232, 232, 1691, "elaboration"], [232, 270, 270, 1691, "list"], [232, 247, 247, 270, "elaboration"], [247, 252, 252, 270, "elaboration"], [261, 270, 252, 261, "attribution"], [270, 1691, 232, 270, "list"], [270, 278, 278, 284, "elaboration"], [270, 284, 284, 1691, "elaboration"], [284, 289, 289, 1691, "textualorganization"], [289, 1691, 284, 289, "textualorganization"], [289, 296, 296, 1691, "textualorganization"], [296, 1691, 289, 296, "textualorganization"], [296, 341, 341, 1691, "topic"], [296, 307, 307, 341, "elaboration"], [309, 341, 307, 309, "attribution"], [309, 312, 312, 341, "elaboration"], [312, 328, 328, 341, "same_unit"], [312, 318, 318, 328, "elaboration"], [328, 341, 312, 328, "same_unit"], [328, 337, 337, 341, "elaboration"], [341, 1691, 296, 341, "topic"], [341, 351, 351, 356, "elaboration"], [341, 356, 356, 1691, "elaboration"], [356, 359, 359, 1691, "textualorganization"], [359, 1691, 356, 359, "textualorganization"], [359, 372, 372, 395, "elaboration"], [374, 386, 372, 374, "attribution"], [372, 386, 386, 395, "concession"], [359, 395, 395, 1691, "elaboration"], [400, 426, 395, 400, "attribution"], [395, 426, 426, 1691, "elaboration"], [426, 430, 430, 445, "purpose"], [426, 445, 445, 1691, "condition"], [445, 467, 467, 476, "elaboration"], [467, 473, 473, 476, "purpose"], [445, 476, 476, 1691, "elaboration"], [476, 489, 489, 506, "elaboration"], [476, 506, 506, 1691, "elaboration"], [506, 522, 522, 1691, "topic"], [510, 522, 506, 510, "attribution"], [510, 515, 515, 522, "purpose"], [522, 1691, 506, 522, "topic"], [525, 535, 522, 525, "attribution"], [525, 530, 530, 535, "list"], [530, 535, 525, 530, "list"], [522, 535, 535, 567, "elaboration"], [535, 539, 539, 543, "elaboration"], [535, 543, 543, 567, "elaboration"], [543, 548, 548, 567, "elaboration"], [548, 552, 552, 567, "elaboration"], [552, 557, 557, 567, "circumstance"], [522, 567, 567, 1691, "elaboration"], [567, 576, 576, 603, "elaboration"], [576, 580, 580, 603, "elaboration"], [593, 603, 580, 593, "attribution"], [593, 594, 594, 603, "elaboration"], [567, 603, 603, 1691, "elaboration"], [603, 645, 645, 1691, "list"], [603, 607, 607, 645, "elaboration"], [607, 620, 620, 645, "elaboration"], [635, 645, 620, 635, "attribution"], [645, 1691, 603, 645, "list"], [645, 677, 677, 1691, "list"], [677, 1691, 645, 677, "list"], [677, 692, 692, 1691, "list"], [677, 682, 682, 692, "purpose"], [692, 1691, 677, 692, "list"], [692, 696, 696, 1691, "textualorganization"], [696, 1691, 692, 696, "textualorganization"], [696, 717, 717, 1691, "elaboration"], [717, 723, 723, 755, "elaboration"], [723, 725, 725, 755, "reason"], [725, 730, 730, 755, "elaboration"], [730, 732, 732, 755, "purpose"], [734, 755, 732, 734, "attribution"], [734, 743, 743, 755, "elaboration"], [744, 755, 743, 744, "attribution"], [744, 749, 749, 755, "contrast"], [749, 755, 744, 749, "contrast"], [717, 755, 755, 1691, "elaboration"], [755, 795, 795, 1691, "list"], [755, 757, 757, 795, "elaboration"], [757, 782, 782, 795, "elaboration"], [795, 1691, 755, 795, "list"], [795, 799, 799, 821, "purpose"], [799, 809, 809, 821, "elaboration"], [795, 821, 821, 1691, "elaboration"], [821, 825, 825, 857, "elaboration"], [825, 829, 829, 857, "elaboration"], [829, 849, 849, 857, "circumstance"], [853, 857, 849, 853, "attribution"], [821, 857, 857, 1691, "elaboration"], [857, 863, 863, 908, "circumstance"], [863, 865, 865, 908, "elaboration"], [865, 870, 870, 908, "elaboration"], [857, 908, 908, 1691, "elaboration"], [908, 1075, 1075, 1691, "list"], [908, 921, 921, 940, "example"], [921, 931, 931, 940, "purpose"], [931, 934, 934, 940, "list"], [934, 940, 931, 934, "list"], [908, 940, 940, 1075, "elaboration"], [940, 959, 959, 1075, "example"], [959, 985, 985, 1075, "elaboration"], [997, 1007, 985, 997, "attribution"], [998, 1007, 997, 998, "attribution"], [985, 1007, 1007, 1075, "elaboration"], [1007, 1054, 1054, 1075, "list"], [1054, 1075, 1007, 1054, "list"], [1059, 1075, 1054, 1059, "attribution"], [1059, 1065, 1065, 1075, "elaboration"], [1075, 1691, 908, 1075, "list"], [1081, 1095, 1075, 1081, "antithesis"], [1075, 1095, 1095, 1691, "elaboration"], [1095, 1104, 1104, 1691, "elaboration"], [1127, 1691, 1104, 1127, "antithesis"], [1104, 1118, 1118, 1127, "elaboration"], [1127, 1132, 1132, 1162, "purpose"], [1134, 1162, 1132, 1134, "attribution"], [1134, 1136, 1136, 1162, "elaboration"], [1136, 1144, 1144, 1162, "elaboration"], [1144, 1151, 1151, 1162, "means"], [1151, 1155, 1155, 1162, "list"], [1155, 1162, 1151, 1155, "list"], [1127, 1162, 1162, 1691, "elaboration"], [1162, 1163, 1163, 1177, "list"], [1163, 1177, 1162, 1163, "list"], [1163, 1168, 1168, 1177, "purpose"], [1162, 1177, 1177, 1180, "elaboration"], [1162, 1180, 1180, 1691, "elaboration"], [1187, 1212, 1180, 1187, "attribution"], [1190, 1212, 1187, 1190, "attribution"], [1195, 1212, 1190, 1195, "attribution"], [1180, 1212, 1212, 1415, "elaboration"], [1212, 1260, 1260, 1280, "elaboration"], [1212, 1280, 1280, 1415, "elaboration"], [1282, 1323, 1280, 1282, "attribution"], [1282, 1283, 1283, 1298, "elaboration"], [1282, 1298, 1298, 1323, "elaboration"], [1280, 1323, 1323, 1415, "elaboration"], [1323, 1360, 1360, 1415, "elaboration"], [1180, 1415, 1415, 1691, "elaboration"], [1431, 1691, 1415, 1431, "attribution"], [1431, 1442, 1442, 1691, "elaboration"], [1442, 1464, 1464, 1691, "list"], [1464, 1691, 1442, 1464, "list"], [1464, 1470, 1470, 1691, "elaboration"], [1470, 1516, 1516, 1691, "elaboration"], [1516, 1531, 1531, 1691, "explanation"], [1531, 1543, 1543, 1691, "list"], [1531, 1538, 1538, 1543, "elaboration"], [1543, 1691, 1531, 1543, "list"], [1543, 1549, 1549, 1567, "elaboration"], [1549, 1551, 1551, 1567, "elaboration"], [1543, 1567, 1567, 1691, "elaboration"], [1567, 1571, 1571, 1691, "textualorganization"], [1571, 1691, 1567, 1571, "textualorganization"], [1571, 1580, 1580, 1691, "elaboration"], [1580, 1584, 1584, 1603, "elaboration"], [1580, 1603, 1603, 1691, "elaboration"], [1603, 1617, 1617, 1691, "list"], [1603, 1605, 1605, 1617, "elaboration"], [1617, 1691, 1603, 1617, "list"], [1617, 1622, 1622, 1691, "elaboration"], [1622, 1641, 1641, 1691, "elaboration"], [1641, 1646, 1646, 1650, "purpose"], [1641, 1650, 1650, 1655, "elaboration"], [1641, 1655, 1655, 1691, "elaboration"], [1655, 1660, 1660, 1675, "elaboration"], [1655, 1675, 1675, 1691, "elaboration"], [1675, 1681, 1681, 1691, "elaboration"]], "tokens": ["The", "paper", "presents", "a", "framework", ",", "called", "ChoiceNet", ",", "for", "learning", "when", "the", "supervision", "outputs", "-LRB-", "e.g.", ",", "labels", "-RRB-", "are", "corrupted", "by", "noise", ".", "The", "method", "relies", "on", "estimating", "the", "correlation", "between", "the", "training", "data", "distribution", "and", "a", "target", "distribution", ",", "where", "training", "data", "distribution", "is", "assumed", "to", "be", "a", "mixture", "of", "that", "target", "distribution", "and", "other", "unknown", "distributions", ".", "The", "paper", "also", "presents", "some", "compelling", "results", "on", "synthetic", "and", "real", "datasets", ",", "for", "both", "regression", "and", "classification", "problems", ".", "The", "proposed", "idea", "builds", "on", "top", "of", "previously", "published", "work", "on", "Mixture", "Density", "Networks", "-LRB-", "MDNs", "-RRB-", "and", "Mixup", "-LRB-", "Zhang", "et", "al", ",", "2017", "-RRB-", ".", "The", "main", "difference", "is", "the", "MDN", "are", "modified", "to", "construct", "the", "Mixture", "of", "Correlated", "Density", "Network", "-LRB-", "MCDN", "-RRB-", "block", ",", "that", "forms", "the", "main", "component", "of", "ChoiceNets", ".", "I", "like", "the", "overall", "direction", "and", "idea", "of", "modelling", "correlation", "between", "the", "target", "distribution", "and", "the", "data", "distribution", "to", "deal", "with", "noisy", "labels", ".", "The", "results", "are", "also", "compelling", "and", "I", "thus", "lean", "towards", "accepting", "this", "paper", ".", "My", "decision", "on", "TICKTICK", "marginal", "accept", "''", "is", "based", "primarily", "on", "my", "unfamiliarity", "with", "this", "specific", "area", "and", "that", "some", "parts", "of", "the", "paper", "are", "not", "very", "easy", "or", "intuitive", "to", "read", "through", ".", "==", "Related", "Work", "==", "I", "like", "the", "related", "work", "discussion", ",", "but", "would", "emphasize", "more", "the", "connection", "to", "MDNs", "and", "to", "Mixup", ".", "Only", "one", "sentence", "is", "mentioned", "about", "Mixup", "but", "reading", "through", "the", "abstract", "and", "the", "introduction", "that", "is", "the", "first", "paper", "that", "came", "to", "my", "mind", "and", "thus", "I", "believe", "that", "it", "may", "deserve", "a", "bit", "more", "discussion", ".", "Also", ",", "there", "are", "a", "couple", "more", "papers", "that", "felt", "relevant", "to", "this", "work", "but", "are", "not", "mentioned", ":", "-", "Estimating", "Accuracy", "from", "Unlabeled", "Data", ":", "A", "Bayesian", "Approach", ",", "Platanios", "et", "al.", ",", "ICML", "2016", ".", "I", "believe", "this", "is", "related", "in", "how", "noisy", "labels", "are", "modeled", "-LRB-", "i.e.", ",", "section", "3", "in", "the", "reviewed", "paper", "-RRB-", "and", "in", "the", "idea", "of", "correlation/consistency", "as", "a", "means", "to", "detect", "errors", ".", "There", "are", "couple", "more", "papers", "in", "this", "line", "of", "work", "that", "may", "be", "relevant", ".", "-", "ADIOS", ":", "Architectures", "Deep", "In", "Output", "Space", ",", "Al-Shedivat", "et", "al.", ",", "ICML", "2016", ".", "I", "believe", "this", "is", "related", "in", "learning", "some", "structure", "in", "the", "output", "space", ",", "even", "though", "not", "directly", "dealing", "with", "noisy", "labels", ".", "==", "Method", "==", "I", "believe", "the", "methods", "section", "could", "have", "been", "written", "in", "a", "more", "clear/easy-to-follow", "way", ",", "but", "this", "may", "also", "be", "due", "to", "my", "unfamiliarity", "with", "this", "area", ".", "Figure", "1", "is", "hard", "to", "parse", "and", "does", "not", "really", "offer", "much", "more", "than", "section", "3.2", "currently", "does", ".", "If", "the", "figure", "is", "improved", "with", "some", "more", "text/labels", "on", "boxes", "rather", "than", "plain", "equations", ",", "it", "may", "go", "a", "long", "way", "in", "making", "the", "methods", "section", "easier", "to", "follow", ".", "I", "would", "also", "point", "out", "MCDN", "as", "the", "key", "contribution", "of", "this", "paper", "as", "ChoiceNet", "is", "just", "any", "base", "network", "with", "an", "MCDN", "block", "stacked", "on", "top", "of", "this", ".", "Thus", ",", "I", "believe", "this", "should", "be", "emphasized", "more", "to", "make", "your", "key", "contribution", "clear", ".", "==", "Experiments", "==", "The", "experiments", "are", "nicely", "presented", "and", "are", "quite", "thorough", ".", "A", "couple", "minor", "comments", "I", "have", "are", ":", "-", "It", "would", "be", "nice", "to", "run", "regression", "experiments", "for", "bigger", "real-world", "datasets", ",", "as", "the", "ones", "used", "seem", "to", "be", "quite", "small", ".", "-", "I", "am", "a", "bit", "confused", "at", "the", "fact", "that", "in", "table", "3", "you", "compare", "your", "method", "to", "mixup", "and", "in", "table", "4", "you", "also", "show", "results", "when", "using", "both", "your", "method", "and", "mixup", "combined", ".", "Up", "until", "that", "point", "I", "thought", "that", "mixup", "was", "posed", "as", "an", "alternative", "method", ",", "but", "here", "it", "seems", "it", "'s", "quite", "orthogonal", "and", "can", "be", "used", "together", ",", "which", "I", "think", "makes", "sense", ",", "but", "would", "be", "good", "to", "clarify", ".", "Also", ",", "given", "that", "you", "show", "combined", "results", "in", "table", "4", ",", "why", "not", "also", "perform", "exactly", "the", "same", "analysis", "for", "table", "3", "and", "also", "show", "numbers", "for", "CN", "+", "Mixup", "?", "It", "would", "also", "be", "nice", "to", "use", "the", "same", "naming", "scheme", "for", "both", "tables", ".", "I", "would", "use", ":", "ConvNet", ",", "ConvNet", "+", "CN", ",", "ConvNet", "+", "CN", "+", "Mixup", ",", "and", "the", "same", "with", "WRN", "for", "table", "4", ".", "This", "would", "make", "the", "tables", "easier", "to", "read", "because", "currently", "the", "first", "thing", "that", "comes", "to", "mind", "is", "what", "may", "be", "different", "between", "the", "two", "setups", "given", "that", "they", "are", "presented", "side-by-side", "but", "use", "different", "naming", "conventions", ".", "One", "question", "that", "comes", "to", "mind", "is", "that", "you", "make", "certain", "assumptions", "on", "the", "kinds", "of", "noise", "your", "model", "can", "capture", ",", "so", "are", "there", "any", "cases", "where", "you", "have", "good", "intuition", "as", "to", "why", "your", "model", "may", "fail", "?", "It", "would", "be", "good", "to", "present", "a", "short", "discussion", "on", "this", "to", "help", "readers", "understand", "whether", "they", "can", "benefit", "by", "using", "your", "model", "or", "not", ".", "We", "conducted", "additional", "experiments", "based", "on", "other", "reviews", "where", "we", "observe", "that", "the", "proposed", "method", "show", "superior", "performance", "to", "symmetric", "noises", "but", "vulnerable", "to", "asymmetric", "noise", "on", "CIFAR-10", "following", "the", "settings", "in", "-LSB-", "3", "-RSB-", ".", "We", "implement", "the", "9-layer", "CNN", "architecture", "following", "VAT", "-LSB-", "5", "-RSB-", "and", "Co-teaching", "-LSB-", "3", "-RSB-", "to", "fairly", "evaluate", "the", "performance", "of", "CIFAR10", "experiments", "with", "both", "symmetric", "and", "asymmetric", "noise", "settings", ":", "Pair-45", "%", ",", "Symmetry-50", "%", ",", "and", "Symmetry-20", "%", ",", "using", "the", "authors", "'", "implementations", "available", "on", "github", ".", "Pair-45", "%", "flips", "45", "%", "of", "each", "label", "to", "the", "next", "label", ".", "For", "example", ",", "randomly", "flipping", "45", "%", "of", "label", "1", "to", "label", "2", "and", "label", "2", "to", "label3", ".", "On", "the", "other", "hand", ",", "Symmetriy-50", "%", "randomly", "assigns", "50", "%", "of", "each", "label", "to", "other", "labels", "uniformly", ".", "For", "example", ",", "Symmetriy-50", "%", "randomly", "flips", "50", "%", "the", "labels", "of", "instances", "whose", "original", "label", "is", "1", "to", "a", "random", "label", "sampled", "from", "2-10", ".", "We", "set", "other", "configurations", "such", "as", "the", "network", "topology", "and", "an", "activation", "functions", "to", "be", "the", "same", "as", "-LSB-", "3", "-RSB-", ".", "-LRB-", "Single-run", ",", "last", "validation", "accuracy", "-RRB-", "Pair-45", "%", "sym-50", "%", "sym-20", "%", "------------------------------------------", "ChoiceNet", "70.3", "%", "85.2", "%", "91.0", "%", "------------------------------------------", "MentorNet", "58.14", "%", "71.10", "%", "80.76", "%", "Co-teaching", "72.62", "%", "74.02", "%", "82.32", "%", "F-correction", "6.61", "%", "59.83", "%", "84.55", "%", "The", "results", "of", "MentorNet", "-LSB-", "6", "-RSB-", ",", "Co-teaching", "-LSB-", "3", "-RSB-", ",", "and", "F-correction", "-LSB-", "7", "-RSB-", "are", "copied", "from", "-LSB-", "3", "-RSB-", ".", "While", "our", "proposed", "method", "outperforms", "all", "compared", "methods", "on", "symmetric", "noise", "settings", ",", "it", "shows", "inferior", "performances", "to", "Co-teaching", ".", "This", "shows", "the", "weakness", "of", "the", "proposed", "method", ".", "In", "other", "words", ",", "our", "mixture", "distribution", "failed", "to", "correctly", "infer", "the", "dominant", "distribution", "which", "shows", "the", "weakness", "of", "the", "mixture-based", "method", ".", "However", ",", "we", "would", "like", "to", "note", "that", "Co-teaching", "-LSB-", "5", "-RSB-", "is", "complementary", "to", "our", "method", "where", "one", "can", "combine", "these", "two", "methods", "by", "using", "two", "ChoiceNets", "and", "update", "each", "network", "using", "Co-teaching", ".", "*", "We", "also", "conducted", "additional", "experiments", "to", "show", "the", "strength", "of", "the", "proposed", "method", ".", "a", "-RRB-", ".", "More", "baselines", "to", "current", "CIFAR-10", "experiments", ":", "We", "implemented", "MentorNet", "-LSB-", "6", "-RSB-", "and", "VAT", "-LSB-", "5", "-RSB-", "to", "better", "evaluate", "the", "performance", "of", "the", "proposed", "method", "on", "current", "CIFAR-10", "setting", ".", "corruption", "rate", "20", "%", "50", "%", "80", "%", "----------------------------------------------", "MentorNet", "PD", "64.0", "%", "49.0", "%", "21.4", "%", "MentorNet", "DD", "62.0", "%", "43.1", "%", "21.8", "%", "VAT", "82.0", "%", "71.6", "%", "16.9", "%", "----------------------------------------------", "CN+M", "ixup", "92.3", "%", "87.9", "%", "75.4", "%", "b", "-RRB-", "Natural", "language", "processing", "experiments", ":", "We", "used", "a", "Large", "Movie", "Review", "Dataset", "consist", "of", "25,000", "movie", "reviews", "for", "training", "and", "25,000", "reviews", "for", "testing", ".", "Each", "movie", "review", "-LRB-", "sentences", "-RRB-", "is", "mapped", "to", "a", "128-dimensional", "feature", "vector", "using", "feed-forward", "Neural-Net", "Language", "Models", "-LSB-", "8", "-RSB-", "and", "we", "tested", "the", "robustness", "of", "the", "proposed", "method", ",", "mix-up", ",", "and", "naive", "MLP", "baseline", "by", "randomly", "flipping", "the", "labels", ".", "random", "flip", "rate", "0", "%", "10", "%", "20", "%", "30", "%", "40", "%", "-------------------------------------------------------------", "ChoiceNet", "79.43", "%", "79.50", "%", "78.66", "%", "77.10", "%", "73.98", "%", "Mix-up", "79.77", "%", "78.73", "%", "77.58", "%", "75.85", "%", "69.63", "%", "Baseline", "-LRB-", "MLP", "-RRB-", "79.04", "%", "77.88", "%", "75.70", "%", "69.05", "%", "62.83", "%", "VAT", "76.40", "%", "72.50", "%", "69.20", "%", "65.20", "%", "58.30", "%", "Similar", "to", "regression", "experiments", ",", "ChoiceNet", "shows", "the", "superior", "performance", "in", "the", "presence", "of", "outliers", "where", "we", "observe", "that", "the", "proposed", "method", "can", "be", "used", "for", "NLP", "tasks", "as", "well", ".", "-LSB-", "1", "-RSB-", "V.", "Belagiannis", ",", "C.", "Rupprecht", ",", "G", ",", "Carneiro", ",", "N.", "Navab", ",", "TICKTICK", "Robust", "Optimization", "for", "Deep", "Regression", "''", ",", "ICCV", ",", "2015", "-LSB-", "2", "-RSB-", "H.", "Zhang", ",", "M.", "Cisse", ",", "Y.", "Dauphin", ",", "D.", "Lopez-Paz", ",", "TICKTICK", "mixup", ":", "Beyond", "Empirical", "Risk", "Minimization", "TICKTICK", ",", "ICLR", ",", "2018", ".", "-LSB-", "3", "-RSB-", "B.", "Han", ",", "Q.", "Yao", ",", "X.", "Yu", ",", "G.", "Niu", ",", "M.", "Xu", ",", "W.", "Hu", ",", "I.", "Tsang", ",", "M.", "Sugiyama", ",", "TICKTICK", "Co-teaching", ":", "Robust", "Training", "of", "Deep", "Neural", "Networks", "with", "Extremely", "Noisy", "Labels", "''", ",", "NIPS", ",", "2018", ".", "-LSB-", "4", "-RSB-", "Platanios", ",", "E.", "Antonios", ",", "A.", "Dubey", ",", "and", "T.", "Mitchell", ".", "TICKTICK", "Estimating", "accuracy", "from", "unlabeled", "data", ":", "A", "bayesian", "approach", ".", "''", "International", "Conference", "on", "Machine", "Learning", ".", "2016", ".", "-LSB-", "5", "-RSB-", "T.", "Miyato", ",", "S.", "Maeda", ",", "M.", "Koyama", ",", "and", "S.", "Ishii", ".", "Virtual", "adversarial", "training", ":", "A", "regularization", "method", "for", "supervised", "and", "semi-supervised", "learning", ".", "ICLR", ",", "2016", ".", "-LSB-", "6", "-RSB-", "L.", "Jiang", ",", "Z.", "Zhou", ",", "T.", "Leung", ",", "L.", "Li", ",", "and", "L.", "Fei-Fei", ".", "Mentornet", ":", "Learning", "data-driven", "curriculum", "for", "very", "deep", "neural", "networks", "on", "corrupted", "labels", ".", "In", "ICML", ",", "2018", ".", "-LSB-", "7", "-RSB-", "G.", "Patrini", ",", "A.", "Rozza", ",", "A.", "Menon", ",", "R.", "Nock", ",", "and", "L.", "Qu", ".", "Making", "deep", "neural", "networks", "robust", "to", "label", "noise", ":", "A", "loss", "correction", "approach", ".", "In", "CVPR", ",", "2017", ".", "-LSB-", "8", "-RSB-", "Y.", "Bengio", ",", "R.", "Ducharme", ",", "P.", "Vincent", ",", "C.", "Jauvin", ".", "A", "Neural", "Probabilistic", "Language", "Model", ".", "Journal", "of", "Machine", "Learning", "Research", ",", "3:1137-1155", ",", "2003", "."], "comment_id": "B1eqVtIKRm"}, {"rels": [[0, 5, 5, 23, "list"], [5, 23, 0, 5, "list"], [0, 23, 23, 647, "elaboration"], [23, 34, 34, 56, "list"], [34, 56, 23, 34, "list"], [23, 56, 56, 647, "elaboration"], [56, 67, 67, 73, "elaboration"], [67, 68, 68, 73, "elaboration"], [56, 73, 73, 647, "elaboration"], [73, 100, 100, 647, "list"], [77, 100, 73, 77, "attribution"], [77, 96, 96, 100, "attribution"], [100, 647, 73, 100, "list"], [100, 140, 140, 196, "elaboration"], [140, 154, 154, 196, "list"], [140, 147, 147, 154, "elaboration"], [154, 196, 140, 154, "list"], [154, 163, 163, 196, "list"], [163, 196, 154, 163, "list"], [100, 196, 196, 647, "elaboration"], [196, 201, 201, 203, "elaboration"], [196, 203, 203, 647, "example"], [203, 223, 223, 647, "list"], [223, 647, 203, 223, "list"], [223, 225, 225, 647, "list"], [225, 647, 223, 225, "list"], [232, 260, 225, 232, "attribution"], [237, 260, 232, 237, "attribution"], [237, 241, 241, 260, "circumstance"], [241, 251, 251, 259, "elaboration"], [241, 259, 259, 260, "elaboration"], [225, 260, 260, 647, "elaboration"], [260, 280, 280, 647, "list"], [280, 647, 260, 280, "list"], [280, 282, 282, 647, "elaboration"], [282, 312, 312, 647, "list"], [298, 312, 282, 298, "attribution"], [282, 297, 297, 298, "elaboration"], [312, 647, 282, 312, "list"], [312, 315, 315, 324, "purpose"], [312, 324, 324, 456, "explanation"], [324, 335, 335, 353, "list"], [335, 353, 324, 335, "list"], [335, 339, 339, 353, "elaboration"], [324, 353, 353, 456, "elaboration"], [353, 362, 362, 389, "elaboration"], [353, 389, 389, 456, "elaboration"], [389, 434, 434, 456, "elaboration"], [441, 456, 434, 441, "attribution"], [312, 456, 456, 647, "elaboration"], [456, 458, 458, 492, "purpose"], [458, 471, 471, 492, "purpose"], [456, 492, 492, 647, "elaboration"], [492, 500, 500, 530, "elaboration"], [500, 522, 522, 530, "elaboration"], [522, 526, 526, 530, "elaboration"], [492, 530, 530, 647, "elaboration"], [530, 551, 551, 647, "contrast"], [530, 536, 536, 551, "purpose"], [536, 548, 548, 551, "elaboration"], [551, 647, 530, 551, "contrast"], [551, 559, 559, 567, "same_unit"], [551, 554, 554, 559, "elaboration"], [559, 567, 551, 559, "same_unit"], [559, 564, 564, 567, "elaboration"], [551, 567, 567, 647, "elaboration"], [567, 586, 586, 647, "list"], [568, 586, 567, 568, "attribution"], [586, 647, 567, 586, "list"], [587, 593, 586, 587, "attribution"], [588, 593, 587, 588, "attribution"], [586, 593, 593, 647, "elaboration"], [593, 598, 598, 608, "elaboration"], [593, 608, 608, 626, "elaboration"], [608, 609, 609, 626, "elaboration"], [609, 617, 617, 626, "elaboration"], [617, 625, 625, 626, "elaboration"], [593, 626, 626, 647, "elaboration"], [626, 635, 635, 647, "elaboration"], [639, 647, 635, 639, "attribution"], [639, 643, 643, 647, "elaboration"]], "tokens": ["The", "authors", "made", "several", "claims", "and", "provide", "suggestions", "on", "training", "binary", "networks", ",", "however", ",", "they", "are", "not", "proved", "or", "theoretically", "analyzed", ".", "The", "empirical", "verification", "of", "the", "proposed", "hypothesis", "was", "viewed", "as", "weak", "as", "the", "only", "two", "datasets", "used", "are", "small", "datasets", "MNIST", "and", "CIFAR-10", ",", "and", "the", "used", "network", "architectures", "are", "also", "limited", ".", "Much", "more", "rigorous", "and", "thorough", "testing", "is", "required", "for", "an", "empirical", "paper", "which", "proposes", "new", "claims", ".", "Take", "the", "first", "claim", "TICKTICK", "end-to-end", "training", "of", "binary", "networks", "crucially", "relies", "on", "the", "optimiser", "taking", "advantage", "of", "second", "moment", "gradient", "estimates", "''", "as", "an", "example", ".", "As", "it", "is", "known", "that", "choice", "of", "optimizer", "is", "highly", "dependent", "on", "the", "specific", "dataset", "and", "network", "structure", ",", "it", "is", "not", "convincing", "to", "jump", "to", "this", "conclusion", "using", "the", "observations", "on", "two", "small", "datasets", "and", "limited", "network", "architectures", ".", "E.g", ",", "many", "binarization", "papers", "use", "momentum", "for", "ImageNet", "dataset", "with", "residual", "networks", ".", "Does", "Adam", "also", "outperforms", "momentum", "in", "this", "case", "?", "Similarly", ",", "it", "is", "also", "hard", "for", "me", "to", "judge", "whether", "the", "other", "conclusions", "made", "about", "weight/gradient", "clipping", ",", "the", "momentum", "in", "batch", "normalization", "and", "learning", "rate", ",", "are", "correct", "or", "not", ".", "Some", "minor", "issues", "are", ":", "1", ".", "In", "Figure", "4", ",", "different", "methods", "are", "not", "run", "to", "convergence", ",", "and", "the", "comparison", "may", "not", "be", "fair", ".", "2", ".", "The", "second", "paragraph", "in", "section", "4", ":", "TICKTICK", "It", "can", "be", "seen", "that", "not", "clipping", "weights", "when", "learning", "rates", "are", "large", "can", "completely", "halt", "the", "optimisation", "-LRB-", "red", "curve", "in", "Figure", "5", "-RRB-", ".", "''", "However", ",", "in", "figure", "5", ",", "the", "red", "curve", "is", "TICKTICK", "Clipping", "gradients", "''", ",", "which", "one", "is", "correct", "?", "3", ".", "The", "authors", "propose", "a", "recipe", "for", "faster", "training", "of", "binary", "networks", ",", "is", "there", "experiments", "supporting", "that", "training", "networks", "with", "the", "proposed", "recipe", "is", "faster", "than", "the", "original", "counterpart", "?", "We", "would", "like", "to", "thank", "the", "reviewer", "for", "the", "constructive", "comments", ".", "Our", "aim", "in", "this", "paper", "is", "to", "provide", "useful", "empirical", "observations", "and", "generate", "possible", "hypotheses", "that", "explain", "them", ",", "rather", "than", "to", "make", "new", "claims", "or", "theoretical", "analysis", ".", "It", "is", "true", "that", "we", "have", "provided", "some", "hypotheses", "about", "what", "might", "be", "going", "on", ",", "but", "at", "the", "end", "of", "the", "day", ",", "it", "is", "difficult", "to", "prove", "such", "new", "claims", "through", "empirical", "research", ".", "We", "did", "not", "aim", "to", "present", "conclusive", "observations", "for", "TICKTICK", "X", "is", "necessary", "for", "Y", "''", "but", "rather", "give", "empirical", "support", "that", "TICKTICK", "X", "seems", "to", "be", "tightly", "connected", "to", "Y", "''", ",", "i.e.", "generating", "hypothesis", "to", "be", "validated", "in", "future", "theoretical", "research", ".", ">", "More", "datasets", "and", "architectures", "We", "do", "agree", "that", "in", "this", "line", "of", "work", "would", "benefit", "from", "more", "datasets", "and", "model", "architectures", ".", "We", "intended", "to", "repeat", "our", "experiments", "with", "larger", "datasets", ",", "but", "a", "hyperparameter", "search", "similar", "to", "what", "we", "have", "done", "for", "smaller", "standard", "datasets", "is", "computationally", "difficult", "on", "much", "larger", "datasets", "such", "as", "ImageNet", "dataset", ".", "However", ",", "we", "have", "now", "updated", "the", "paper", "to", "include", "results", "on", "ImageNet", "for", "Section", "4", "of", "the", "paper", ">", "Convergence", "in", "Figure", "4", "This", "touches", "on", "the", "same", "points", "raised", "by", "another", "reviewer", "regarding", "early", "stopping", ".", "In", "our", "experiments", ",", "we", "tried", "to", "give", "the", "training", "phase", "in", "all", "experiments", "more", "than", "enough", "time", "to", "converge", ",", "but", "some", "optimizers", "-LRB-", "like", "vanilla", "SGD", "-RRB-", "simply", "fail", "in", "many", "scenarios", "to", "converge", ".", ">", "In", "figure", "5", ",", "the", "red", "curve", "is", "TICKTICK", "Clipping", "gradients", "''", ",", "which", "one", "is", "correct", "?", "Thank", "you", "for", "reporting", "this", "error", ".", "We", "have", "updated", "the", "paper", "to", "correct", "the", "order", "of", "items", "in", "the", "legend", ".", ">", "Baselines", "for", "training", "binary", "networks", "faster", "We", "believe", "these", "results", "are", "already", "included", "in", "Table", "5", "where", "TICKTICK", "end-to-end", "''", "denotes", "the", "original", "counterpart", "experiments", ".", "Do", "let", "us", "know", "if", "you", "have", "something", "different", "in", "mind", "."], "comment_id": "B1eVJiKyCX"}, {"rels": [[0, 338, 338, 1324, "topic"], [0, 5, 5, 15, "elaboration"], [5, 9, 9, 15, "elaboration"], [0, 15, 15, 338, "elaboration"], [15, 23, 23, 53, "elaboration"], [23, 35, 35, 53, "elaboration"], [35, 40, 40, 53, "elaboration"], [15, 53, 53, 151, "elaboration"], [53, 59, 59, 85, "elaboration"], [59, 62, 62, 85, "elaboration"], [53, 85, 85, 151, "elaboration"], [85, 92, 92, 105, "purpose"], [85, 105, 105, 151, "elaboration"], [105, 115, 115, 151, "elaboration"], [15, 151, 151, 338, "elaboration"], [151, 167, 167, 188, "elaboration"], [167, 172, 172, 188, "elaboration"], [151, 188, 188, 338, "elaboration"], [188, 198, 198, 209, "purpose"], [188, 209, 209, 304, "elaboration"], [209, 217, 217, 243, "elaboration"], [217, 225, 225, 243, "elaboration"], [209, 243, 243, 304, "elaboration"], [243, 244, 244, 286, "elaboration"], [243, 286, 286, 304, "elaboration"], [286, 288, 288, 304, "elaboration"], [288, 294, 294, 304, "list"], [294, 304, 288, 294, "list"], [188, 304, 304, 338, "elaboration"], [304, 309, 309, 324, "elaboration"], [304, 324, 324, 338, "elaboration"], [338, 1324, 0, 338, "topic"], [338, 417, 417, 1324, "list"], [338, 352, 352, 417, "elaboration"], [352, 376, 376, 417, "list"], [352, 368, 368, 369, "elaboration"], [352, 369, 369, 376, "purpose"], [376, 417, 352, 376, "list"], [376, 382, 382, 393, "purpose"], [382, 385, 385, 393, "elaboration"], [376, 393, 393, 417, "elaboration"], [417, 1324, 338, 417, "list"], [417, 428, 428, 1324, "list"], [428, 1324, 417, 428, "list"], [428, 440, 440, 1324, "list"], [440, 1324, 428, 440, "list"], [440, 452, 452, 1324, "list"], [452, 1324, 440, 452, "list"], [452, 479, 479, 1324, "elaboration"], [479, 505, 505, 1324, "list"], [479, 500, 500, 505, "elaboration"], [505, 1324, 479, 505, "list"], [505, 526, 526, 1324, "list"], [505, 509, 509, 526, "purpose"], [509, 516, 516, 526, "elaboration"], [519, 526, 516, 519, "attribution"], [526, 1324, 505, 526, "list"], [526, 538, 538, 563, "list"], [538, 563, 526, 538, "list"], [541, 563, 538, 541, "attribution"], [541, 547, 547, 563, "list"], [547, 563, 541, 547, "list"], [547, 552, 552, 563, "purpose"], [526, 563, 563, 1324, "example"], [563, 579, 579, 1324, "list"], [579, 1324, 563, 579, "list"], [579, 589, 589, 1324, "list"], [589, 1324, 579, 589, "list"], [589, 610, 610, 1324, "question"], [610, 1324, 589, 610, "question"], [610, 648, 648, 1324, "list"], [610, 616, 616, 648, "same_unit"], [610, 615, 615, 616, "elaboration"], [616, 648, 610, 616, "same_unit"], [627, 648, 616, 627, "attribution"], [627, 630, 630, 635, "elaboration"], [627, 635, 635, 648, "elaboration"], [648, 1324, 610, 648, "list"], [648, 973, 973, 1324, "topic"], [648, 650, 650, 973, "elaboration"], [650, 656, 656, 660, "elaboration"], [650, 660, 660, 973, "elaboration"], [660, 679, 679, 973, "elaboration"], [679, 692, 692, 973, "elaboration"], [692, 706, 706, 731, "elaboration"], [706, 717, 717, 731, "same_unit"], [717, 731, 706, 717, "same_unit"], [723, 731, 717, 723, "concession"], [692, 731, 731, 769, "elaboration"], [731, 748, 748, 769, "elaboration"], [692, 769, 769, 973, "elaboration"], [769, 771, 771, 973, "list"], [771, 973, 769, 771, "list"], [774, 783, 771, 774, "attribution"], [771, 783, 783, 973, "elaboration"], [783, 793, 793, 797, "circumstance"], [783, 797, 797, 973, "elaboration"], [797, 802, 802, 973, "elaboration"], [802, 818, 818, 973, "elaboration"], [818, 832, 832, 852, "same_unit"], [818, 821, 821, 832, "elaboration"], [832, 852, 818, 832, "same_unit"], [832, 835, 835, 852, "elaboration"], [818, 852, 852, 973, "elaboration"], [852, 866, 866, 973, "elaboration"], [866, 871, 871, 882, "elaboration"], [866, 882, 882, 973, "elaboration"], [882, 908, 908, 973, "elaboration"], [908, 911, 911, 922, "elaboration"], [911, 913, 913, 922, "elaboration"], [908, 922, 922, 973, "elaboration"], [922, 937, 937, 948, "list"], [922, 931, 931, 937, "purpose"], [937, 948, 922, 937, "list"], [922, 948, 948, 973, "circumstance"], [973, 1324, 648, 973, "topic"], [973, 1075, 1075, 1324, "topic"], [978, 1009, 973, 978, "attribution"], [997, 1009, 978, 997, "attribution"], [973, 1009, 1009, 1075, "elaboration"], [1009, 1011, 1011, 1032, "elaboration"], [1015, 1032, 1011, 1015, "attribution"], [1015, 1020, 1020, 1032, "same_unit"], [1020, 1032, 1015, 1020, "same_unit"], [1009, 1032, 1032, 1075, "elaboration"], [1032, 1043, 1043, 1053, "same_unit"], [1032, 1042, 1042, 1043, "elaboration"], [1043, 1053, 1032, 1043, "same_unit"], [1032, 1053, 1053, 1075, "elaboration"], [1053, 1067, 1067, 1075, "elaboration"], [1075, 1324, 973, 1075, "topic"], [1075, 1078, 1078, 1324, "textualorganization"], [1078, 1324, 1075, 1078, "textualorganization"], [1078, 1100, 1100, 1324, "list"], [1088, 1100, 1078, 1088, "attribution"], [1088, 1091, 1091, 1100, "elaboration"], [1091, 1095, 1095, 1100, "elaboration"], [1100, 1324, 1078, 1100, "list"], [1100, 1103, 1103, 1324, "list"], [1103, 1324, 1100, 1103, "list"], [1103, 1105, 1105, 1324, "textualorganization"], [1105, 1324, 1103, 1105, "textualorganization"], [1105, 1123, 1123, 1324, "list"], [1105, 1115, 1115, 1123, "elaboration"], [1123, 1324, 1105, 1123, "list"], [1123, 1125, 1125, 1148, "example"], [1125, 1135, 1135, 1148, "elaboration"], [1135, 1141, 1141, 1148, "purpose"], [1141, 1145, 1145, 1148, "elaboration"], [1123, 1148, 1148, 1324, "elaboration"], [1148, 1156, 1156, 1167, "list"], [1156, 1167, 1148, 1156, "list"], [1148, 1167, 1167, 1324, "elaboration"], [1167, 1178, 1178, 1324, "list"], [1178, 1324, 1167, 1178, "list"], [1178, 1181, 1181, 1196, "purpose"], [1178, 1196, 1196, 1210, "elaboration"], [1178, 1210, 1210, 1324, "elaboration"], [1210, 1231, 1231, 1324, "list"], [1214, 1231, 1210, 1214, "attribution"], [1218, 1231, 1214, 1218, "attribution"], [1231, 1324, 1210, 1231, "list"], [1237, 1242, 1231, 1237, "attribution"], [1231, 1242, 1242, 1255, "elaboration"], [1242, 1250, 1250, 1255, "elaboration"], [1231, 1255, 1255, 1324, "elaboration"], [1255, 1278, 1278, 1294, "elaboration"], [1278, 1289, 1289, 1294, "elaboration"], [1255, 1294, 1294, 1324, "elaboration"], [1294, 1322, 1322, 1324, "list"], [1294, 1307, 1307, 1322, "purpose"], [1311, 1322, 1307, 1311, "attribution"], [1311, 1317, 1317, 1322, "elaboration"], [1322, 1324, 1294, 1322, "list"], [1322, 1323, 1323, 1324, "elaboration"]], "tokens": ["This", "paper", "presents", "a", "methodology", "to", "infer", "shape", "programs", "that", "can", "describe", "3D", "objects", ".", "The", "key", "intuition", "of", "the", "shape", "programs", "is", "to", "integrate", "bottom-up", "low-level", "feature", "recognition", "with", "symbolic", "high-level", "program", "structure", ",", "which", "allows", "the", "shape", "programs", "to", "capture", "both", "high-level", "structure", "and", "the", "low-level", "geometry", "of", "the", "shapes", ".", "The", "paper", "proposes", "a", "domain-specific", "language", "for", "3D", "shapes", "that", "consists", "of", "TICKTICK", "For", "''", "loops", "for", "capturing", "high-level", "regularity", ",", "and", "associates", "objects", "with", "both", "their", "geometric", "and", "semantic", "attributes", ".", "It", "then", "proposes", "an", "end-to-end", "differentiable", "architecture", "to", "learn", "such", "3D", "programs", "from", "shapes", "using", "an", "interesting", "self-supervised", "mechanism", ".", "The", "neural", "program", "generator", "proposes", "a", "program", "in", "the", "DSL", "that", "is", "executed", "by", "a", "neural", "program", "execution", "module", "to", "render", "the", "corresponding", "output", "shape", ",", "which", "is", "then", "compared", "with", "the", "original", "shape", "and", "the", "difference", "loss", "is", "back-propagated", "to", "improve", "the", "program", "distribution", ".", "The", "technique", "is", "evaluated", "on", "both", "synthetic", "and", "ShapeNet", "tasks", ",", "and", "leads", "to", "significant", "improvements", "compared", "to", "Tulsiani", "et", "al.", "that", "embed", "a", "prior", "structure", "on", "learning", "shape", "representations", "as", "a", "composition", "of", "primitive", "abstractions", ".", "In", "addition", ",", "the", "technique", "is", "also", "paired", "with", "MarrNet", "to", "allow", "for", "a", "better", "3D", "reconstruction", "from", "2D", "images", ".", "Overall", ",", "this", "paper", "presents", "an", "elegant", "idea", "to", "describe", "3D", "shapes", "as", "a", "DSL", "program", "that", "captures", "both", "geometric", "and", "spatial", "abstractions", ",", "and", "at", "the", "same", "time", "captures", "regularities", "using", "loops", ".", "CSGNet", "-LSB-", "Sharma", "et", "al.", "2018", "-RSB-", "also", "uses", "programs", "to", "describe", "2D", "and", "3D", "shapes", ",", "but", "the", "DSL", "used", "here", "is", "richer", "as", "it", "captures", "more", "high-level", "regularities", "using", "loops", "and", "also", "semantic", "relationships", "such", "as", "top", ",", "support", "etc.", ".", "The", "idea", "of", "training", "a", "neural", "program", "executor", "and", "using", "it", "for", "self-supervised", "training", "is", "quite", "elegant", ".", "I", "also", "liked", "the", "idea", "of", "guided", "adaption", "to", "make", "the", "program", "generator", "generalize", "beyond", "the", "synthetic", "template", "programs", ".", "Finally", ",", "the", "results", "show", "impressive", "improvements", "and", "generalization", "capability", "of", "the", "model", ".", "Can", "the", "authors", "comment", "on", "some", "notion", "of", "completeness", "of", "the", "proposed", "DSL", "?", "In", "other", "words", ",", "is", "this", "the", "only", "set", "of", "operators", ",", "shapes", ",", "and", "semantics", "needed", "to", "represent", "all", "of", "ShapeNet", "objects", "?", "Also", ",", "it", "might", "be", "interesting", "to", "comment", "more", "on", "how", "this", "particular", "DSL", "was", "derived", ".", "Some", "of", "the", "semantics", "operator", "such", "as", "TICKTICK", "Support", "''", ",", "TICKTICK", "Locker", "''", ",", "etc.", "look", "overly", "specific", "to", "chair", "and", "tables", ".", "Is", "there", "a", "way", "to", "possibly", "learn", "such", "abstractions", "automatically", "?", "What", "is", "the", "total", "search", "space", "of", "programs", "in", "this", "DSL", "?", "How", "would", "a", "naive", "random", "search", "perform", "in", "this", "synthesis", "task", "?", "I", "also", "particularly", "liked", "the", "decomposition", "of", "programs", "into", "draw", "and", "compound", "statements", ",", "and", "the", "corresponding", "program", "generator", "decomposition", "into", "2", "steps", "BlockLSTM", "and", "StepLSTM", ".", "At", "inference", "time", ",", "does", "the", "model", "use", "some", "form", "of", "beam", "search", "to", "sample", "block", "programs", "or", "are", "the", "results", "corresponding", "to", "top-1", "prediction", "?", "Would", "it", "be", "possible", "to", "compare", "the", "results", "to", "the", "technique", "presented", "in", "CSGNet", "-LSB-", "Sharma", "et", "al.", "2018", "-RSB-", "?", "There", "are", "some", "key", "differences", "in", "terms", "of", "using", "lower-level", "DSL", "primitives", "and", "using", "REINFORCE", "for", "training", "the", "program", "generator", ",", "but", "it", "would", "be", "good", "to", "measure", "how", "well", "having", "higher-level", "primitives", "improve", "the", "results", ".", "I", "presume", "the", "neural", "program", "executor", "module", "was", "trained", "using", "a", "manually-written", "shape", "program", "interpreter", ".", "How", "difficult", "is", "it", "to", "write", "such", "an", "interpreter", "?", "Also", ",", "how", "easy/difficult", "is", "to", "extend", "the", "DSL", "with", "new", "semantics", "operator", "and", "then", "write", "the", "corresponding", "interpreter", "extension", "?", "Minor", "typos", ":", "page", "3", ":", "consists", "a", "variable", "NN", "consists", "of", "a", "variable", "page", "5", ":", "We", "executes", "CD", "We", "execute", "page", "6", ":", "synthetica", "dataset", "CD", "synthetic", "dataset", "Thank", "you", "for", "the", "very", "constructive", "comments", ".", "1", ".", "DSL", "The", "current", "DSL", "is", "designed", "to", "represent", "furnitures", ".", "Representing", "all", "ShapeNet", "objects", "needs", "a", "richer", "set", "of", "primitives", ",", "e.g.", ",", "curved", "cylinders", "for", "mug", "handles", ".", "When", "we", "design", "such", "DSL", ",", "the", "main", "challenge", "is", "on", "semantics", ".", "For", "humans", ",", "some", "semantics", "are", "shared", "across", "different", "object", "categories", ",", "e.g.", ",", "TICKTICK", "top", "''", "can", "be", "shared", "by", "tables", "and", "bed", ",", "while", "some", "are", "just", "category-specific", ",", "TICKTICK", "armrest", "''", "is", "mainly", "for", "chairs", ".", "Following", "this", "spirit", ",", "we", "include", "both", "category-specific", "and", "shared", "semantics", "for", "the", "instantialization", "of", "furnitures", ".", "Learning", "a", "primitive", "library", "from", "data", "is", "a", "natural", "research", "direction", ",", "and", "we", "are", "working", "on", "it", "as", "follow-up", ".", "2", ".", "Baselines", "We", "agree", "that", "it", "'s", "important", "to", "add", "more", "baselines", ".", "In", "the", "revision", ",", "we", "will", "include", "comparisons", "with", "the", "following", "three", "algorithms", ":", "1", "-RRB-", "Nearest", "neighbors", ".", "For", "a", "given", "test", "shape", ",", "we", "search", "its", "nearest", "neighbor", "in", "the", "training", "set", ".", "2", "-RRB-", "CSGNet-original", "-LRB-", "the", "original", "model", "released", "by", "the", "authors", "of", "CSGNet", "-RRB-", "3", "-RRB-", "CSGNet-augmented", "-LRB-", "the", "augmented", "CSGNet", "model", "trained", "on", "our", "dataset", "with", "additional", "shape", "primitives", "we", "introduced", "-RRB-", ".", "Amortized", "inference", "is", "essential", "for", "our", "task", "due", "to", "its", "large", "search", "space", ".", "Our", "model", "takes", "5", "ms", "to", "infer", "a", "shape", "program", "with", "a", "Titan", "X", "GPU", ".", "There", "are", "two", "possible", "approaches", "for", "a", "structured", "search", "over", "the", "space", "of", "programs", ",", "both", "of", "which", "will", "be", "too", "slow", "for", "our", "task", ":", "1", "-RRB-", "Constraint", "solving", ":", "we", "would", "have", "to", "use", "an", "SMT", "solver", ".", "Ellis", "et", "al", "-LSB-", "1", "-RSB-", "used", "SMT", "solvers", "to", "infer", "2D", "graphics", "programs", ",", "and", "takes", "on", "the", "order", "of", "5-20", "minutes", "per", "program", ".", "As", "3D", "shapes", "have", "a", "much", "larger", "search", "space", ",", "such", "an", "approach", "would", "not", "be", "able", "to", "find", "a", "solution", "in", "reasonable", "time", ".", "2", "-RRB-", "Stochastic", "search", ":", "Here", "the", "problem", "would", "be", "at", "least", "as", "tough", "as", "doing", "inverse", "graphics", ",", "so", "we", "can", "safely", "assume", "that", "this", "would", "work", "no", "better", "than", "MCMC", "for", "inverse", "graphics", ".", "In", "Picture", "-LRB-", "Kulkarni", "et", "al.", "-LSB-", "2", "-RSB-", "-RRB-", ",", "their", "approach", "takes", "minutes", "for", "a", "2D", "image", "with", "simple", "contours", ".", "We", "have", "contacted", "the", "authors", "of", "these", "two", "papers", ",", "who", "confirmed", "our", "estimates", "of", "the", "efficiency", "of", "their", "methods", ".", "-LSB-", "1", "-RSB-", "Ellis", ",", "Kevin", ",", "Armando", "Solar-Lezama", ",", "and", "Josh", "Tenenbaum", ".", "TICKTICK", "Unsupervised", "learning", "by", "program", "synthesis", ".", "''", "NIPS", "2015", ".", "-LSB-", "2", "-RSB-", "Kulkarni", ",", "Tejas", "D.", ",", "et", "al.", "TICKTICK", "Picture", ":", "A", "probabilistic", "programming", "language", "for", "scene", "perception", ".", "''", "CVPR", "2015", ".", "3", ".", "Decomposition", "Thanks", "for", "the", "positive", "comment", "on", "the", "decomposition", ".", "The", "results", "just", "correspond", "to", "top-1", "predictions", ".", "4", ".", "Interpreter", "Our", "semantic", "operators", "correspond", "to", "simple", "geometric", "primitives", ".", "Therefore", ",", "it", "'s", "quite", "straightforward", "to", "write", "an", "interpreter", "for", "them", ".", "The", "programs", "in", "our", "DSL", "are", "tokenized", "vectors", "and", "can", "be", "directly", "feed", "into", "the", "neural", "program", "executor", ".", "Adding", "new", "semantic", "operator", "to", "the", "DSL", "is", "thus", "easy", ".", "We", "just", "need", "to", "re-train", "or", "finetune", "the", "current", "program", "executor", "with", "the", "new", "semantic", "operator", "included", ".", "We", "have", "also", "listed", "all", "other", "planned", "changes", "in", "our", "general", "response", "above", ".", "Please", "do", "n't", "hesitate", "to", "let", "us", "know", "for", "any", "additional", "comments", "on", "the", "paper", "or", "on", "the", "planned", "changes", ".", "Dear", "Reviewer", "2", ",", "Thanks", "again", "for", "your", "constructive", "comments", ".", "We", "have", "made", "substantial", "changes", "in", "the", "revision", "according", "to", "the", "reviews", ".", "In", "particular", ",", "we", "have", "compared", "our", "model", "with", "three", "additional", "baselines", ",", "including", "CSGNet", ",", "in", "Table", "2", "and", "Sec", "5.2", ".", "We", "'ve", "also", "discussed", "the", "design", "of", "DSL", "and", "search-based", "models", "-LRB-", "Sec", "6", "-RRB-", ".", "As", "the", "discussion", "period", "is", "about", "to", "end", ",", "please", "do", "n't", "hesitate", "to", "let", "us", "know", "if", "there", "are", "any", "additional", "clarifications", "that", "we", "can", "offer", ".", "Thanks", "!"], "comment_id": "B1eBI3bX1V"}, {"rels": [[0, 5, 5, 18, "purpose"], [5, 9, 9, 18, "elaboration"], [9, 13, 13, 18, "elaboration"], [0, 18, 18, 1797, "elaboration"], [18, 28, 28, 43, "list"], [28, 43, 18, 28, "list"], [28, 36, 36, 43, "list"], [36, 43, 28, 36, "list"], [36, 37, 37, 43, "elaboration"], [18, 43, 43, 1797, "elaboration"], [43, 58, 58, 1797, "textualorganization"], [43, 52, 52, 58, "elaboration"], [58, 1797, 43, 58, "textualorganization"], [58, 94, 94, 1797, "list"], [58, 72, 72, 94, "elaboration"], [72, 78, 78, 94, "list"], [78, 94, 72, 78, "list"], [78, 88, 88, 94, "list"], [88, 94, 78, 88, "list"], [94, 1797, 58, 94, "list"], [94, 108, 108, 1797, "list"], [94, 99, 99, 108, "purpose"], [108, 1797, 94, 108, "list"], [116, 128, 108, 116, "antithesis"], [116, 122, 122, 128, "elaboration"], [122, 125, 125, 128, "purpose"], [108, 128, 128, 173, "elaboration"], [128, 154, 154, 173, "elaboration"], [154, 168, 168, 173, "elaboration"], [108, 173, 173, 1797, "elaboration"], [173, 191, 191, 1797, "list"], [173, 179, 179, 191, "purpose"], [179, 184, 184, 191, "elaboration"], [191, 1797, 173, 191, "list"], [191, 200, 200, 219, "elaboration"], [201, 219, 200, 201, "attribution"], [191, 219, 219, 1797, "elaboration"], [221, 1797, 219, 221, "attribution"], [221, 237, 237, 1797, "textualorganization"], [237, 1797, 221, 237, "textualorganization"], [237, 243, 243, 266, "elaboration"], [243, 255, 255, 266, "same_unit"], [243, 249, 249, 255, "elaboration"], [255, 266, 243, 255, "same_unit"], [237, 266, 266, 1797, "elaboration"], [266, 296, 296, 1797, "list"], [266, 278, 278, 296, "elaboration"], [296, 1797, 266, 296, "list"], [296, 333, 333, 1797, "list"], [296, 330, 330, 333, "same_unit"], [296, 311, 311, 330, "elaboration"], [330, 333, 296, 330, "same_unit"], [333, 1797, 296, 333, "list"], [333, 340, 340, 1797, "textualorganization"], [333, 339, 339, 340, "elaboration"], [340, 1797, 333, 340, "textualorganization"], [340, 385, 385, 1797, "textualorganization"], [340, 364, 364, 385, "same_unit"], [340, 357, 357, 364, "elaboration"], [364, 385, 340, 364, "same_unit"], [385, 1797, 340, 385, "textualorganization"], [385, 424, 424, 429, "elaboration"], [385, 429, 429, 1797, "elaboration"], [429, 471, 471, 1797, "list"], [430, 471, 429, 430, "attribution"], [471, 1797, 429, 471, "list"], [471, 525, 525, 1797, "topic"], [471, 483, 483, 525, "elaboration"], [483, 489, 489, 525, "elaboration"], [525, 1797, 471, 525, "topic"], [565, 1797, 525, 565, "condition"], [525, 559, 559, 565, "elaboration"], [565, 602, 602, 1797, "list"], [565, 578, 578, 584, "purpose"], [565, 584, 584, 602, "elaboration"], [590, 602, 584, 590, "attribution"], [602, 1797, 565, 602, "list"], [602, 608, 608, 626, "purpose"], [608, 614, 614, 626, "elaboration"], [602, 626, 626, 1797, "circumstance"], [626, 630, 630, 648, "same_unit"], [630, 648, 626, 630, "same_unit"], [631, 648, 630, 631, "attribution"], [626, 648, 648, 1797, "elaboration"], [650, 665, 648, 650, "attribution"], [650, 657, 657, 665, "elaboration"], [648, 665, 665, 1797, "elaboration"], [693, 1797, 665, 693, "circumstance"], [674, 693, 665, 674, "attribution"], [675, 693, 674, 675, "attribution"], [684, 693, 675, 684, "condition"], [693, 709, 709, 1797, "elaboration"], [709, 727, 727, 735, "elaboration"], [709, 735, 735, 1797, "example"], [735, 754, 754, 1797, "textualorganization"], [739, 754, 735, 739, "attribution"], [739, 745, 745, 754, "list"], [745, 754, 739, 745, "list"], [754, 1797, 735, 754, "textualorganization"], [754, 769, 769, 1797, "list"], [754, 760, 760, 769, "elaboration"], [769, 1797, 754, 769, "list"], [769, 774, 774, 1797, "textualorganization"], [774, 1797, 769, 774, "textualorganization"], [774, 794, 794, 1797, "list"], [794, 1797, 774, 794, "list"], [794, 804, 804, 835, "elaboration"], [804, 827, 827, 835, "elaboration"], [794, 835, 835, 848, "elaboration"], [794, 848, 848, 1797, "elaboration"], [854, 871, 848, 854, "attribution"], [856, 871, 854, 856, "attribution"], [848, 871, 871, 1797, "elaboration"], [871, 874, 874, 888, "purpose"], [876, 888, 874, 876, "attribution"], [871, 888, 888, 909, "elaboration"], [888, 892, 892, 909, "circumstance"], [871, 909, 909, 1797, "elaboration"], [909, 913, 913, 1797, "textualorganization"], [913, 1797, 909, 913, "textualorganization"], [913, 934, 934, 1797, "list"], [934, 1797, 913, 934, "list"], [934, 967, 967, 981, "elaboration"], [934, 981, 981, 1016, "elaboration"], [981, 984, 984, 1016, "elaboration"], [984, 992, 992, 1016, "condition"], [999, 1016, 992, 999, "condition"], [999, 1001, 1001, 1016, "same_unit"], [1001, 1016, 999, 1001, "same_unit"], [934, 1016, 1016, 1797, "elaboration"], [1016, 1040, 1040, 1797, "topic"], [1016, 1026, 1026, 1040, "list"], [1026, 1040, 1016, 1026, "list"], [1026, 1027, 1027, 1040, "purpose"], [1027, 1033, 1033, 1040, "elaboration"], [1040, 1797, 1016, 1040, "topic"], [1040, 1068, 1068, 1080, "elaboration"], [1040, 1080, 1080, 1797, "elaboration"], [1080, 1099, 1099, 1108, "elaboration"], [1080, 1108, 1108, 1797, "explanation"], [1108, 1140, 1140, 1797, "topic"], [1110, 1140, 1108, 1110, "attribution"], [1112, 1140, 1110, 1112, "attribution"], [1112, 1113, 1113, 1140, "circumstance"], [1113, 1123, 1123, 1140, "sequence"], [1123, 1140, 1113, 1123, "sequence"], [1140, 1797, 1108, 1140, "topic"], [1140, 1153, 1153, 1797, "list"], [1153, 1797, 1140, 1153, "list"], [1153, 1169, 1169, 1797, "list"], [1169, 1797, 1153, 1169, "list"], [1169, 1242, 1242, 1797, "topic"], [1169, 1183, 1183, 1193, "elaboration"], [1169, 1193, 1193, 1242, "elaboration"], [1193, 1200, 1200, 1220, "same_unit"], [1193, 1196, 1196, 1200, "purpose"], [1200, 1220, 1193, 1200, "same_unit"], [1200, 1204, 1204, 1220, "elaboration"], [1193, 1220, 1220, 1242, "elaboration"], [1220, 1225, 1225, 1242, "purpose"], [1225, 1227, 1227, 1242, "condition"], [1227, 1237, 1237, 1242, "elaboration"], [1242, 1797, 1169, 1242, "topic"], [1242, 1256, 1256, 1797, "list"], [1256, 1797, 1242, 1256, "list"], [1269, 1797, 1256, 1269, "antithesis"], [1256, 1261, 1261, 1269, "elaboration"], [1261, 1263, 1263, 1269, "elaboration"], [1269, 1286, 1286, 1797, "topic"], [1276, 1286, 1269, 1276, "attribution"], [1276, 1282, 1282, 1286, "circumstance"], [1286, 1797, 1269, 1286, "topic"], [1286, 1306, 1306, 1326, "elaboration"], [1286, 1326, 1326, 1797, "elaboration"], [1326, 1362, 1362, 1797, "contrast"], [1328, 1359, 1326, 1328, "attribution"], [1328, 1353, 1353, 1359, "elaboration"], [1326, 1359, 1359, 1362, "elaboration"], [1359, 1360, 1360, 1362, "elaboration"], [1362, 1797, 1326, 1362, "contrast"], [1362, 1375, 1375, 1797, "explanation"], [1375, 1409, 1409, 1797, "textualorganization"], [1380, 1409, 1375, 1380, "attribution"], [1401, 1409, 1380, 1401, "condition"], [1380, 1385, 1385, 1401, "elaboration"], [1409, 1797, 1375, 1409, "textualorganization"], [1409, 1425, 1425, 1435, "elaboration"], [1425, 1427, 1427, 1435, "purpose"], [1409, 1435, 1435, 1797, "elaboration"], [1435, 1448, 1448, 1797, "list"], [1438, 1448, 1435, 1438, "attribution"], [1448, 1797, 1435, 1448, "list"], [1459, 1485, 1448, 1459, "attribution"], [1448, 1458, 1458, 1459, "same_unit"], [1448, 1451, 1451, 1458, "elaboration"], [1458, 1459, 1448, 1458, "same_unit"], [1459, 1477, 1477, 1479, "elaboration"], [1459, 1479, 1479, 1485, "elaboration"], [1479, 1484, 1484, 1485, "same_unit"], [1479, 1480, 1480, 1484, "elaboration"], [1484, 1485, 1479, 1484, "same_unit"], [1448, 1485, 1485, 1797, "elaboration"], [1485, 1491, 1491, 1494, "purpose"], [1485, 1494, 1494, 1505, "elaboration"], [1485, 1505, 1505, 1529, "elaboration"], [1505, 1521, 1521, 1529, "condition"], [1485, 1529, 1529, 1797, "explanation"], [1560, 1797, 1529, 1560, "circumstance"], [1536, 1560, 1529, 1536, "circumstance"], [1562, 1571, 1560, 1562, "attribution"], [1560, 1571, 1571, 1579, "elaboration"], [1560, 1579, 1579, 1797, "circumstance"], [1579, 1612, 1612, 1649, "elaboration"], [1612, 1622, 1622, 1628, "temporal"], [1612, 1628, 1628, 1649, "elaboration"], [1579, 1649, 1649, 1797, "elaboration"], [1649, 1680, 1680, 1682, "elaboration"], [1649, 1682, 1682, 1694, "elaboration"], [1682, 1683, 1683, 1694, "elaboration"], [1649, 1694, 1694, 1797, "circumstance"], [1694, 1795, 1795, 1797, "list"], [1694, 1705, 1705, 1707, "elaboration"], [1694, 1707, 1707, 1718, "elaboration"], [1707, 1708, 1708, 1718, "elaboration"], [1708, 1712, 1712, 1718, "elaboration"], [1694, 1718, 1718, 1795, "elaboration"], [1718, 1726, 1726, 1763, "elaboration"], [1726, 1736, 1736, 1763, "same_unit"], [1726, 1729, 1729, 1736, "elaboration"], [1736, 1763, 1726, 1736, "same_unit"], [1736, 1753, 1753, 1763, "same_unit"], [1736, 1737, 1737, 1753, "elaboration"], [1753, 1763, 1736, 1753, "same_unit"], [1757, 1763, 1753, 1757, "attribution"], [1762, 1763, 1757, 1762, "attribution"], [1718, 1763, 1763, 1795, "elaboration"], [1763, 1766, 1766, 1795, "purpose"], [1766, 1782, 1782, 1795, "elaboration"], [1782, 1790, 1790, 1795, "elaboration"], [1795, 1797, 1694, 1795, "list"]], "tokens": ["Dear", "reviewers", "We", "would", "like", "to", "thank", "the", "reviewers", "for", "taking", "the", "time", "to", "leave", "thoughtful", "reviews", ".", "Given", "these", "feedbacks", ",", "we", "have", "significantly", "improved", "the", "draft", "and", "hope", "the", "reviewers", "will", "take", "this", "into", "account", "when", "assessing", "the", "final", "scores", ".", "We", "appreciate", "the", "reviewers", "for", "the", "time", "and", "effort", "they", "dedicated", "to", "our", "paper", ".", "Please", "find", "individual", "replies", "to", "each", "of", "the", "reviews", "in", "the", "respective", "threads", ".", "Based", "on", "the", "reviewers", "'", "reviews", "and", "the", "comment", "by", "Ian", "Osband", "we", "revised", "the", "draft", "and", "uploaded", "the", "new", "version", ".", "Thank", "you", "to", "the", "authors", "for", "trying", "to", "improve", "the", "paper", "and", "analysis", ".", "Some", "parts", "of", "the", "paper", "have", "improved", ",", "but", "there", "are", "still", "many", "parts", "that", "are", "difficult", "to", "follow", ".", "-LRB-", "e.g.", "confidence", "set", "C_t", "is", "not", "introduced", "before", "Appendix", ",", "gamma", "discount", "appears", "in", "undiscounted", "analysis", "-RRB-", "Rather", "than", "get", "bogged", "down", "in", "small", "details", "I", "want", "to", "highlight", "at", "least", "one", "fundamental", "error", "in", "the", "analysis", "of", "PSRL", "-LRB-", "Theorem", "1", "-RRB-", ".", "Stating", "this", "clearly", "should", "be", "enough", "to", "convince", "a", "third", "party", "that", "this", "analysis", "needs", "more", "work", ".", "##", "Main", "theorem", "claim", "+", "prior/posterior", "disconnect", "The", "authors", "claim", "TICKTICK", "the", "first", "model-free", "theoretical", "guarantee", "for", "continuous", "state-action", "space", "MDP", ",", "beyond", "the", "tabular", "setting", "''", ".", "This", "means", "that", ",", "the", "PSRL", "algorithm", "of", "Theorem", "1", ",", "should", "maintain", "its", "posterior", "over", "$", "w", "$", "without", "an", "underlying", "model", ".", "The", "description", "of", "the", "PSRL", "algorithm", "-LRB-", "and", "associated", "regret", "bound", "-RRB-", "is", "not", "tied", "to", "any", "specific", "choice", "of", "prior/likelihood", "format", ".", "This", "statement", "is", "itself", "unclear", ",", "do", "the", "authors", "mean", "this", "result", "to", "hold", "for", "all", "choices", "of", "prior/likelihood", ",", "or", "specifically", "using", "a", "Gaussian", "form", "for", "PSRL", "updates", "?", "Either", "way", ",", "the", "application", "of", "the", "TICKTICK", "posterior", "sampling", "lemma", "''", "on", "page", "23", "-LRB-", "that", "conditioned", "on", "any", "data", "H_t", ",", "the", "sampled", "posterior", "is", "identically", "distributed", "to", "the", "optimal", "value", "-RRB-", "is", "inconsistent", ".", "There", "are", "two", "main", "options", "here", ":", "a", "-", "If", "their", "TICKTICK", "PSRL", "''", "is", "using", "a", "model-free", "Gaussian", "form", "of", "the", "optimal", "value", "-LRB-", "per", "Gaussian", "linear", "bandits", "-RRB-", ",", "then", "this", "is", "not", "the", "correct", "posterior", "for", "the", "Bayesian", "decision", "rule", "on", "the", "optimal", "policy", "for", "all", "underlying", "MDPs", ".", "To", "see", "this", ",", "note", "that", "the", "*", "optimal", "*", "policy", "includes", "a", "max", "operator", "over", "actions", ",", "this", "breaks", "Gaussian", "conjugacy", "even", "if", "the", "rewards", "are", "gaussian", "...", "this", "is", "the", "main", "difficulty", "in", "prior", "analyses", "of", "RLSVI", "-LRB-", "e.g.", "https://arxiv.org/abs/1402.0635", "-RRB-", ".", "b", "-", "If", "PSRL", "is", "using", "the", "correct", "form", "of", "the", "posterior", ",", "then", "it", "must", "be", "using", "the", "information", "about", "the", "likelihood", "of", "the", "TICKTICK", "noise", "process", "''", "$", "\\", "nu", "$", "and", "thus", "this", "is", "not", "a", "model-free", "algorithm", ".", "This", "setting", "is", "most", "similar", "to", "prior", "work", "on", "PSRL", "with", "generalization", "-LRB-", "e.g.", "https://arxiv.org/abs/1406.1853", ",", "https://arxiv.org/abs/1709.04047", "-RRB-", "To", "remedy", "this", ",", "the", "authors", "need", "to", "be", "much", "more", "clear", "about", "what", "prior/posterior", "sampling", "procedure", "their", "PSRL", "algorithm", "uses", "*", "and", "*", "the", "prior/likelihood", "of", "tasks", "against", "which", "they", "are", "assessing", "their", "algorithm", ".", "If", "the", "two", "are", "the", "same", ",", "then", "they", "need", "to", "be", "clear", "on", "*", "how", "*", "PSRL", "is", "able", "to", "be", "model-free", "algorithm", "and", "still", "match", "the", "exact", "posterior", "of", "the", "underlying", "MDP", "given", "any", "possible", "data", "H_t", ".", "This", "is", "an", "interesting", "line", "of", "research", ",", "and", "it", "would", "be", "impactful", "to", "get", "this", "answer", "right", "!", "Unfortunately", ",", "I", "do", "not", "think", "this", "proof", "is", "correct", "and", "so", "it", "should", "not", "be", "accepted", ".", "Dear", "Ian", ",", "We", "also", "like", "to", "thank", "you", "for", "the", "time", "you", "dedicated", "and", "kindly", "read", "the", "revised", "version", "of", "our", "paper", ".", "As", "you", "mentioned", ",", "upon", "you", "and", "our", "four", "reviewers", "'", "thoughtful", "comments", ",", "we", "improved", "the", "clarity", "of", "the", "presentation", ".", "We", "believe", "that", "the", "merit", "of", "openreview", "helps", "authors", "to", "deliver", "polished", "and", "influential", "research", "contributions", ".", "With", "this", "regard", ",", "we", "would", "be", "grateful", "to", "you", "if", "you", "could", "leave", "a", "comment", "for", "our", "AnonReviewer1", "regarding", "drop-out", "and", "its", "correspondence", "to", "Thompson", "sampling", ".", "We", "already", "referred", "our", "AnonReviewer1", "to", "the", "discussion", "in", "Appendix", "A", "of", "your", "BootstrapDQN", "paper", ".", "Moreover", ",", "we", "made", "an", "additional", "empirical", "study", "on", "four", "Atari", "games", "to", "show", "the", "deficiency", "of", "dropout", "in", "providing", "reasonable", "exploration", "and", "exploitation", "tradeoff", ".", "We", "would", "appreciate", "it", "if", "you", "could", "take", "a", "time", "and", "leave", "a", "comment", "in", "the", "corresponding", "thread", ".", "Regarding", "the", "confidence", "set", "C_t", ":", "The", "confidence", "C_t", "is", "mentioned", "in", "section", "4", ".", "Regarding", "the", "discount", "factor", ":", "Both", "theorem", "1", "and", "theorem", "2", "hold", "for", "any", "discount", "factor", "0", "<", "=", "\\", "gamma", "<", "=", "1", ".", "We", "get", "a", "tight", "bound", "if", "we", "replace", "\\", "sqrt", "-LRB-", "H", "-RRB-", "with", "a", "smaller", "quantity", "|", "|", "1", ",", "\\", "gamma", ",", "gamma", "^", "2", ",", "...", ",", "\\", "gamma", "^", "-LRB-", "H-1", "-RRB-", "|", "|", "_", "2", ".", "We", "addressed", "this", "in", "terms", "of", "a", "remark", "in", "the", "latest", "version", ".", "Regarding", "the", "choices", "of", "prior/likelihood", ":", "We", "apologize", "that", "the", "choices", "of", "prior", "and", "likelihood", "were", "not", "clear", "from", "the", "main", "text", ".", "We", "would", "like", "to", "restate", "that", "we", "do", "not", "specify", "the", "choices", "of", "prior", "and", "likelihood", ".", "They", "can", "be", "anything", "as", "long", "as", "they", "satisfy", "the", "set", "of", "assumptions", "on", "page", "6", ",", "e.g.", ",", "sub-Gaussianity", ".", "Regarding", "the", "inconsistency", ":", "Conditioned", "on", "any", "data", "history", "H_t", ",", "the", "posterior", "over", "w", "is", "identical", "to", "the", "posterior", "of", "the", "optimal", "parameter", ".", "Similar", "theoretical", "justification", "is", "also", "deployed", "in", "Russo", "et", "al.", "2014", ",", "TICKTICK", "Learning", "to", "Optimize", "Via", "Posterior", "Sampling", "''", "page", "10", ",", "as", "well", "as", "many", "of", "your", "papers", ",", "e.g.", ",", "TICKTICK", "-LRB-", "More", "-RRB-", "Efficient", "Reinforcement", "Learning", "via", "Posterior", "Sampling", "''", "lemma", "1", ".", "Regarding", "your", "statement", "on", "TICKTICK", "this", "is", "not", "a", "model-free", "algorithm", "if", "we", "know", "the", "likelihood", "''", ":", "Theoretically", ",", "given", "a", "w", ",", "the", "knowledge", "of", "the", "likelihood", "does", "not", "determine", "a", "model", ".", "These", "algorithms", ",", "also", "neither", "require", "to", "construct", "a", "model", "nor", "to", "store", "any", "MDP", "model", "parameters", "-LRB-", "e.g.", ",", "transition", "kernel", "-RRB-", ".", "In", "model-based", "PSRL", ",", "we", "generally", "specify", "the", "problem", "with", "a", "prior", "over", "MDP", "models", ",", "as", "well", "as", "a", "likelihood", "over", "state", "transitions", "and", "reward", "processes", ".", "These", "quantities", "are", "given", "and", "known", "in", "the", "model-based", "PSRL", "framework", ".", "Consequently", ",", "in", "model-free", "PSRL", "we", "specify", "the", "problem", "with", "a", "prior", "over", "Q", "and", "likelihood", "over", "the", "return", "where", "similarly", "these", "quantities", "are", "given", "and", "known", ".", "We", "agree", "with", "you", "that", "when", "the", "prior", "and", "the", "likelihood", "functions", "are", "arbitrary", ",", "then", "computing", "the", "posterior", ",", "as", "well", "as", "sampling", "from", "it", ",", "can", "be", "computationally", "hard", ".", "As", "you", "know", ",", "this", "is", "a", "principled", "issue", "with", "Bayesian", "methods", ".", "It", "is", "also", "an", "unsolved", "issue", "for", "model-based", "methods", ",", "e.g.", ",", "in", "continuous", "MDPs", ".", "While", "we", "are", "excited", "about", "this", "line", "of", "research", ",", "we", "left", "the", "study", "of", "relaxing", "this", "computation", "complexity", "for", "the", "future", "work", ".", "We", "would", "like", "to", "thank", "you", "again", "for", "taking", "the", "time", "to", "leave", "thoughtful", "comments", "and", "we", "appreciate", "your", "positive", "assessment", "of", "this", "line", "of", "research", ".", "We", "would", "be", "also", "grateful", "to", "you", "if", "you", "could", "leave", "a", "comment", "on", "our", "AnonReviewer1", "review", "regarding", "the", "drop-out", "discussion", ".", "Sincerely", ",", "Authors", "This", "issue", "of", "TICKTICK", "exact", "''", "posterior", "inference", "is", "crucial", ".", "Yes", ",", "in", "previous", "papers", "analysing", "PSRL", "they", "assume", "exact", "posterior", "inference", ".", "However", ",", "those", "papers", "do", "not", "claim", "that", "PSRL", "is", "a", "model-free", "algorithm", "when", "doing", "this", ".", "At", "this", "point", ",", "the", "analysis", "of", "this", "TICKTICK", "model-free", "''", "PSRL", "is", "quite", "divorced", "from", "your", "algorithm", "Bayesian", "DQN", "-LRB-", "which", "is", "the", "model-free", "RLSVI", ",", "but", "only", "applying", "randomization", "to", "the", "final", "layer", "of", "a", "DQN", "-RRB-", ".", "I", "think", "it", "would", "be", "better", "to", "separate", "these", "contributions", "into", "two", "separate", "papers", "...", "At", "the", "moment", ",", "there", "is", "an", "implication", "that", "the", "two", "algorithms", "-LRB-", "model-free", "PSRL", "and", "BDQN", "-RRB-", "are", "conflated", "...", "but", "this", "is", "confusing", "because", "actually", "they", "are", "not", "the", "same", "thing", ".", "It", "'s", "also", "not", "clear", "if", "there", "are", "any", "examples", "where", "you", "can", "do", "this", "TICKTICK", "model-free", "PSRL", "''", "exactly", ",", "even", "with", "infinite", "compute", ",", "without", "an", "underlying", "model", "of", "the", "MDP", "?", "The", "issue", "is", "that", ",", "in", "order", "to", "have", "the", "*", "exact", "*", "prior/likelihood", "updates", ",", "you", "need", "to", "take", "into", "account", "the", "max_a", "dynamics", ".", "I", "also", "think", "you", "should", "omit", "the", "TICKTICK", "gamma", "''", "stuff", "entirely", ".", "Regret", "bounds", "O", "-LRB-", "\\", "sqrt", "-LCB-", "T", "-RCB-", "-RRB-", "make", "absolutely", "no", "sense", "in", "a", "discounted", "setting", "...", "for", "any", "discount", "<", "1", "the", "regret", "is", "bounded", "O", "-LRB-", "1", "/", "-LRB-", "1-gamma", "-RRB-", "-RRB-", ".", "Dear", "Ian", ",", "We", "would", "like", "to", "thank", "you", "for", "kindly", "leaving", "a", "comment", "on", "our", "AnonReviewer1", "'s", "thread", ".", "Regarding", "the", "analysis", "of", "model-free", "PSRL", ";", "BDQN", "up", "to", "some", "modification", "reduces", "to", "PSRL", "algorithm", "if", "the", "prior", "and", "posterior", "are", "Gaussian", ".", "As", "we", "mentioned", "in", "the", "paper", ",", "since", "maintaining", "the", "posterior", "distribution", "can", "be", "computationally", "intractable", ",", "in", "our", "empirical", "study", ",", "we", "approximate", "the", "posterior", "with", "a", "Gaussian", "distribution", ".", "We", "apologize", "if", "it", "is", "not", "clear", "from", "the", "paper", ".", "We", "will", "emphasize", "more", "on", "this", "statement", ".", "As", "we", "mentioned", "before", ",", "in", "model-based", "PSRL", ",", "we", "generally", "specify", "the", "problem", "with", "a", "prior", "over", "MDP", "models", ",", "as", "well", "as", "a", "likelihood", "over", "state", "transitions", "and", "reward", "processes", ".", "As", "you", "also", "agreed", ",", "we", "are", "given", "these", "quantities", "before", "interacting", "with", "the", "environment", ".", "Consequently", ",", "in", "model-free", "PSRL", ",", "we", "specify", "the", "problem", "with", "a", "prior", "over", "Q", "and", "likelihood", "over", "the", "return", ".", "Similarly", ",", "we", "are", "given", "these", "quantities", "before", "interacting", "with", "the", "environment", "to", "pursue", "PSRL", "Regarding", "the", "discount", "factor", "\\", "gamma", ";", "the", "per", "episode", "regret", "is", "bounded", "above", "with", "O", "-LRB-", "1", "/", "-LRB-", "1-gamma", "-RRB-", "-RRB-", ",", "but", "not", "the", "overall", "regret", ".", "Following", "your", "statement", ",", "the", "regret", "is", "upper", "bounded", "as", "O", "-LRB-", "T", "/", "-LRB-", "1-gamma", "-RRB-", "-RRB-", "which", "is", "linear", "in", "T", ".", "We", "derived", "a", "sublinear", "regret", "of", "\\", "tild", "-LCB-", "O", "-RCB-", "-LRB-", "\\", "sqrt", "-LCB-", "T", "-RCB-", "|", "|", "-LRB-", "1", ",", "\\", "gamma", ",", "\\", "gamma", "^", "2", ",", "...", ",", "\\", "gamma", "^", "-LCB-", "H-1", "-RCB-", "-RRB-", "|", "|", "_", "2", "-RRB-", ".", "We", "would", "like", "to", "appreciate", "the", "thoughtful", "comments", "on", "our", "paper", "and", "also", "thank", "you", "for", "taking", "the", "time", "to", "leave", "a", "comment", "on", "our", "AnonReviewer1", "review", "regarding", "the", "drop-out", "discussion", ".", "Sincerely", "Authors"], "comment_id": "B1eFHHDnAQ"}, {"rels": [[0, 26, 26, 675, "elaboration"], [26, 34, 34, 59, "purpose"], [34, 40, 40, 59, "elaboration"], [40, 54, 54, 59, "elaboration"], [26, 59, 59, 675, "elaboration"], [59, 90, 90, 675, "list"], [59, 82, 82, 90, "elaboration"], [90, 675, 59, 90, "list"], [99, 112, 90, 99, "attribution"], [99, 100, 100, 112, "elaboration"], [90, 112, 112, 675, "elaboration"], [138, 197, 112, 138, "antithesis"], [138, 152, 152, 197, "elaboration"], [112, 197, 197, 238, "elaboration"], [202, 238, 197, 202, "attribution"], [112, 238, 238, 675, "elaboration"], [238, 250, 250, 675, "elaboration"], [250, 257, 257, 263, "list"], [257, 263, 250, 257, "list"], [250, 263, 263, 675, "purpose"], [263, 282, 282, 675, "elaboration"], [282, 316, 316, 675, "elaboration"], [325, 341, 316, 325, "attribution"], [325, 333, 333, 341, "contrast"], [333, 341, 325, 333, "contrast"], [316, 341, 341, 675, "elaboration"], [341, 351, 351, 359, "elaboration"], [341, 359, 359, 675, "elaboration"], [364, 379, 359, 364, "attribution"], [364, 369, 369, 379, "elaboration"], [359, 379, 379, 675, "elaboration"], [379, 423, 423, 675, "topic"], [379, 383, 383, 396, "elaboration"], [379, 396, 396, 423, "concession"], [414, 423, 396, 414, "concession"], [396, 404, 404, 414, "elaboration"], [423, 675, 379, 423, "topic"], [458, 675, 423, 458, "concession"], [423, 445, 445, 458, "elaboration"], [458, 478, 478, 503, "same_unit"], [458, 470, 470, 478, "elaboration"], [478, 503, 458, 478, "same_unit"], [491, 503, 478, 491, "attribution"], [491, 496, 496, 503, "elaboration"], [458, 503, 503, 675, "elaboration"], [503, 507, 507, 514, "elaboration"], [503, 514, 514, 675, "elaboration"], [525, 544, 514, 525, "attribution"], [514, 518, 518, 525, "elaboration"], [518, 522, 522, 525, "elaboration"], [514, 544, 544, 570, "elaboration"], [544, 561, 561, 570, "list"], [544, 557, 557, 561, "elaboration"], [561, 570, 544, 561, "list"], [514, 570, 570, 675, "elaboration"], [576, 610, 570, 576, "attribution"], [577, 610, 576, 577, "attribution"], [570, 610, 610, 675, "elaboration"], [610, 632, 632, 644, "elaboration"], [632, 635, 635, 644, "circumstance"], [610, 644, 644, 675, "elaboration"], [644, 651, 651, 675, "elaboration"], [651, 662, 662, 675, "same_unit"], [651, 656, 656, 662, "elaboration"], [662, 675, 651, 662, "same_unit"], [662, 668, 668, 675, "elaboration"], [668, 670, 670, 675, "circumstance"]], "tokens": ["This", "paper", "considers", "the", "issue", "of", "distribution", "mismatch", "between", "the", "input", "data", "used", "for", "training", "generative", "models", "and", "the", "new", "data", "for", "new", "instance", "generation", ".", "Given", "a", "sample", "operation", ",", "the", "authors", "propose", "to", "use", "the", "so-called", "optimal", "transport", "to", "map", "the", "distribution", "of", "the", "new", "data", "to", "that", "of", "the", "input", "data", "that", "were", "used", "training", ".", "The", "optimal", "transport", "is", "essentially", "a", "monotonic", "transformation", "as", "the", "composite", "of", "the", "inverse", "of", "the", "target", "distribution", "and", "the", "source", "distribution", ".", "The", "paper", "is", "in", "general", "well", "written", ".", "However", ",", "I", "am", "concerned", "with", "two", "issues", "here", ",", "which", "are", "related", "to", "the", "motivation", "and", "performance", "evaluation", ",", "respectively", ".", "First", ",", "the", "authors", "did", "n't", "make", "it", "clear", "what", "data", "generation", "of", "the", "trained", "generative", "model", "suffers", "from", "the", "distribution", "mismatch", "issue", ",", "although", "there", "was", "some", "discussion", "on", "this", "in", "the", "literature", ",", "as", "the", "authors", "mentioned", ".", "To", "me", ",", "once", "the", "generative", "model", "is", "successfully", "trained", ",", "it", "is", "something", "like", "a", "physical", "process", ",", "and", "new", "data", ",", "which", "are", "contained", "in", "the", "support", "of", "the", "training", "data", ",", "can", "always", "be", "used", "as", "input", "to", "generate", "new", "data", ".", "-LRB-", "Personally", ",", "I", "think", "this", "is", "very", "different", "from", "covariate", "shift", "correction", "in", "domain", "adaptation", ",", "in", "which", "the", "correction", "is", "necessary", "because", "simpler", "models", ",", "instead", "of", "flexible", ",", "nonparametric", "ones", ",", "are", "used", "to", "make", "prediction", ".", "-RRB-", "Second", ",", "the", "authors", "used", "the", "Inception", "Score", "for", "performance", "evaluation", ".", "Please", "give", "this", "score", "in", "the", "paper", "and", "make", "its", "definition", "clear", ".", "To", "me", ",", "it", "is", "not", "surprising", "at", "all", "that", "the", "proposed", "method", "had", "a", "better", "Inception", "Score", ":", "roughly", "speaking", ",", "when", "we", "use", "interpolated", "values", "of", "the", "training", "input", "data", "to", "generate", "images", ",", "the", "Inception", "Score", "is", "expected", "to", "decrease", ",", "compared", "to", "that", "evaluated", "on", "the", "training", "data", ".", "Intuitively", ",", "a", "very", "high", "Inception", "Score", "may", "indicate", "that", "we", "are", "not", "trying", "to", "generalize", ",", "but", "just", "memorize", "the", "training", "input", "data", ".", "An", "explanation", "about", "this", "point", "would", "be", "highly", "appreciated", ".", "We", "thank", "the", "reviewer", "for", "the", "feedback", ".", "Regarding", "the", "data-generation", "process", ":", "we", "do", "use", "a", "model", "that", "is", "only", "trained", "once", "to", "generate", "new", "data", ".", "However", ",", "we", "observe", "-LRB-", "both", "theoretically", "and", "experimentally", "-RRB-", "the", "opposite", "of", "what", "you", "claim", ":", "even", "though", "you", "train", "on", "a", "specific", "distribution", "-LRB-", "say", "uniform", "in", "the", "100", "dimensional", "hypercube", "-RRB-", ",", "it", "matters", "where", "from", "the", "support", "you", "sample", ".", "Of", "course", ",", "if", "you", "use", "the", "model", "as", "a", "TICKTICK", "physical", "process", "''", "and", "sample", "new", "data", "with", "the", "same", "distribution", "as", "you", "used", "during", "training", ",", "you", "do", "not", "have", "a", "problem", ".", "However", ",", "once", "you", "start", "sampling", "the", "distribution", "in", "a", "different", "way", "-LRB-", "e.g.", "by", "interpolating", "between", "samples", "-RRB-", ",", "even", "though", "you", "remain", "in", "the", "support", "of", "your", "distribution", "you", "start", "getting", "TICKTICK", "abnormal", "''", "latent", "codes", "which", "your", "model", "performs", "poorly", "on", ".", "We", "urge", "the", "reviewer", "to", "carefully", "look", "at", "Figure", "2", ".", "in", "the", "paper", ",", "which", "illustrates", "how", "different", "-LRB-", "geometrically", "-RRB-", "the", "interpolated", "samples", "can", "be", "compared", "to", "the", "endpoints", ",", "due", "to", "the", "high", "dimensionality", "of", "the", "space", ".", "Regarding", "the", "Inception", "Score", ",", "it", "was", "proposed", "in", "by", "Salimans", "et", "al.", "-LRB-", "https://arxiv.org/pdf/1606.03498.pdf", "-RRB-", ",", "and", "will", "describe", "it", "better", "in", "the", "paper", ".", "We", "do", "not", "understand", "your", "statement", "that", "TICKTICK", "when", "we", "use", "interpolated", "values", "of", "the", "training", "input", "data", "to", "generate", "images", ",", "the", "Inception", "Score", "is", "expected", "to", "decrease", ",", "compared", "to", "that", "evaluated", "on", "the", "training", "data", "''", ".", "We", "are", "not", "interpolating", "training", "input", "data", ",", "we", "are", "interpolating", "random", "latent", "points", "during", "evaluation", ",", "the", "exact", "same", "latent", "points", "that", "are", "used", "when", "evaluating", "the", "model", "in", "its", "standard", "setting", ".", "We", "do", "not", "obtain", "improved", "Inception", "Scores", "compared", "to", "the", "original", "model", "-LRB-", "when", "sampled", "randomly", "-RRB-", ",", "rather", "we", "avoid", "dropping", "in", "performance", "as", "happens", "when", "you", "linearly", "interpolate", "."], "comment_id": "B1e-bBgiCX"}, {"rels": [[0, 142, 142, 1527, "topic"], [0, 6, 6, 17, "purpose"], [6, 10, 10, 17, "elaboration"], [0, 17, 17, 142, "elaboration"], [17, 27, 27, 51, "elaboration"], [27, 43, 43, 51, "elaboration"], [17, 51, 51, 142, "elaboration"], [51, 58, 58, 86, "elaboration"], [58, 78, 78, 86, "same_unit"], [58, 74, 74, 78, "elaboration"], [78, 86, 58, 78, "same_unit"], [78, 83, 83, 86, "purpose"], [51, 86, 86, 142, "elaboration"], [86, 104, 104, 142, "list"], [86, 91, 91, 104, "purpose"], [104, 142, 86, 104, "list"], [104, 118, 118, 142, "list"], [104, 112, 112, 118, "elaboration"], [118, 142, 104, 118, "list"], [118, 130, 130, 142, "list"], [118, 122, 122, 130, "same_unit"], [122, 130, 118, 122, "same_unit"], [122, 125, 125, 130, "list"], [125, 130, 122, 125, "list"], [125, 127, 127, 130, "purpose"], [130, 142, 118, 130, "list"], [130, 134, 134, 142, "elaboration"], [134, 137, 137, 142, "purpose"], [142, 1527, 0, 142, "topic"], [142, 164, 164, 1527, "elaboration"], [164, 191, 191, 1527, "topic"], [170, 191, 164, 170, "attribution"], [170, 178, 178, 191, "same_unit"], [170, 174, 174, 178, "purpose"], [178, 191, 170, 178, "same_unit"], [178, 181, 181, 191, "purpose"], [181, 186, 186, 191, "manner"], [191, 1527, 164, 191, "topic"], [191, 196, 196, 209, "elaboration"], [198, 209, 196, 198, "attribution"], [191, 209, 209, 1527, "elaboration"], [209, 226, 226, 240, "elaboration"], [209, 240, 240, 1527, "elaboration"], [244, 254, 240, 244, "attribution"], [240, 254, 254, 1527, "explanation"], [254, 258, 258, 276, "purpose"], [254, 276, 276, 1527, "elaboration"], [276, 300, 300, 306, "elaboration"], [276, 306, 306, 1527, "elaboration"], [306, 319, 319, 1527, "elaboration"], [319, 347, 347, 353, "same_unit"], [319, 321, 321, 347, "elaboration"], [321, 334, 334, 347, "elaboration"], [347, 353, 319, 347, "same_unit"], [319, 353, 353, 1527, "elaboration"], [353, 380, 380, 1527, "topic"], [353, 369, 369, 380, "same_unit"], [353, 361, 361, 369, "purpose"], [369, 380, 353, 369, "same_unit"], [369, 376, 376, 380, "comparison"], [380, 1527, 353, 380, "topic"], [380, 413, 413, 422, "elaboration"], [380, 422, 422, 432, "elaboration"], [422, 428, 428, 432, "elaboration"], [380, 432, 432, 1527, "elaboration"], [432, 456, 456, 1527, "list"], [432, 435, 435, 456, "elaboration"], [456, 1527, 432, 456, "list"], [456, 461, 461, 479, "same_unit"], [456, 458, 458, 461, "elaboration"], [461, 479, 456, 461, "same_unit"], [461, 471, 471, 479, "circumstance"], [456, 479, 479, 1527, "elaboration"], [479, 489, 489, 502, "same_unit"], [479, 485, 485, 489, "elaboration"], [489, 502, 479, 489, "same_unit"], [489, 492, 492, 502, "elaboration"], [479, 502, 502, 1527, "elaboration"], [502, 506, 506, 1527, "elaboration"], [506, 548, 548, 1527, "circumstance"], [548, 557, 557, 1527, "textualorganization"], [557, 1527, 548, 557, "textualorganization"], [557, 575, 575, 582, "elaboration"], [557, 582, 582, 596, "elaboration"], [582, 586, 586, 596, "purpose"], [557, 596, 596, 611, "elaboration"], [597, 611, 596, 597, "attribution"], [597, 601, 601, 611, "purpose"], [601, 606, 606, 611, "circumstance"], [557, 611, 611, 1527, "elaboration"], [611, 624, 624, 1527, "elaboration"], [624, 628, 628, 645, "elaboration"], [628, 637, 637, 645, "condition"], [624, 645, 645, 1527, "elaboration"], [645, 650, 650, 683, "elaboration"], [650, 675, 675, 683, "elaboration"], [645, 683, 683, 1527, "elaboration"], [683, 716, 716, 1527, "topic"], [683, 690, 690, 697, "elaboration"], [690, 691, 691, 697, "elaboration"], [683, 697, 697, 716, "elaboration"], [698, 716, 697, 698, "attribution"], [707, 716, 698, 707, "antithesis"], [716, 1527, 683, 716, "topic"], [735, 1527, 716, 735, "antithesis"], [719, 735, 716, 719, "attribution"], [741, 760, 735, 741, "attribution"], [741, 752, 752, 760, "purpose"], [735, 760, 760, 1527, "elaboration"], [760, 818, 818, 1527, "topic"], [760, 789, 789, 818, "list"], [760, 767, 767, 789, "purpose"], [767, 782, 782, 789, "elaboration"], [789, 818, 760, 789, "list"], [790, 818, 789, 790, "attribution"], [807, 818, 790, 807, "antithesis"], [790, 799, 799, 807, "purpose"], [807, 814, 814, 818, "comparison"], [818, 1527, 760, 818, "topic"], [818, 851, 851, 870, "elaboration"], [851, 860, 860, 870, "elaboration"], [860, 866, 866, 870, "elaboration"], [818, 870, 870, 871, "elaboration"], [818, 871, 871, 1527, "elaboration"], [871, 874, 874, 903, "elaboration"], [874, 896, 896, 903, "elaboration"], [871, 903, 903, 1527, "elaboration"], [903, 906, 906, 914, "elaboration"], [903, 914, 914, 926, "elaboration"], [903, 926, 926, 1527, "elaboration"], [926, 939, 939, 962, "purpose"], [939, 952, 952, 962, "same_unit"], [939, 944, 944, 952, "purpose"], [944, 949, 949, 952, "elaboration"], [952, 962, 939, 952, "same_unit"], [954, 962, 952, 954, "attribution"], [926, 962, 962, 1527, "elaboration"], [964, 987, 962, 964, "attribution"], [962, 987, 987, 1527, "elaboration"], [987, 996, 996, 1527, "list"], [996, 1527, 987, 996, "list"], [1008, 1018, 996, 1008, "attribution"], [996, 1004, 1004, 1008, "same_unit"], [996, 998, 998, 1004, "elaboration"], [1004, 1008, 996, 1004, "same_unit"], [996, 1018, 1018, 1527, "elaboration"], [1018, 1035, 1035, 1041, "elaboration"], [1018, 1041, 1041, 1527, "example"], [1041, 1049, 1049, 1069, "elaboration"], [1041, 1069, 1069, 1527, "means"], [1069, 1090, 1090, 1102, "elaboration"], [1094, 1102, 1090, 1094, "attribution"], [1069, 1102, 1102, 1129, "elaboration"], [1116, 1129, 1102, 1116, "attribution"], [1069, 1129, 1129, 1527, "elaboration"], [1130, 1150, 1129, 1130, "attribution"], [1130, 1134, 1134, 1150, "elaboration"], [1134, 1142, 1142, 1150, "circumstance"], [1129, 1150, 1150, 1527, "elaboration"], [1150, 1153, 1153, 1160, "elaboration"], [1150, 1160, 1160, 1171, "elaboration"], [1150, 1171, 1171, 1527, "elaboration"], [1171, 1185, 1185, 1218, "elaboration"], [1185, 1217, 1217, 1218, "same_unit"], [1185, 1199, 1199, 1217, "elaboration"], [1217, 1218, 1185, 1217, "same_unit"], [1171, 1218, 1218, 1527, "elaboration"], [1218, 1221, 1221, 1242, "elaboration"], [1221, 1225, 1225, 1242, "purpose"], [1225, 1231, 1231, 1242, "elaboration"], [1231, 1235, 1235, 1242, "elaboration"], [1218, 1242, 1242, 1527, "elaboration"], [1242, 1247, 1247, 1527, "elaboration"], [1247, 1287, 1287, 1527, "circumstance"], [1287, 1310, 1310, 1330, "elaboration"], [1287, 1330, 1330, 1377, "elaboration"], [1330, 1336, 1336, 1352, "list"], [1336, 1352, 1330, 1336, "list"], [1336, 1339, 1339, 1352, "purpose"], [1330, 1352, 1352, 1377, "elaboration"], [1352, 1358, 1358, 1377, "elaboration"], [1358, 1366, 1366, 1367, "elaboration"], [1358, 1367, 1367, 1377, "means"], [1287, 1377, 1377, 1527, "elaboration"], [1377, 1381, 1381, 1390, "purpose"], [1377, 1390, 1390, 1527, "elaboration"], [1390, 1392, 1392, 1406, "elaboration"], [1390, 1406, 1406, 1527, "elaboration"], [1406, 1407, 1407, 1527, "textualorganization"], [1407, 1527, 1406, 1407, "textualorganization"], [1407, 1411, 1411, 1514, "elaboration"], [1411, 1430, 1430, 1445, "elaboration"], [1430, 1434, 1434, 1445, "purpose"], [1411, 1445, 1445, 1514, "elaboration"], [1445, 1471, 1471, 1490, "elaboration"], [1471, 1480, 1480, 1490, "elaboration"], [1445, 1490, 1490, 1514, "elaboration"], [1407, 1514, 1514, 1527, "elaboration"], [1524, 1527, 1514, 1524, "attribution"], [1514, 1519, 1519, 1520, "purpose"], [1514, 1520, 1520, 1524, "elaboration"]], "tokens": ["The", "paper", "proposes", "a", "new", "approach", "to", "compute", "hyperbolic", "embeddings", "based", "on", "the", "squared", "Lorentzian", "distance", ".", "This", "choice", "of", "distance", "function", "is", "motivated", "by", "the", "observation", "that", "the", "ranking", "of", "these", "distances", "is", "equivalent", "to", "the", "ranking", "of", "the", "true", "hyperbolic", "distance", "-LRB-", "e.g.", ",", "on", "the", "hyperboloid", "-RRB-", ".", "For", "this", "reason", ",", "the", "paper", "proposes", "to", "use", "this", "distance", "function", "in", "combination", "with", "ranking", "losses", "as", "proposed", "by", "Nickel", "&", "Kiela", "-LRB-", "2017", "-RRB-", ",", "as", "it", "might", "be", "easier", "to", "optimize", ".", "Moreover", ",", "the", "paper", "proposes", "to", "use", "Weierstrass", "coordinates", "as", "a", "representation", "for", "points", "on", "the", "hyperboloid", ".", "Hyperbolic", "embeddings", "are", "a", "promising", "new", "research", "area", "that", "fits", "well", "into", "ICLR", ".", "Overall", ",", "the", "paper", "is", "written", "well", "and", "good", "to", "understand", ".", "It", "introduces", "interesting", "ideas", "that", "are", "promising", "to", "advance", "hyperbolic", "embeddings", ".", "However", ",", "in", "the", "current", "version", "of", "the", "paper", ",", "these", "ideas", "are", "not", "fully", "developed", "or", "their", "impact", "is", "unclear", ".", "For", "instance", ",", "using", "Weierstrass", "coordinates", "as", "a", "representations", "seems", "to", "make", "sense", ",", "as", "it", "allows", "to", "use", "standard", "optimization", "methods", "without", "leaving", "the", "manifold", ".", "However", ",", "it", "is", "important", "to", "note", "that", "the", "optimization", "is", "still", "performed", "on", "a", "Riemannian", "manifold", ".", "For", "that", "reason", ",", "following", "the", "Riemannian", "gradient", "along", "geodesics", "would", "still", "require", "the", "exponential", "map", ".", "Moreover", ",", "optimization", "methods", "like", "Adam", "or", "SVRG", "are", "still", "not", "directly", "applicable", ".", "Therefore", ",", "it", "seems", "that", "the", "practical", "benefit", "of", "this", "representation", "is", "limited", ".", "Similarly", ",", "being", "able", "to", "compute", "the", "centroid", "efficiently", "in", "closed", "form", "is", "indeed", "an", "interesting", "aspect", "of", "the", "proposed", "approach", ".", "Moreover", ",", "the", "paper", "explicitly", "connects", "the", "centroid", "to", "the", "least", "common", "ancestor", "of", "children", "in", "a", "tree", ",", "what", "could", "be", "very", "useful", "to", "derive", "new", "embedding", "methods", ".", "Unfortunately", ",", "this", "is", "advantage", "is", "n't", "really", "exploited", "in", "the", "paper", ".", "The", "approach", "taken", "in", "the", "paper", "simply", "uses", "the", "loss", "function", "of", "Nickel", "&", "Kiela", "-LRB-", "2017", "-RRB-", "and", "this", "loss", "does", "n't", "make", "use", "of", "centroids", ",", "as", "the", "paper", "notes", "itself", ".", "The", "only", "use", "of", "the", "centroid", "seems", "then", "to", "justify", "the", "regularization", "method", ",", "i.e.", ",", "that", "parents", "should", "have", "a", "smaller", "norm", "than", "their", "children", ".", "However", ",", "this", "insight", "alone", "seems", "not", "particularly", "novel", ",", "as", "the", "same", "insight", "can", "be", "derived", "for", "standard", "hyperbolic", "method", "and", "has", ",", "for", "instance", ",", "been", "discussed", "in", "Nickel", "&", "Kiela", "-LRB-", "2017", ",", "2018", "-RRB-", ",", "Ganea", "et", "al", "-LRB-", "2018", "-RRB-", ",", "De", "Sa", "-LRB-", "2018", "-RRB-", ".", "Using", "the", "centroid", "to", "derive", "new", "hyperbolic", "embeddings", "could", "be", "interesting", ",", "but", ",", "unfortunately", ",", "is", "currently", "not", "done", "in", "the", "paper", ".", "Further", "comments", "-", "p.", "3", ":", "Projection", "back", "onto", "the", "Poincar", "ball/manifold", "is", "only", "necessary", "when", "the", "exponential", "map", "is", "n't", "used", ".", "The", "methods", "of", "Nickel", "&", "Kiela", "-LRB-", "2018", "-RRB-", ",", "Ganea", "et", "al", "-LRB-", "2018", "-RRB-", "therefore", "do", "n't", "have", "this", "problem", ".", "-", "p.", "7", ":", "Since", "MR", "and", "MAP", "are", "ranking", "measures", ",", "and", "the", "ranking", "of", "distances", "between", "H", "^", "d", "and", "the", "L", "^", "2", "distance", "should", "be", "identical", ",", "it", "is", "not", "clear", "to", "me", "why", "the", "experiments", "show", "significant", "differences", "for", "these", "methods", "when", "\\", "beta", "=", "1", "-", "p.", "7", ":", "Embeddings", "in", "the", "Poincar", "ball", "and", "the", "Hyperboloid", "are", "both", "compatible", "with", "the", "regularization", "method", "in", "eq", ".14", "-LRB-", "using", "their", "respective", "norms", "-RRB-", ".", "It", "would", "be", "interesting", "to", "also", "see", "results", "for", "these", "methods", "with", "regularization", ".", "-", "TICKTICK", "Using", "Weierstrass", "allows", "to", "use", "standard", "optimization", "methods", "without", "leaving", "the", "manifold", ".", "However", ",", "the", "optimization", "is", "still", "performed", "on", "a", "Riemannian", "manifold", ".", "''", "We", "understand", "the", "concern", "that", "a", "Riemannian", "optimizer", "would", "probably", "be", "more", "appropriate", "since", "our", "representations", "lie", "on", "a", "manifold", ".", "However", ",", "from", "Eq", ".", "-LRB-", "9", "-RRB-", ",", "our", "distance", "function", "can", "also", "be", "seen", "as", "the", "sum", "of", "a", "simple", "bilinear", "form", "between", "real", "vectors", "and", "another", "term", "promoting", "some", "similarity", "of", "their", "Euclidean", "norms", ".", "This", "formulation", "is", "then", "very", "similar", "to", "optimizing", "-LRB-", "squared", "-RRB-", "Euclidean", "distances", ".", "-", "TICKTICK", "Computing", "the", "centroid", "in", "closed", "form", "is", "interesting", "but", "is", "n't", "really", "exploited", "in", "the", "paper", ".", "TICKTICK", "We", "agree", "that", "we", "do", "not", "explicitly", "use", "the", "closed-form", "solution", "of", "the", "centroid", "in", "our", "experiments", ".", "However", ",", "our", "last", "theorem", "explains", "that", "minimizing", "the", "distances", "to", "a", "set", "of", "points", "is", "equivalent", "to", "minimizing", "the", "distance", "to", "its", "centroid", ".", "Our", "study", "of", "the", "centroid", "is", "important", "to", "understand", "the", "behavior", "of", "our", "distance", "function", "with", "the", "considered", "set", "of", "similarity", "constraints", "-LRB-", "based", "on", "hierarchical", "relationships", "-RRB-", ".", "-", "TICKTICK", "The", "only", "use", "of", "the", "centroid", "seems", "then", "to", "justify", "the", "regularization", "method", ",", "i.e.", ",", "that", "parents", "should", "have", "a", "smaller", "norm", "than", "their", "children", ".", "However", ",", "this", "insight", "alone", "seems", "not", "particularly", "novel", ",", "as", "the", "same", "insight", "can", "be", "derived", "for", "standard", "hyperbolic", "method", "and", "has", ",", "for", "instance", ",", "been", "discussed", "in", "Nickel", "&", "Kiela", "-LRB-", "2017", ",", "2018", "-RRB-", ",", "Ganea", "et", "al", "-LRB-", "2018", "-RRB-", ",", "De", "Sa", "-LRB-", "2018", "-RRB-", ".", "''", "Although", "the", "fact", "that", "the", "representation", "of", "the", "common", "ancestor", "should", "have", "lower", "Euclidean", "norm", "is", "mentioned", "in", "these", "papers", ",", "it", "is", "never", "proven", "that", "it", "has", "lower", "Euclidean", "norm", ".", "The", "closest", "example", "that", "mentions", "a", "minimizer", "of", "an", "expectation", "of", "-LRB-", "squared", "-RRB-", "hyperbolic", "distances", "is", "De", "Sa", "-LSB-", "F", "-RSB-", ".", "However", ",", "they", "do", "not", "exploit", "a", "closed-form", "of", "the", "centroid", "and", "have", "to", "use", "a", "gradient-based", "method", "to", "minimize", "an", "optimization", "problem", "based", "on", "it", "-LRB-", "see", "-LSB-", "F", "-RSB-", ",", "Section", "4.2", "-RRB-", ".", "We", "show", "that", "the", "Euclidean", "norm", "of", "the", "centroid", "of", "a", "set", "of", "point", "can", "be", "controlled", "with", "the", "curvature", "of", "the", "hyperbolic", "space", ".", "We", "experimentally", "show", "its", "impact", "in", "Table", "2", ".", "Retrieval", "performance", "-LRB-", "Mean", "Rank", "and", "MAP", "-RRB-", "in", "Table", "1", "shows", "how", "close", "to", "its", "descendents", "a", "common", "ancestor", "is", ".", "The", "Poincar", "metric", "is", "defined", "for", "a", "fixed", "curvature", "of", "-1", "and", "can", "not", "have", "smaller", "curvature", "given", "its", "formulation", "exploiting", "arcosh", ".", "Fig.", "1", "of", "our", "submission", "shows", "an", "example", "where", "the", "centroid", "of", "the", "Poincar", "metric", "does", "not", "have", "a", "smaller", "Euclidean", "distance", "than", "the", "set", "of", "points", ".", "By", "manipulating", "the", "curvature", "of", "the", "space", ",", "the", "centroid", "of", "the", "Lorentzian", "norm", "can", "produce", "centroids", "with", "smaller", "Euclidean", "norm", "-LRB-", "as", "we", "demonstrate", "that", "they", "depend", "on", "each", "other", "-RRB-", ".", "We", "can", "also", "plot", "the", "centroid", "of", "the", "squared", "Poincar", "distance", ",", "which", "shows", "that", "the", "corresponding", "centroid", "does", "not", "have", "a", "smaller", "Euclidean", "norm", "either", ".", "-", "TICKTICK", "p.", "3", ":", "Projection", "onto", "the", "Poincar", "ball/manifold", "is", "only", "necessary", "when", "the", "exponential", "map", "is", "n't", "used", ".", "Nickel", "&", "Kiela", "-LRB-", "2018", "-RRB-", ",", "Ganea", "et", "al", "-LRB-", "2018", "-RRB-", "therefore", "do", "n't", "have", "this", "problem", ".", "''", "That", "is", "exactly", "what", "we", "explain", "in", "p.", "3", ",", "although", "Ganea", "et", "al.", "-LSB-", "E", "-RSB-", "also", "reproject", "their", "embeddings", "onto", "the", "Poincar", "ball", "at", "each", "iteration", "-LRB-", "as", "explained", "in", "the", "TICKTICK", "Numerical", "errors", "''", "paragraph", "of", "Section", "4", "of", "-LSB-", "E", "-RSB-", "-RRB-", ".", "Nickel", "&", "Kiela", "-LRB-", "2018", "-RRB-", "propose", "to", "work", "in", "the", "hyperboloid", "space", "to", "avoid", "this", "reprojection", "as", "we", "explain", "in", "p.", "3", ".", "-", "TICKTICK", "p.", "7", ":", "Since", "MR", "and", "MAP", "are", "ranking", "measures", ",", "and", "the", "ranking", "of", "distances", "between", "H", "^", "d", "and", "the", "L", "^", "2", "distance", "should", "be", "identical", ",", "it", "is", "not", "clear", "why", "the", "experiments", "show", "significant", "differences", "for", "these", "methods", "when", "\\", "beta", "=", "1", "''", "Although", "the", "order", "of", "distances", "is", "the", "same", "between", "H", "^", "d", "and", "the", "L", "^", "2", "-LRB-", "since", "they", "only", "differ", "by", "an", "arcosh", "activation", "function", "-RRB-", ",", "these", "two", "distance", "functions", "are", "not", "equivalent", ".", "The", "arcosh", "has", "a", "logarithmic", "form", "and", "then", "tends", "to", "penalize", "differences", "between", "small", "distances", "more", "than", "differences", "between", "large", "distances", ".", "This", "generates", "a", "difference", "during", "training", "that", "is", "for", "instance", "similar", "to", "the", "difference", "obtained", "by", "training", "a", "linear", "loss", "vs", "a", "quadratic", "loss", ".", "The", "quadratic", "loss", "tends", "to", "penalize", "outliers", "more", "than", "a", "linear", "loss", ".", "The", "fact", "that", "these", "distance", "functions", "are", "not", "equivalent", "explains", "the", "difference", "of", "the", "results", ".", "-", "TICKTICK", "p.", "7", ":", "Embeddings", "in", "the", "Poincar", "ball", "and", "the", "Hyperboloid", "are", "both", "compatible", "with", "the", "regularization", "method", "in", "eq", ".14", ".", "It", "would", "be", "interesting", "to", "also", "see", "results", "for", "these", "methods", "with", "regularization", ".", "''", "We", "agree", "but", "the", "point", "of", "that", "regularizer", "was", "to", "show", "that", "the", "global", "structure", "of", "the", "tree", "could", "be", "easily", "recovered", "by", "using", "such", "constraints", "without", "having", "a", "significant", "impact", "on", "the", "retrieval", "performances", "-LRB-", "i.e.", "Mean", "Rank", "and", "Mean", "Average", "Precision", "-RRB-", ".", "We", "have", "added", "for", "instance", "in", "the", "updated", "version", "a", "study", "of", "the", "impact", "of", "such", "regularization", "on", "classification", "performance", "in", "Table", "3", ".", "Removing", "that", "regularization", "consistently", "leads", "to", "-LRB-", "slightly", "-RRB-", "better", "classification", "scores", "."], "comment_id": "B1epRhtspX"}, {"rels": [[3, 13, 0, 3, "attribution"], [3, 6, 6, 13, "elaboration"], [0, 13, 13, 1242, "elaboration"], [13, 18, 18, 30, "elaboration"], [13, 30, 30, 1242, "elaboration"], [30, 48, 48, 60, "elaboration"], [48, 54, 54, 60, "elaboration"], [56, 60, 54, 56, "attribution"], [30, 60, 60, 1242, "elaboration"], [60, 86, 86, 1242, "elaboration"], [86, 101, 101, 1242, "elaboration"], [102, 110, 101, 102, "attribution"], [104, 110, 102, 104, "attribution"], [101, 110, 110, 1242, "elaboration"], [130, 1242, 110, 130, "antithesis"], [130, 138, 138, 147, "elaboration"], [130, 147, 147, 1242, "elaboration"], [150, 176, 147, 150, "attribution"], [150, 170, 170, 176, "elaboration"], [147, 176, 176, 1242, "elaboration"], [176, 183, 183, 191, "elaboration"], [176, 191, 191, 193, "elaboration"], [176, 193, 193, 1242, "elaboration"], [193, 213, 213, 1242, "list"], [193, 198, 198, 213, "purpose"], [198, 202, 202, 213, "elaboration"], [213, 1242, 193, 213, "list"], [213, 215, 215, 1242, "elaboration"], [215, 234, 234, 1242, "elaboration"], [245, 1242, 234, 245, "attribution"], [245, 249, 249, 261, "purpose"], [245, 261, 261, 1242, "circumstance"], [261, 288, 288, 1242, "list"], [261, 285, 285, 288, "elaboration"], [288, 1242, 261, 288, "list"], [288, 1028, 1028, 1242, "topic"], [288, 290, 290, 1028, "elaboration"], [290, 291, 291, 300, "elaboration"], [290, 300, 300, 334, "manner"], [300, 310, 310, 334, "purpose"], [310, 327, 327, 334, "elaboration"], [290, 334, 334, 1028, "elaboration"], [334, 336, 336, 1028, "elaboration"], [336, 348, 348, 365, "elaboration"], [348, 351, 351, 365, "circumstance"], [336, 365, 365, 433, "elaboration"], [385, 433, 365, 385, "attribution"], [376, 385, 365, 376, "attribution"], [381, 385, 376, 381, "attribution"], [385, 405, 405, 433, "elaboration"], [416, 433, 405, 416, "attribution"], [416, 420, 420, 433, "elaboration"], [336, 433, 433, 1028, "elaboration"], [436, 445, 433, 436, "attribution"], [433, 445, 445, 1028, "elaboration"], [445, 463, 463, 474, "elaboration"], [445, 474, 474, 1028, "elaboration"], [474, 491, 491, 534, "elaboration"], [491, 501, 501, 534, "elaboration"], [501, 507, 507, 534, "purpose"], [474, 534, 534, 1028, "elaboration"], [537, 569, 534, 537, "attribution"], [537, 568, 568, 569, "same_unit"], [537, 557, 557, 568, "elaboration"], [568, 569, 537, 568, "same_unit"], [534, 569, 569, 1028, "elaboration"], [569, 594, 594, 598, "elaboration"], [569, 598, 598, 1028, "elaboration"], [598, 604, 604, 627, "elaboration"], [598, 627, 627, 1028, "elaboration"], [627, 664, 664, 681, "list"], [627, 639, 639, 664, "elaboration"], [639, 653, 653, 664, "elaboration"], [664, 681, 627, 664, "list"], [664, 669, 669, 681, "elaboration"], [627, 681, 681, 1028, "elaboration"], [681, 706, 706, 1028, "elaboration"], [706, 711, 711, 1028, "elaboration"], [711, 721, 721, 759, "list"], [721, 759, 711, 721, "list"], [721, 734, 734, 759, "list"], [734, 759, 721, 734, "list"], [711, 759, 759, 1028, "elaboration"], [759, 763, 763, 779, "purpose"], [763, 770, 770, 779, "purpose"], [759, 779, 779, 1028, "elaboration"], [792, 814, 779, 792, "attribution"], [792, 803, 803, 814, "purpose"], [779, 814, 814, 1028, "elaboration"], [814, 837, 837, 853, "elaboration"], [837, 846, 846, 853, "condition"], [814, 853, 853, 1028, "elaboration"], [853, 855, 855, 864, "elaboration"], [853, 864, 864, 899, "manner"], [864, 874, 874, 899, "purpose"], [874, 891, 891, 899, "elaboration"], [891, 898, 898, 899, "elaboration"], [853, 899, 899, 1028, "elaboration"], [907, 921, 899, 907, "attribution"], [907, 913, 913, 921, "elaboration"], [899, 921, 921, 1028, "elaboration"], [921, 928, 928, 937, "elaboration"], [921, 937, 937, 1028, "elaboration"], [937, 941, 941, 944, "same_unit"], [937, 938, 938, 941, "elaboration"], [941, 944, 937, 941, "same_unit"], [937, 944, 944, 1028, "elaboration"], [944, 956, 956, 965, "elaboration"], [944, 965, 965, 1028, "elaboration"], [965, 977, 977, 1028, "elaboration"], [977, 988, 988, 991, "elaboration"], [977, 991, 991, 1028, "elaboration"], [991, 998, 998, 1028, "elaboration"], [998, 1011, 1011, 1014, "elaboration"], [998, 1014, 1014, 1028, "elaboration"], [1028, 1242, 288, 1028, "topic"], [1028, 1072, 1072, 1242, "topic"], [1049, 1072, 1028, 1049, "attribution"], [1029, 1049, 1028, 1029, "attribution"], [1029, 1031, 1031, 1049, "purpose"], [1031, 1039, 1039, 1049, "elaboration"], [1044, 1049, 1039, 1044, "attribution"], [1049, 1054, 1054, 1072, "elaboration"], [1072, 1242, 1028, 1072, "topic"], [1072, 1095, 1095, 1242, "list"], [1077, 1095, 1072, 1077, "attribution"], [1077, 1083, 1083, 1095, "condition"], [1095, 1242, 1072, 1095, "list"], [1095, 1139, 1139, 1242, "list"], [1095, 1098, 1098, 1117, "purpose"], [1105, 1117, 1098, 1105, "attribution"], [1095, 1117, 1117, 1139, "elaboration"], [1117, 1132, 1132, 1139, "elaboration"], [1132, 1135, 1135, 1139, "elaboration"], [1139, 1242, 1095, 1139, "list"], [1139, 1144, 1144, 1167, "elaboration"], [1139, 1167, 1167, 1242, "elaboration"], [1167, 1175, 1175, 1193, "elaboration"], [1175, 1179, 1179, 1193, "purpose"], [1167, 1193, 1193, 1196, "elaboration"], [1167, 1196, 1196, 1242, "elaboration"], [1196, 1201, 1201, 1208, "elaboration"], [1201, 1202, 1202, 1208, "elaboration"], [1196, 1208, 1208, 1216, "elaboration"], [1196, 1216, 1216, 1242, "elaboration"], [1216, 1218, 1218, 1242, "elaboration"], [1218, 1228, 1228, 1242, "contrast"], [1228, 1242, 1218, 1228, "contrast"]], "tokens": ["This", "paper", "shows", "that", "the", "problem", "of", "defending", "MNIST", "is", "still", "unsuccessful", ".", "It", "hereby", "proposes", "a", "model", "that", "is", "robust", "by", "design", "specifically", "for", "the", "MNIST", "classification", "task", ".", "Unlike", "conventional", "classifiers", ",", "the", "proposal", "learns", "a", "class-dependent", "data", "distribution", "using", "VAEs", ",", "and", "conducts", "variational", "inference", "by", "optimizing", "over", "the", "latent", "space", "to", "estimate", "the", "classification", "logits", ".", "Some", "extensive", "experiments", "verify", "the", "model", "robustness", "with", "respect", "to", "different", "distance", "measure", ",", "with", "most", "state-of-the-art", "attacking", "schemes", ",", "and", "compared", "against", "several", "baselines", ".", "The", "added", "experiments", "with", "rotation", "and", "translation", "further", "consolidate", "the", "value", "of", "the", "work", ".", "Overall", "I", "think", "this", "is", "a", "nice", "paper", ".", "Although", "being", "lack", "of", "some", "good", "intuition", ",", "the", "proposed", "model", "indeed", "show", "superior", "robustness", "to", "previous", "defending", "approaches", ".", "Also", ",", "the", "model", "has", "some", "other", "benefits", "that", "are", "shown", "in", "Figure", "3", "and", "4", ".", "The", "results", "show", "that", "the", "model", "has", "indeed", "learned", "the", "data", "distribution", "rather", "than", "roughly", "determining", "the", "decision", "boundary", "of", "the", "input", "space", "as", "most", "existing", "models", "do", ".", "However", ",", "I", "have", "the", "following", "comments", "that", "might", "help", "to", "improve", "the", "paper", ":", "1", ".", "It", "would", "be", "more", "interesting", "to", "add", "more", "intuition", "on", "why", "the", "proposed", "model", "is", "already", "robust", "by", "design", ".", "2", ".", "Although", "the", "paper", "is", "designed", "for", "MNIST", "specifically", ",", "the", "proposed", "scheme", "should", "apply", "to", "other", "classification", "tasks", ".", "Have", "you", "tried", "the", "models", "on", "other", "datasets", "like", "CIFAR10/100", "?", "It", "would", "be", "interesting", "to", "see", "whether", "the", "proposal", "would", "work", "for", "more", "complicated", "tasks", ".", "When", "the", "training", "data", "for", "each", "label", "is", "unbalanced", ",", "namely", ",", "some", "class", "has", "very", "few", "samples", ",", "would", "you", "expect", "the", "model", "to", "fail", "?", "3", ".", "Equation", "-LRB-", "8", "-RRB-", "is", "complicated", "and", "still", "model-dependent", ".", "Without", "further", "relaxation", "and", "simplification", ",", "it", "'s", "not", "easy", "to", "see", "if", "this", "value", "is", "small", "or", "large", ",", "or", "to", "understand", "what", "kind", "of", "message", "this", "section", "is", "trying", "to", "pass", ".", "4", ".", "Although", "the", "main", "contribution", "of", "the", "paper", "is", "to", "propose", "a", "model", "that", "is", "robust", "without", "further", "defending", ",", "the", "proposed", "model", "could", "still", "benefit", "from", "adversarial", "training", ".", "Have", "you", "tried", "to", "retrain", "your", "model", "using", "the", "adversarial", "examples", "you", "have", "got", "and", "see", "if", "it", "helps", "?", "TICKTICK", "Although", "the", "paper", "is", "designed", "for", "MNIST", "specifically", ",", "the", "proposed", "scheme", "should", "apply", "to", "other", "classification", "tasks", ".", "Have", "you", "tried", "the", "models", "on", "other", "datasets", "like", "CIFAR10/100", "?", "It", "would", "be", "interesting", "to", "see", "whether", "the", "proposal", "would", "work", "for", "more", "complicated", "tasks", ".", "''", "First", "experiments", "suggest", "that", "our", "robustness", "is", "not", "limited", "to", "MNIST", ".", "To", "show", "this", ",", "we", "trained", "the", "proposed", "ABS", "model", "and", "a", "vanilla", "CNN", "on", "two", "class", "CIFAR", "and", "achieve", "a", "robustness", "~", "3x", "larger", "than", "a", "CNN", ".", "Robustness", "results", "on", "2", "class", "CIFAR", ":", "model", "accuracy", "|", "L2", "robustness", "CNN", "97.1", "%", "|", "0.8", "-LRB-", "estimated", "with", "BIM", "-RRB-", "ABS", "89.7", "%", "|", "2.5", "-LRB-", "estimated", "with", "LatentDescent", "attack", "-RRB-", "To", "tackle", "the", "reduced", "accuracy", "of", "ABS", "on", "CIFAR-10", "and", "other", "datasets", ",", "we", "are", "currently", "working", "on", "extensions", "of", "our", "architecture", "and", "the", "training", "procedure", ".", "First", "experiments", "show", "that", "this", "can", "improve", "the", "accuracy", "substantially", "over", "baseline", "ABS", "and", "still", "comes", "with", "the", "same", "robustness", "to", "adversarial", "perturbations", "-LRB-", "but", "this", "is", "beyond", "the", "scope", "of", "this", "paper", "-RRB-", ".", "TICKTICK", "When", "the", "training", "data", "for", "each", "label", "is", "unbalanced", ",", "namely", ",", "some", "class", "has", "very", "few", "samples", ",", "would", "you", "expect", "the", "model", "to", "fail", "?", "''", "In", "contrast", "to", "purely", "discriminative", "models", "that", "require", "manual", "rebalancing", "of", "the", "training", "data", ",", "our", "generative", "architecture", "can", "cope", "well", "with", "unbalanced", "datasets", "out", "of", "the", "box", ".", "To", "demonstrate", "this", "experimentally", ",", "we", "have", "trained", "a", "two-class", "MNIST", "classifier", "-LRB-", "ones", "vs.", "sevens", "-RRB-", "both", "on", "a", "balanced", "dataset", ",", "an", "unbalanced", "datasets", "-LRB-", "10", "times", "as", "many", "sevens", "than", "ones", "during", "training", "-RRB-", "and", "a", "highly", "unbalanced", "dataset", "-LRB-", "100", "times", "as", "many", "ones", "as", "sevens", "during", "training", "-RRB-", ".", "They", "all", "perform", "similarly", "well", ":", "accuracy", "|", "L_2", "median", "perturbation", "size", "with", "Latent", "Descent", "attack", "balanced", "ABS", "99.6", "+", "-", "0.1", "%", "|", "3.5", "+", "-", "0.1", "10", ":", "1", "unbalanced", "ABS", "99.3", "+", "-", "0.2", "%", "|", "3.4", "+", "-", "0.2", "100:1", "unbalanced", "ABS", "98.5", "+", "-", "0.2", "%", "|", "3.2", "+", "-", "0.2", "TICKTICK", "It", "would", "be", "more", "interesting", "to", "add", "more", "intuition", "on", "why", "the", "proposed", "model", "is", "already", "robust", "by", "design", ".", "''", "Adversarial", "training", "is", "used", "to", "prevent", "small", "changes", "in", "the", "input", "to", "make", "large", "changes", "in", "the", "model", "decision", ".", "In", "the", "ABS", "model", ",", "the", "Gaussian", "posterior", "in", "the", "reconstruction", "term", "ensures", "that", "small", "changes", "in", "the", "input", "can", "only", "entail", "small", "changes", "to", "the", "posterior", "likelihood", "and", "thus", "to", "the", "model", "decision", ".", "In", "other", "words", ",", "small", "changes", "in", "the", "input", "can", "only", "lead", "to", "small", "changes", "in", "the", "reconstruction", "error", "and", "so", "the", "logits", "-LRB-", "=", "reconstruction", "error", "+", "KL", "divergence", "-RRB-", "can", "only", "change", "slowly", "with", "varying", "inputs", ".", "TICKTICK", "Equation", "-LRB-", "8", "-RRB-", "is", "complicated", "and", "still", "model-dependent", ".", "Without", "further", "relaxation", "and", "simplification", ",", "it", "'s", "not", "easy", "to", "see", "if", "this", "value", "is", "small", "or", "large", ",", "or", "to", "understand", "what", "kind", "of", "message", "this", "section", "is", "trying", "to", "pass", ".", "''", "We", "provide", "quantitative", "values", "in", "the", "results", "section", "TICKTICK", "Lower", "bounds", "on", "Robustness", "''", "-LRB-", "we", "'ll", "add", "a", "pointer", "-RRB-", ".", "For", "ABS", ",", "the", "mean", "L2", "perturbation", "-LRB-", "i.e.", "the", "mean", "of", "epsilon", "in", "eq", ".", "8", "across", "samples", "-RRB-", "is", "0.69", ".", "For", "comparison", ",", "Hein", "et", "al.", "-LSB-", "1", "-RSB-", "reaches", "0.48", ".", "-LSB-", "1", "-RSB-", "Matthias", "Hein", "and", "Maksym", "Andriushchenko", ".", "Formal", "guarantees", "on", "the", "robustness", "of", "a", "classifier", "against", "adversarial", "manipulation", ".", "In", "Advances", "in", "Neural", "Information", "Processing", "Systems", "30", ",", "pp.", "2266", "--", "2276", ".", "Curran", "Associates", ",", "Inc.", ",", "2017", ".", "TICKTICK", "Although", "the", "main", "contribution", "of", "the", "paper", "is", "to", "propose", "a", "model", "that", "is", "robust", "without", "further", "defending", ",", "the", "proposed", "model", "could", "still", "benefit", "from", "adversarial", "training", ".", "Have", "you", "tried", "to", "retrain", "your", "model", "using", "the", "adversarial", "examples", "you", "have", "got", "and", "see", "if", "it", "helps", "?", "''", "It", "'s", "an", "interesting", "question", "as", "to", "whether", "a", "combination", "of", "analysis", "by", "synthesis", "and", "adversarial", "training", "can", "yield", "even", "better", "results", ".", "One", "potential", "problem", "could", "be", "that", "adversarial", "training", "makes", "little", "sense", "if", "adversarials", "are", "already", "at", "the", "perceptual", "boundary", "between", "two", "classes", ".", "This", "would", "need", "to", "be", "evaluated", "carefully", "and", "we", "feel", "that", "such", "an", "analysis", "goes", "beyond", "the", "scope", "of", "this", "paper", ".", "We", "will", ",", "however", ",", "release", "the", "code", "and", "the", "pretrained", "model", "for", "the", "community", "to", "play", "around", "with", "such", "ideas", ".", "Thanks", "for", "the", "suggestion", "!", "As", "we", "know", ",", "MNIST", "is", "too", "easy", "and", "over", "used", ",", "more", "importantly", ",", "it", "can", "not", "represent", "modern", "CV", "tasks", ".", "Fashion-MNIST", "is", "an", "alternative", "dataset", "for", "MNIST", ".", "It", "would", "be", "interesting", "to", "see", "whether", "the", "proposal", "would", "work", "for", "more", "complicated", "tasks", "like", "Fashion-MNIST", ".", "I", "concur", ".", "Fashion-MNIST", "is", "a", "necessary", "datasets", ",", "which", "is", "similar", "to", "MNIST", ".", "Why", "not", "to", "choose", "Fashion-MNIST", "for", "analysis", ".", "The", "fact", "that", "the", "method", "performs", "well", "on", "MNIST", "is", "nice", ",", "but", "MNIST", "should", "be", "considered", "for", "what", "it", "is", ":", "a", "toy", "dataset", "."], "comment_id": "B1eu6wFIyN"}, {"rels": [[0, 6, 6, 22, "elaboration"], [6, 13, 13, 22, "comparison"], [0, 22, 22, 1048, "elaboration"], [22, 28, 28, 45, "purpose"], [28, 34, 34, 45, "elaboration"], [34, 37, 37, 45, "condition"], [22, 45, 45, 1048, "elaboration"], [45, 77, 77, 1048, "topic"], [45, 51, 51, 77, "elaboration"], [51, 58, 58, 77, "purpose"], [58, 62, 62, 77, "elaboration"], [62, 67, 67, 77, "list"], [67, 77, 62, 67, "list"], [67, 73, 73, 77, "elaboration"], [77, 1048, 45, 77, "topic"], [77, 93, 93, 1048, "contrast"], [77, 79, 79, 93, "elaboration"], [79, 89, 89, 93, "elaboration"], [93, 1048, 77, 93, "contrast"], [93, 107, 107, 1048, "elaboration"], [107, 122, 122, 1048, "list"], [107, 115, 115, 122, "elaboration"], [122, 1048, 107, 122, "list"], [122, 124, 124, 137, "elaboration"], [122, 137, 137, 1048, "elaboration"], [137, 140, 140, 1048, "textualorganization"], [140, 1048, 137, 140, "textualorganization"], [140, 256, 256, 1048, "list"], [140, 143, 143, 256, "elaboration"], [143, 147, 147, 151, "elaboration"], [143, 151, 151, 167, "elaboration"], [143, 167, 167, 256, "elaboration"], [167, 176, 176, 182, "elaboration"], [167, 182, 182, 256, "elaboration"], [182, 183, 183, 184, "elaboration"], [182, 184, 184, 200, "elaboration"], [182, 200, 200, 256, "elaboration"], [200, 222, 222, 240, "list"], [200, 202, 202, 222, "elaboration"], [222, 240, 200, 222, "list"], [222, 231, 231, 240, "elaboration"], [200, 240, 240, 256, "elaboration"], [256, 1048, 140, 256, "list"], [256, 287, 287, 1048, "list"], [256, 265, 265, 287, "elaboration"], [265, 266, 266, 280, "elaboration"], [265, 280, 280, 287, "elaboration"], [287, 1048, 256, 287, "list"], [287, 298, 298, 1048, "condition"], [298, 308, 308, 1048, "condition"], [308, 321, 321, 329, "elaboration"], [308, 329, 329, 1048, "elaboration"], [329, 331, 331, 343, "elaboration"], [329, 343, 343, 1048, "elaboration"], [343, 357, 357, 363, "elaboration"], [343, 363, 363, 1048, "elaboration"], [363, 391, 391, 1048, "list"], [363, 369, 369, 391, "purpose"], [391, 1048, 363, 391, "list"], [391, 404, 404, 441, "elaboration"], [404, 412, 412, 441, "elaboration"], [412, 420, 420, 441, "elaboration"], [420, 426, 426, 441, "elaboration"], [391, 441, 441, 1048, "elaboration"], [444, 457, 441, 444, "attribution"], [441, 457, 457, 1048, "elaboration"], [457, 474, 474, 1048, "elaboration"], [474, 502, 502, 1048, "elaboration"], [502, 526, 526, 1048, "elaboration"], [526, 533, 533, 1048, "explanation"], [533, 542, 542, 558, "elaboration"], [533, 558, 558, 573, "elaboration"], [533, 573, 573, 1048, "elaboration"], [573, 575, 575, 606, "elaboration"], [575, 588, 588, 606, "same_unit"], [575, 583, 583, 588, "elaboration"], [588, 606, 575, 588, "same_unit"], [588, 600, 600, 606, "same_unit"], [588, 595, 595, 600, "elaboration"], [600, 606, 588, 600, "same_unit"], [573, 606, 606, 1048, "elaboration"], [606, 625, 625, 660, "elaboration"], [625, 633, 633, 660, "elaboration"], [606, 660, 660, 688, "elaboration"], [660, 661, 661, 662, "elaboration"], [660, 662, 662, 688, "elaboration"], [662, 675, 675, 688, "same_unit"], [662, 670, 670, 675, "elaboration"], [675, 688, 662, 675, "same_unit"], [675, 684, 684, 688, "same_unit"], [675, 681, 681, 684, "elaboration"], [684, 688, 675, 684, "same_unit"], [606, 688, 688, 1048, "elaboration"], [688, 704, 704, 712, "elaboration"], [688, 712, 712, 1048, "elaboration"], [712, 741, 741, 1048, "list"], [712, 714, 714, 741, "elaboration"], [714, 725, 725, 741, "same_unit"], [714, 722, 722, 725, "elaboration"], [725, 741, 714, 725, "same_unit"], [725, 727, 727, 741, "list"], [727, 741, 725, 727, "list"], [727, 735, 735, 741, "same_unit"], [727, 730, 730, 735, "elaboration"], [735, 741, 727, 735, "same_unit"], [741, 1048, 712, 741, "list"], [741, 750, 750, 758, "elaboration"], [741, 758, 758, 1048, "elaboration"], [758, 807, 807, 819, "elaboration"], [814, 819, 807, 814, "attribution"], [758, 819, 819, 1048, "elaboration"], [819, 929, 929, 1048, "list"], [819, 828, 828, 847, "elaboration"], [828, 832, 832, 847, "purpose"], [832, 843, 843, 847, "elaboration"], [819, 847, 847, 864, "elaboration"], [819, 864, 864, 929, "elaboration"], [864, 882, 882, 929, "elaboration"], [882, 900, 900, 929, "list"], [882, 893, 893, 900, "elaboration"], [900, 929, 882, 900, "list"], [908, 929, 900, 908, "attribution"], [908, 919, 919, 929, "same_unit"], [908, 912, 912, 919, "elaboration"], [919, 929, 908, 919, "same_unit"], [919, 921, 921, 929, "elaboration"], [929, 1048, 819, 929, "list"], [929, 960, 960, 979, "elaboration"], [929, 979, 979, 1048, "elaboration"], [979, 985, 985, 986, "elaboration"], [979, 986, 986, 1048, "elaboration"], [986, 1001, 1001, 1015, "list"], [1001, 1015, 986, 1001, "list"], [1001, 1008, 1008, 1015, "elaboration"], [986, 1015, 1015, 1037, "elaboration"], [1015, 1030, 1030, 1035, "elaboration"], [1015, 1035, 1035, 1037, "elaboration"], [986, 1037, 1037, 1048, "elaboration"], [1040, 1048, 1037, 1040, "attribution"]], "tokens": ["This", "paper", "investigates", "multi-target", "domain", "adaptation", "which", "is", "an", "unexplored", "domain", "adaptation", "scenario", "compared", "with", "adapting", "single/multiple", "source", "to", "single", "target", ".", "A", "mutual", "information-based", "loss", "is", "proposed", "to", "encourage", "part", "of", "the", "features", "to", "be", "domain-specific", "while", "the", "other", "part", "to", "be", "domain-invariant", ".", "Instead", "of", "optimizing", "the", "proposed", "loss", "which", "is", "intractable", ",", "this", "work", "proposes", "to", "use", "neural", "network", "to", "model", "the", "relative", "functions", "and", "optimize", "proposed", "loss", "'", "lower", "bound", "by", "SGD", ".", "Method", ":", "The", "proposed", "loss", "has", "an", "explanation", "from", "information", "theory", ",", "which", "is", "nice", ".", "However", ",", "the", "proposed", "loss", "is", "a", "combination", "of", "4", "different", "mutual", "information", ".", "The", "effectiveness", "of", "each", "one", "is", "unclear", ".", "An", "ablation", "study", "should", "be", "provided", ".", "Clarity", ":", "The", "presentation", "should", "be", "improved", ",", "especially", "in", "the", "descriptions", "for", "experiments", ".", "-", "Typo", ":", "Section", "4", ":", "TanH", "should", "be", "Tanh", "-", "Duplicated", "reference", ":", "Konstantinos", "Bousmalis", ",", "Nathan", "Silberman", ",", "David", "Dohan", ",", "Dumitru", "Erhan", ",", "and", "Dilip", "Krishnan", ".", "Unsupervised", "pixel-level", "domain", "adaptation", "with", "generative", "adversarial", "networks", ".", "In", "CVPR", ",", "July", "2017a", ".", "Results", ":", "-", "I", "am", "confused", "by", "the", "experimental", "settings", "of", "MTDA-ITA", ",", "c-MTDA-ITA", ",", "and", "c-MTDA-ITA", ".", "s-MTDA-ITA", ".", "I", "understand", "c-MTDA-ITA", "is", "to", "combine", "all", "the", "target", "domains", "into", "a", "single", "one", "and", "train", "it", "using", "MTDA-ITA", ".", "And", "s-MTDA-ITA", "is", "to", "train", "multiple", "MTDA-ITA", "separately", ",", "where", "each", "one", "corresponds", "to", "a", "source-target", "pair", ".", "But", "I", "am", "confused", "by", "the", "MTDA-ITA", "results", "in", "both", "table", "1", "and", "table", "2", ".", "Could", "the", "authors", "provide", "some", "explanation", "for", "MTDA-ITA", "?", "-", "For", "the", "metric", "in", "digits", "adaptation", ",", "the", "standard", "metric", "is", "classification", "accuracy", ".", "The", "authors", "use", "mean", "classification", "accuracy", ".", "Is", "this", "the", "mean", "of", "classification", "accuracy", "of", "multiple", "runs", "?", "If", "so", ",", "authors", "should", "provide", "the", "standard", "deviation", ".", "If", "this", "is", "the", "average", "per-class", "accuracy", ",", "this", "is", "different", "from", "standard", "routine", "in", "ADDA", ",", "CORAL", ",", "etc.", ".", "Concerns", ":", "The", "effectiveness", "of", "MDTA-ITA", ",", "s-MDTA-ITA", "and", "c-MDTA-ITA", "are", "not", "convincing", ".", "From", "the", "experiments", ",", "it", "seems", "the", "c-MDTA-ITA", "can", "not", "provide", "convincing", "superior", "performance", "compared", "to", "c-ADDA", "and", "c-DTN", ".", "Thank", "you", "for", "the", "review", "!", "To", "improve", "the", "quality", "of", "the", "paper", ",", "we", "have", "made", "several", "adjustments", "to", "our", "paper", "in", "accordance", "with", "your", "review", ".", "TICKTICK", "The", "proposed", "loss", "is", "a", "combination", "of", "4", "different", "mutual", "information", ".", "The", "effectiveness", "of", "each", "one", "is", "unclear", ".", "An", "ablation", "study", "should", "be", "provided", "''", ".", "We", "provided", "a", "detailed", "ablation", "study", "analyzing", "the", "effectiveness", "of", "each", "term", "in", "our", "proposed", "loss", "function", "in", "Sec.", "4.3", ".", "The", "conclusion", "is", "that", "disabling", "each", "of", "the", "model", "'s", "components", "leads", "to", "degraded", "performance", ".", "More", "precisely", ",", "the", "average", "drop", "by", "disabling", "the", "classifier", "entropy", "loss", "is", "about", "3.5", "%", ".", "Similarly", ",", "by", "disabling", "the", "reconstruction", "loss", "and", "the", "multi-domain", "separation", "loss", ",", "we", "have", "about", "4.5", "%", "and", "22", "%", "average", "drop", "in", "performance", ",", "respectively", ".", "Clearly", ",", "by", "disabling", "the", "multi-domain", "separation", "loss", ",", "the", "accuracy", "drops", "significantly", "due", "to", "the", "severe", "data", "distribution", "mismatch", "between", "different", "domains", ".", "See", "Sec.", "4.3", "for", "more", "details", ".", "TICKTICK", "The", "descriptions", "for", "experiments", "should", "be", "improved", ".", "I", "am", "confused", "by", "the", "experimental", "settings", "of", "MTDA-ITA", ",", "c-MTDA-ITA", ",", "and", "s-MTDA-ITA", ".", "''", "The", "experimental", "setups", "for", "the", "c-MTDA-ITA", ",", "s-MTDA-ITA", "and", "MTDA-ITA", "results", "are", "as", "follows", ".", "c-MTDA-ITA", ":", "for", "this", "case", ",", "we", "consider", "a", "dataset", "-LRB-", "for", "example", "SVHN", "-RRB-", "as", "the", "source", "and", "combine", "the", "others", "-LRB-", "MNIST,MNIST-M", ",", "USPS", "-RRB-", "into", "a", "single", "target", "dataset", ".", "Hence", ",", "this", "is", "a", "standard", "single", "source", "single", "target", "domain", "adaptation", ",", "where", "the", "target", "contains", "multiple", "datasets", "without", "knowing", "which", "sample", "belongs", "to", "which", "dataset", "-LRB-", "the", "domain", "label", "of", "the", "source", "samples", "are", "set", "to", "0", ",", "and", "the", "domain", "label", "of", "all", "target", "samples", "are", "set", "to", "1", "-RRB-", ".", "s-MTDA-ITA", ":", "in", "this", "case", ",", "we", "consider", "a", "dataset", "-LRB-", "for", "example", "SVHN", "-RRB-", "as", "the", "source", "and", "another", "one", "-LRB-", "MNIST", "-RRB-", "as", "the", "target", ".", "Thus", ",", "this", "setup", "also", "corresponds", "to", "a", "standard", "single", "source", "single", "target", "domain", "adaptation", ",", "where", "the", "target", "contains", "only", "one", "dataset", ".", "MTDA-ITA", ":", "for", "this", "case", ",", "we", "consider", "a", "dataset", "-LRB-", "SVHN", "-RRB-", "as", "source", "and", "consider", "others", "-LRB-", "MNIST,MNIST-M", ",", "USPS", "-RRB-", "as", "multiple", "disjoint", "target", "domains", ".", "Therefore", ",", "this", "setup", "corresponds", "to", "a", "novel", "setting", "where", "we", "adapt", "jointly", "multiple", "target", "domains", ".", "It", "should", "be", "noted", "that", "although", "for", "both", "MTDA-ITA", "and", "c-MTDA-ITA", ",", "we", "do", "domain", "adaptation", "for", "multiple", "target", "dataset", ",", "for", "c-MTDA-ITA", ",", "we", "do", "not", "have", "access", "to", "the", "domain", "labels", "of", "the", "target", "datasets", "while", "for", "MTDA-ITA", ",", "we", "have", "access", "to", "the", "target", "domain", "labels", "-LRB-", "we", "know", "which", "target", "sample", "belong", "to", "which", "domain", "-RRB-", ".", "TICKTICK", "The", "meaning", "of", "mean", "classification", "accuracy", "''", ".", "We", "use", "this", "term", "to", "indicate", "the", "mean", "of", "classification", "accuracy", "of", "five", "different", "runs", "using", "random", "initialization", ".", "We", "have", "included", "the", "standard", "deviation", "of", "the", "reported", "accuracies", "to", "the", "tables", "in", "the", "paper", ".", "Based", "on", "the", "standard", "deviation", "results", ",", "our", "model", "has", "lower", "variances", "than", "the", "other", "competing", "methods", ".", "TICKTICK", "It", "seems", "the", "c-MDTA-ITA", "can", "not", "provide", "convincing", "superior", "performance", "compared", "to", "c-ADDA", "and", "c-DTN", "''", ".", "The", "performance", "scores", "reported", "in", "the", "tables", "indicate", "that", "c-MDTA-ITA", "outperforms", "c-ADDA", "-LRB-", "27", "out", "of", "32", "cases", "-RRB-", "and", "c-DTN", "-LRB-", "22", "out", "of", "32", "cases", "-RRB-", ".", "More", "importantly", ",", "one", "of", "the", "contributions", "of", "our", "work", "is", "to", "demonstrate", "our", "specific", ",", "novel", "way", "of", "simultaneously", "adapting", "to", "multiple", "target", "domains", "offers", "empirical", "benefit", "over", "naive", "solutions", "-LRB-", "combining", "all", "target", "datasets", "into", "single", "domain", "or", "adapting", "each", "source-target", "separately", "in", "a", "pair-wise", "fashion", "-RRB-", ".", "Our", "experimental", "results", "support", "this", "claim", ":", "On", "digit", "experiments", ",", "our", "approach", "ranks", "1", "in", "9", "out", "of", "12", "cases", ",", "On", "Multi-PIE", "dataset", ",", "it", "ranks", "1", "in", "17", "out", "of", "20", "cases", ".", "We", "also", "included", "the", "average", "rank", "of", "each", "method", "over", "all", "adaptation", "pairs", "to", "the", "-LRB-", "last", "column", "of", "-RRB-", "tables", ".", "The", "scores", "indicate", "that", "MDTA-ITA", "significantly", "outperforms", "other", "competing", "methods", "."], "comment_id": "B1eo5rRORm"}, {"rels": [[0, 5, 5, 14, "elaboration"], [0, 14, 14, 28, "elaboration"], [0, 28, 28, 1028, "elaboration"], [28, 47, 47, 57, "elaboration"], [28, 57, 57, 1028, "elaboration"], [57, 73, 73, 1028, "elaboration"], [73, 100, 100, 1028, "question"], [73, 84, 84, 100, "elaboration"], [100, 1028, 73, 100, "question"], [100, 109, 109, 122, "list"], [109, 122, 100, 109, "list"], [109, 115, 115, 122, "list"], [115, 122, 109, 115, "list"], [100, 122, 122, 1028, "elaboration"], [122, 135, 135, 161, "same_unit"], [122, 134, 134, 135, "elaboration"], [135, 161, 122, 135, "same_unit"], [135, 138, 138, 161, "elaboration"], [138, 140, 140, 161, "circumstance"], [122, 161, 161, 1028, "elaboration"], [161, 177, 177, 178, "same_unit"], [161, 172, 172, 177, "elaboration"], [177, 178, 161, 177, "same_unit"], [161, 178, 178, 1028, "elaboration"], [178, 180, 180, 186, "attribution"], [178, 186, 186, 1028, "elaboration"], [186, 209, 209, 1028, "topic"], [186, 191, 191, 209, "elaboration"], [209, 1028, 186, 209, "topic"], [209, 223, 223, 1028, "list"], [223, 1028, 209, 223, "list"], [224, 233, 223, 224, "attribution"], [224, 229, 229, 233, "list"], [229, 233, 224, 229, "list"], [223, 233, 233, 1028, "condition"], [233, 240, 240, 241, "elaboration"], [233, 241, 241, 1028, "elaboration"], [241, 254, 254, 264, "elaboration"], [255, 264, 254, 255, "attribution"], [241, 264, 264, 1028, "elaboration"], [264, 266, 266, 276, "elaboration"], [266, 271, 271, 276, "purpose"], [264, 276, 276, 283, "elaboration"], [264, 283, 283, 310, "elaboration"], [283, 288, 288, 310, "elaboration"], [264, 310, 310, 1028, "elaboration"], [310, 324, 324, 1028, "elaboration"], [324, 345, 345, 1028, "elaboration"], [345, 392, 392, 1028, "list"], [345, 366, 366, 392, "elaboration"], [366, 386, 386, 392, "same_unit"], [366, 369, 369, 383, "elaboration"], [366, 383, 383, 386, "restatement"], [386, 392, 366, 386, "same_unit"], [392, 1028, 345, 392, "list"], [392, 412, 412, 1028, "list"], [392, 404, 404, 412, "elaboration"], [412, 1028, 392, 412, "list"], [412, 422, 422, 434, "elaboration"], [422, 429, 429, 434, "same_unit"], [422, 423, 423, 429, "elaboration"], [429, 434, 422, 429, "same_unit"], [412, 434, 434, 1028, "elaboration"], [434, 442, 442, 452, "elaboration"], [442, 449, 449, 452, "elaboration"], [434, 452, 452, 1028, "example"], [452, 458, 458, 499, "elaboration"], [458, 459, 459, 498, "elaboration"], [459, 482, 482, 498, "elaboration"], [482, 487, 487, 498, "elaboration"], [458, 498, 498, 499, "elaboration"], [452, 499, 499, 550, "elaboration"], [499, 513, 513, 526, "same_unit"], [499, 506, 506, 513, "elaboration"], [513, 526, 499, 513, "same_unit"], [499, 526, 526, 550, "elaboration"], [452, 550, 550, 1028, "elaboration"], [550, 567, 567, 1028, "elaboration"], [567, 594, 594, 1028, "question"], [567, 578, 578, 594, "elaboration"], [594, 1028, 567, 594, "question"], [594, 617, 617, 641, "same_unit"], [594, 603, 603, 617, "list"], [603, 617, 594, 603, "list"], [603, 609, 609, 617, "purpose"], [617, 641, 594, 617, "same_unit"], [617, 627, 627, 641, "same_unit"], [617, 622, 622, 627, "elaboration"], [627, 641, 617, 627, "same_unit"], [627, 635, 635, 641, "elaboration"], [594, 641, 641, 1028, "elaboration"], [641, 660, 660, 667, "purpose"], [641, 667, 667, 668, "elaboration"], [641, 668, 668, 1028, "elaboration"], [668, 684, 684, 685, "same_unit"], [668, 679, 679, 684, "elaboration"], [684, 685, 668, 684, "same_unit"], [668, 685, 685, 1028, "elaboration"], [685, 687, 687, 693, "attribution"], [685, 693, 693, 721, "elaboration"], [693, 694, 694, 721, "attribution"], [694, 712, 712, 713, "same_unit"], [694, 705, 705, 712, "elaboration"], [712, 713, 694, 712, "same_unit"], [694, 713, 713, 721, "elaboration"], [685, 721, 721, 748, "elaboration"], [721, 735, 735, 747, "elaboration"], [721, 747, 747, 748, "elaboration"], [685, 748, 748, 1028, "elaboration"], [753, 772, 748, 753, "attribution"], [748, 772, 772, 1028, "elaboration"], [772, 779, 779, 784, "purpose"], [772, 784, 784, 1028, "elaboration"], [784, 822, 822, 848, "elaboration"], [822, 826, 826, 848, "circumstance"], [826, 839, 839, 848, "list"], [839, 848, 826, 839, "list"], [784, 848, 848, 1028, "elaboration"], [848, 876, 876, 1028, "list"], [848, 855, 855, 876, "elaboration"], [855, 857, 857, 876, "elaboration"], [876, 1028, 848, 876, "list"], [876, 891, 891, 954, "list"], [891, 954, 876, 891, "list"], [901, 954, 891, 901, "attribution"], [892, 901, 891, 892, "attribution"], [892, 897, 897, 901, "list"], [897, 901, 892, 897, "list"], [901, 910, 910, 924, "elaboration"], [910, 916, 916, 924, "purpose"], [901, 924, 924, 954, "elaboration"], [926, 954, 924, 926, "attribution"], [926, 931, 931, 954, "elaboration"], [931, 932, 932, 954, "elaboration"], [937, 954, 932, 937, "attribution"], [937, 941, 941, 953, "elaboration"], [941, 948, 948, 953, "purpose"], [937, 953, 953, 954, "elaboration"], [876, 954, 954, 1028, "elaboration"], [954, 969, 969, 982, "elaboration"], [954, 982, 982, 1028, "elaboration"], [982, 994, 994, 1028, "list"], [984, 985, 982, 984, "attribution"], [982, 985, 985, 994, "elaboration"], [994, 1028, 982, 994, "list"], [994, 996, 996, 1002, "elaboration"], [994, 1002, 1002, 1028, "elaboration"], [1002, 1009, 1009, 1028, "elaboration"], [1009, 1013, 1013, 1023, "elaboration"], [1009, 1023, 1023, 1028, "elaboration"]], "tokens": ["I", "have", "found", "the", "ideas", "proposed", "in", "the", "paper", "very", "insightful", "and", "interesting", ".", "The", "paper", ",", "in", "general", ",", "is", "written", "very", "well", "and", "is", "accessible", ".", "My", "most", "important", "concern", "is", "The", "whole", "development", "seems", "not", "as", "effective", "as", "k", "=", "1", "in", "Table", ".2", "-LRB-", "BTW", ",", "there", "is", "a", "typo", "there", "-RRB-", ".", "One", "wonders", ",", "why", "for", "k", "=", "2", ",", "k", "=", "1", "is", "not", "included", "?", "That", "is", ",", "can", "the", "formulation", "be", "changed", "in", "a", "way", "that", "\\", "downarrow", "operator", "represents", "l", "\\", "in", "-LCB-", "1", "\\", "cdots", "k", "-RCB-", "projections", "?", "In", "the", "end", ",", "the", "method", "creates", "k", "tuples", "and", "feed", "them", "through", "specific", "fs", "so", "why", "not", "having", "smaller", "tuples", "?", "The", "rest", "of", "my", "review", "below", "hopefully", "can", "help", "improving", "the", "paper", ";", "-", "Is", "there", "any", "reason", "as", "to", "why", "higher", "order", "Janossy", "poolings", "do", "not", "perform", "as", "good", "as", "k", "=", "1", "for", "the", "sum", "experiment", "?", "-", "Can", "you", "report", "the", "number", "of", "parameters", "for", "the", "developments", "-LRB-", "Janossy", "-", "k", "-RRB-", "?", "Some", "examples", "according", "to", "the", "experiments", "help", ".", "-", "I", "am", "a", "bit", "lost", "to", "grasp", "the", "paragraph", "below", "Eq", ".4", ",", "can", "you", "rephrase", "it", "and", "possibly", "provide", "references", "?", "-", "When", "it", "comes", "to", "testing", ",", "how", "do", "you", "use", "Eq", ".13", "?", "Do", "you", "sample", "a", "few", "permutation", "and", "compute", "13", "?", "If", "yes", ",", "how", "many", "in", "practice", "?", "-", "In", "preposition", "2.1", ",", "n", "seems", "confusing", ",", "why", "not", "|", "h", "|", "-", "In", "P6", ",", "x_i", "is", "a", "sequence", ".", "this", "needs", "to", "be", "mentioned", "Thank", "you", "for", "your", "positive", "comments", ".", "We", "address", "your", "concerns", "below", ".", "''", "-", "Is", "there", "any", "reason", "as", "to", "why", "higher", "order", "Janossy", "poolings", "do", "not", "perform", "as", "good", "as", "k", "=", "1", "for", "the", "sum", "experiment", "?", "''", "The", "sum", "task", "is", "an", "easy", "task", ",", "designed", "for", "k", "=", "1", ".", "Our", "revised", "manuscript", "shows", "sum", "task", "results", "with", "more", "runs", "and", "more", "epochs", "and", "the", "difference", "is", "not", "statistically", "significant", ".", "TICKTICK", "-", "The", "whole", "development", "seems", "not", "as", "effective", "as", "k", "=", "1", "in", "Table", ".2", "...", "''", "Theorem", "2.1", "shows", "that", "Janossy", "Pooling", "-LRB-", "JP", "-RRB-", "with", "k-ary", "dependencies", "includes", "and", "is", "more", "expressive", "than", "JP", "with", "-LRB-", "k-1", "-RRB-", "-", "ary", "dependencies", ",", "but", "there", "will", "be", "tasks", "where", "it", "is", "sufficient", "to", "let", "k", "=", "1", "-LRB-", "and", "also", "easier", "to", "optimize", "-RRB-", ".", "This", "is", "especially", "true", "for", "easy", "tasks", "like", "the", "sum", "task", "which", "do", "not", "require", "exploiting", "dependencies", "within", "the", "input", "sequence", ".", "Our", "revised", "manuscript", "now", "considers", "the", "harder", "task", "of", "computing", "the", "variance", "of", "a", "sequence", "of", "numbers", ".", "For", "this", "harder", "task", ",", "full-sequence", "Janossy", "-LRB-", "k", "=", "|", "h", "|", "-RRB-", "is", "significantly", "more", "accurate", "than", "k", "=", "1,2,3", ",", "by", "using", "pi-SGD", "to", "train", "the", "model", "-LRB-", "which", "optimizes", "\\", "doublebar", "-LCB-", "J", "-RCB-", "rather", "than", "\\", "doublebar", "-LCB-", "L", "-RCB-", "-RRB-", ".", "In", "the", "range", "task", ",", "full", "Janossy", "-LRB-", "k", "=", "|", "h", "|", "-RRB-", "+", "GRU", "+", "pi-SGD", "also", "shows", "significant", "gains", "over", "k", "=", "1,2,3", ".", "For", "all", "other", "tasks", ",", "Janossy", "k", "=", "|", "h", "|", "+", "GRU", "+", "pi-SGD", "performs", "as", "well", "as", "the", "other", "approaches", ".", "''", "-", "One", "wonders", ",", "why", "for", "k", "=", "2", ",", "k", "=", "1", "is", "not", "included", "?", "That", "is", ",", "can", "the", "formulation", "be", "changed", "in", "a", "way", "that", "\\", "downarrow", "operator", "represents", "l", "\\", "in", "-LCB-", "1", "\\", "cdots", "k", "-RCB-", "projections", "?", "In", "the", "end", ",", "the", "method", "creates", "k", "tuples", "and", "feed", "them", "through", "specific", "fs", "so", "why", "not", "having", "smaller", "tuples", "?", "''", "Theoretically", "it", "is", "not", "necessary", "-LRB-", "by", "Theorem", "2.1", "-RRB-", "but", "is", "an", "interesting", "direction", "for", "future", "work", "that", "could", "help", "in", "practice", ".", "It", "is", "clear", ",", "however", ",", "that", "Janossy", "k", "=", "|", "h", "|", "with", "GRU", "+", "pi-SGD", "is", "hard", "to", "beat", "in", "more", "challenging", "tasks", ".", "''", "-", "Can", "you", "report", "the", "number", "of", "parameters", "for", "the", "developments", "-LRB-", "Janossy", "-", "k", "-RRB-", "?", "Some", "examples", "according", "to", "the", "experiments", "help", ".", "''", "We", "have", "added", "the", "number", "of", "parameters", "in", "the", "Supplementary", "Material", "-LRB-", "Table", "7", "and", "Table", "9", "-RRB-", "together", "with", "more", "details", "about", "our", "experimental", "setting", ".", "We", "have", "also", "tested", "k", "=", "2,3", "with", "more", "complex", "models", "for", "\\", "arrow", "-LCB-", "f", "-RCB-", ",", "the", "Supplementary", "Material", "shows", "the", "improved", "results", ".", "''", "-", "I", "am", "a", "bit", "lost", "to", "grasp", "the", "paragraph", "below", "Eq", ".4", ",", "can", "you", "rephrase", "it", "and", "possibly", "provide", "references", "?", "''", "Thank", "you", ",", "we", "rephrased", "our", "observations", "to", "simplify", "the", "exposition", ".", "We", "also", "considered", "the", "pros", "and", "cons", "of", "including", "a", "proof", "that", "Eq", ".4", "captures", "any", "permutation-invariant", "function", "with", "an", "expressive-enough", "set", "of", "permutation-sensitive", "functions", ":", "the", "proof", "is", "straightforward", "as", "one", "can", "simply", "add", "all", "possible", "asymmetries", "-LRB-", "that", "cancel", "out", "when", "summing", "over", "all", "permutations", "-RRB-", "to", "the", "set", "of", "all", "permutation-invariant", "functions", "and", "make", "this", "a", "set", "of", "permutation-sensitive", "functions", ".", "It", "could", "be", "useful", "as", "a", "Proposition", "but", ",", "given", "the", "page", "limit", ",", "we", "have", "chosen", "to", "omit", "this", "straightforward", "proof", "in", "favor", "of", "other", "observations", ".", "TICKTICK", "-", "When", "it", "comes", "to", "testing", ",", "how", "do", "you", "use", "Eq", ".13", "?", "Do", "you", "sample", "a", "few", "permutation", "and", "compute", "13", "?", "If", "yes", ",", "how", "many", "in", "practice", "?", "''", "We", "have", "rewritten", "our", "experimental", "section", "to", "clarify", "how", "Eq", ".13", "is", "used", ".", "We", "recommend", "looking", "at", "the", "new", "Table", "1", "which", "now", "more", "clearly", "defines", "TICKTICK", "infr", "samples", "''", "to", "describe", "how", "many", "samples", "we", "use", "to", "estimate", "Eq", ".13", ".", "''", "-", "In", "preposition", "2.1", ",", "n", "seems", "confusing", ",", "why", "not", "|", "h", "|", "''", "That", "was", "a", "typo", ",", "we", "have", "changed", "to", "|", "h", "|", ".", "Thank", "you", "!", "-", "In", "P6", ",", "x_i", "is", "a", "sequence", ".", "this", "needs", "to", "be", "mentioned", "Thank", "you", ".", "We", "have", "made", "changes", "in", "the", "notation", "to", "clarify", "that", "x", "-LRB-", "i", "-RRB-", "is", "the", "i-th", "sequence", "from", "the", "training", "-LRB-", "test", "-RRB-", "data", "."], "comment_id": "B1eC2L8J0m"}, {"rels": [[0, 13, 13, 36, "elaboration"], [0, 36, 36, 66, "elaboration"], [36, 48, 48, 66, "elaboration"], [0, 66, 66, 682, "elaboration"], [66, 74, 74, 682, "elaboration"], [74, 105, 105, 682, "elaboration"], [105, 113, 113, 119, "elaboration"], [105, 119, 119, 682, "elaboration"], [119, 153, 153, 183, "elaboration"], [153, 156, 156, 183, "elaboration"], [119, 183, 183, 682, "elaboration"], [183, 199, 199, 682, "list"], [183, 184, 184, 199, "temporal"], [184, 192, 192, 199, "purpose"], [199, 682, 183, 199, "list"], [199, 206, 206, 212, "elaboration"], [199, 212, 212, 682, "elaboration"], [212, 220, 220, 682, "elaboration"], [220, 231, 231, 682, "elaboration"], [231, 258, 258, 682, "list"], [231, 234, 234, 258, "elaboration"], [234, 249, 249, 258, "elaboration"], [249, 253, 253, 258, "elaboration"], [258, 682, 231, 258, "list"], [258, 272, 272, 318, "elaboration"], [272, 294, 294, 318, "contrast"], [294, 318, 272, 294, "contrast"], [294, 298, 298, 318, "elaboration"], [258, 318, 318, 682, "elaboration"], [318, 326, 326, 352, "same_unit"], [318, 321, 321, 326, "elaboration"], [326, 352, 318, 326, "same_unit"], [326, 335, 335, 352, "elaboration"], [335, 341, 341, 352, "same_unit"], [335, 336, 336, 341, "elaboration"], [341, 352, 335, 341, "same_unit"], [318, 352, 352, 682, "elaboration"], [354, 375, 352, 354, "attribution"], [354, 365, 365, 375, "means"], [365, 369, 369, 375, "elaboration"], [352, 375, 375, 405, "elaboration"], [375, 379, 379, 405, "purpose"], [381, 405, 379, 381, "attribution"], [381, 398, 398, 405, "same_unit"], [381, 390, 390, 398, "same_unit"], [381, 383, 383, 390, "elaboration"], [390, 398, 381, 390, "same_unit"], [398, 405, 381, 398, "same_unit"], [398, 399, 399, 405, "elaboration"], [352, 405, 405, 682, "circumstance"], [405, 426, 426, 488, "elaboration"], [426, 432, 432, 455, "concession"], [432, 450, 450, 455, "elaboration"], [426, 455, 455, 488, "elaboration"], [459, 488, 455, 459, "attribution"], [459, 471, 471, 488, "elaboration"], [471, 477, 477, 488, "list"], [477, 488, 471, 477, "list"], [405, 488, 488, 682, "elaboration"], [488, 504, 504, 682, "list"], [488, 490, 490, 504, "elaboration"], [501, 504, 490, 501, "attribution"], [490, 496, 496, 501, "elaboration"], [496, 497, 497, 501, "elaboration"], [497, 500, 500, 501, "elaboration"], [501, 502, 502, 504, "elaboration"], [504, 682, 488, 504, "list"], [504, 532, 532, 682, "list"], [504, 506, 506, 532, "elaboration"], [506, 520, 520, 532, "elaboration"], [532, 682, 504, 532, "list"], [532, 534, 534, 566, "elaboration"], [534, 549, 549, 566, "elaboration"], [549, 555, 555, 566, "elaboration"], [532, 566, 566, 682, "elaboration"], [566, 571, 571, 592, "purpose"], [566, 592, 592, 682, "elaboration"], [592, 597, 597, 607, "elaboration"], [597, 599, 599, 607, "elaboration"], [592, 607, 607, 635, "elaboration"], [592, 635, 635, 653, "elaboration"], [592, 653, 653, 682, "elaboration"], [653, 676, 676, 682, "elaboration"]], "tokens": ["In", "the", "submitted", "manuscript", ",", "the", "authors", "introduce", "a", "novel", "deep", "learning", "architecture", "to", "solve", "the", "problem", "of", "supervised", "learning", "with", "sparse", "and", "irregularly", "sampled", "multivariate", "time", "series", ",", "with", "a", "specific", "interest", "in", "EHRs", ".", "The", "architecture", "is", "based", "on", "the", "use", "of", "a", "semi-parametric", "interpolation", "network", "followed", "by", "the", "application", "of", "a", "prediction", "network", ",", "and", "it", "is", "tested", "on", "two", "classification/regression", "tasks", ".", "The", "manuscript", "is", "interesting", "and", "well", "written", ":", "the", "problem", "is", "properly", "located", "into", "context", "with", "extensive", "bibliography", ",", "the", "method", "is", "sufficiently", "detailed", "and", "the", "experimental", "comparative", "section", "is", "rich", "and", "supportive", "of", "the", "authors", "'", "claim", ".", "However", ",", "there", "are", "a", "couple", "of", "issues", "that", "need", "to", "be", "discussed", ":", "VB", "the", "reported", "performances", "represent", "only", "a", "limited", "improvement", "over", "the", "comparing", "baselines", ",", "indicating", "that", "the", "proposed", "model", "is", "promising", "but", "it", "is", "still", "immature", "IN", "the", "model", "is", "sharing", "many", "characteristics", "with", "-LRB-", "referenced", "-RRB-", "published", "methods", ",", "which", "the", "proposed", "algorithm", "is", "a", "smart", "combination", "of", "-", "thus", ",", "overall", ",", "the", "novelty", "of", "the", "introduced", "method", "is", "somewhat", "limited", ".", "#########", "After", "considering", "the", "proposed", "improvements", ",", "I", "decided", "to", "raise", "my", "mark", "to", "6", ".", "Thanks", "for", "the", "good", "job", "done", "!", "Thank", "you", "for", "your", "comments", ".", "We", "address", "the", "issues", "below", ":", "Q", ":", "the", "reported", "performances", "represent", "only", "a", "limited", "improvement", "...", "A", ":", "In", "Table", "1", "-LRB-", "UWave", "dataset", "-RRB-", ",", "the", "proposed", "model", "achieves", "similar", "accuracy", "to", "the", "Gaussian", "Process", "-LRB-", "GP", "-RRB-", "baseline", "while", "running", "50x", "faster", ".", "At", "the", "same", "time", ",", "it", "outperforms", "the", "other", "strong", "deep", "learning", "baselines", ".", "Our", "model", "allows", "for", "incorporating", "all", "of", "the", "information", "from", "all", "available", "time", "points", "into", "a", "global", "interpolation", "model", "just", "like", "GP", "but", "removes", "the", "restrictions", "associated", "with", "the", "need", "for", "a", "positive", "definite", "covariance", "matrix", "and", "at", "the", "same", "time", "reduces", "the", "computational", "complexity", ".", "In", "Table", "2", "-LRB-", "MIMIC-III", "dataset", "-RRB-", ",", "our", "model", "achieves", "statistically", "significant", "improvements", "over", "the", "baseline", "models", "-LRB-", "p", "<", "0.01", "-RRB-", "with", "respect", "to", "all", "the", "metrics", "except", "median", "absolute", "error", ".", "We", "show", "that", "the", "performance", "on", "the", "regression", "task", "can", "be", "further", "improved", "using", "only", "two", "interpolants", "-LRB-", "Appendix", "A.", "3", "-RRB-", ".", "We", "would", "also", "like", "to", "note", "that", "AUPRC", "-LRB-", "Davis", "&", "Goadrich", ",", "2006", "-RRB-", "is", "a", "better", "metric", "for", "a", "highly", "imbalanced", "dataset", "which", "is", "the", "case", "here", ".", "When", "considering", "AUPRC", ",", "the", "difference", "between", "the", "performance", "of", "the", "proposed", "model", "with", "respect", "to", "the", "other", "baselines", "increases", ".", "Similarly", "for", "the", "regression", "task", ",", "even", "though", "the", "median", "absolute", "error", "is", "similar", "to", "the", "baselines", "the", "explained", "variance", "score", "shows", "large", "improvements", "compared", "to", "the", "baselines", ".", "Thus", ",", "we", "feel", "that", "the", "improved", "accuracy", "relative", "to", "the", "existing", "GRU-based", "methods", "on", "MIMIC-III", "coupled", "with", "the", "increased", "modeling", "flexibility", "and", "significant", "speed-ups", "relative", "to", "the", "GP-GRU", "are", "important", "contributions", ".", "Q", ":", "the", "model", "is", "sharing", "many", "characteristics", "with", "-LRB-", "referenced", "-RRB-", "published", "methods", "...", ".", "A", ":", "The", "proposed", "model", "is", "designed", "to", "allow", "the", "flexible", "selection", "of", "prediction", "networks", ",", "which", "is", "characteristic", "that", "it", "shares", "with", "the", "prior", "GP-based", "methods", ".", "Here", ",", "the", "primary", "contribution", "of", "our", "approach", "is", "a", "highly", "significant", "reduction", "in", "the", "compute", "time", "relative", "to", "using", "GP-based", "methods", ",", "which", "makes", "the", "method", "much", "more", "suitable", "for", "practical", "use", ".", "In", "addition", ",", "our", "approach", "to", "decomposing", "the", "continuous", "time", "data", "to", "directly", "expose", "smooth", "trends", "and", "transient", "components", "is", "absent", "from", "prior", "GP-based", "methods", ".", "Relative", "to", "prior", "neural", "network", "based", "approaches", "-LRB-", "the", "GRU", "-", "*", "family", "-RRB-", ",", "our", "method", "focuses", "on", "enabling", "global", "interpolation", "and", "direct", "use", "of", "continuous", "time", "data", "with", "no", "ad-hoc", "decisions", "about", "how", "to", "assign", "values", "to", "discrete", "time", "intervals", ".", "These", "are", "significant", "differences", "relative", "to", "the", "prior", "approaches", ",", "particularly", "in", "terms", "of", "the", "interpolation", "process", ".", "Indeed", ",", "these", "differences", "between", "global", "learned", "interpolation", "and", "local", "imputation", "directly", "account", "for", "the", "improved", "performance", "of", "our", "approach", "over", "the", "GRU", "-", "*", "family", "of", "methods", "."], "comment_id": "B1eEd30jpQ"}, {"rels": [[0, 5, 5, 22, "elaboration"], [0, 22, 22, 768, "elaboration"], [22, 29, 29, 48, "elaboration"], [29, 39, 39, 48, "elaboration"], [22, 48, 48, 768, "elaboration"], [48, 54, 54, 60, "contrast"], [54, 60, 48, 54, "contrast"], [48, 60, 60, 768, "elaboration"], [60, 64, 64, 82, "elaboration"], [60, 82, 82, 768, "elaboration"], [82, 121, 121, 768, "contrast"], [82, 93, 93, 121, "elaboration"], [93, 98, 98, 121, "elaboration"], [98, 105, 105, 121, "elaboration"], [121, 768, 82, 121, "contrast"], [121, 140, 140, 145, "elaboration"], [121, 145, 145, 768, "elaboration"], [145, 152, 152, 174, "elaboration"], [152, 156, 156, 174, "elaboration"], [156, 167, 167, 174, "elaboration"], [145, 174, 174, 768, "elaboration"], [174, 199, 199, 265, "list"], [174, 175, 175, 176, "elaboration"], [174, 176, 176, 186, "elaboration"], [174, 186, 186, 195, "elaboration"], [174, 195, 195, 199, "elaboration"], [199, 265, 174, 199, "list"], [199, 215, 215, 265, "list"], [199, 200, 200, 201, "elaboration"], [199, 201, 201, 211, "elaboration"], [199, 211, 211, 215, "elaboration"], [215, 265, 199, 215, "list"], [215, 242, 242, 265, "list"], [227, 242, 215, 227, "attribution"], [227, 232, 232, 242, "purpose"], [232, 236, 236, 242, "circumstance"], [242, 265, 215, 242, "list"], [242, 257, 257, 265, "elaboration"], [174, 265, 265, 768, "elaboration"], [265, 285, 285, 768, "elaboration"], [285, 302, 302, 768, "textualorganization"], [302, 768, 285, 302, "textualorganization"], [302, 311, 311, 372, "elaboration"], [311, 314, 314, 372, "elaboration"], [314, 332, 332, 349, "elaboration"], [335, 349, 332, 335, "attribution"], [314, 349, 349, 372, "elaboration"], [351, 372, 349, 351, "attribution"], [302, 372, 372, 768, "elaboration"], [372, 411, 411, 768, "list"], [372, 381, 381, 411, "elaboration"], [381, 405, 405, 411, "elaboration"], [411, 768, 372, 411, "list"], [411, 417, 417, 768, "list"], [411, 414, 414, 417, "elaboration"], [417, 768, 411, 417, "list"], [417, 444, 444, 768, "list"], [429, 444, 417, 429, "attribution"], [429, 434, 434, 444, "purpose"], [434, 438, 438, 444, "circumstance"], [444, 768, 417, 444, "list"], [444, 447, 447, 768, "elaboration"], [447, 448, 448, 457, "elaboration"], [448, 453, 453, 457, "purpose"], [447, 457, 457, 768, "elaboration"], [457, 463, 463, 478, "elaboration"], [463, 465, 465, 478, "purpose"], [465, 474, 474, 478, "elaboration"], [457, 478, 478, 768, "elaboration"], [478, 503, 503, 514, "elaboration"], [503, 509, 509, 514, "purpose"], [478, 514, 514, 768, "elaboration"], [514, 523, 523, 768, "elaboration"], [523, 548, 548, 768, "list"], [523, 526, 526, 548, "elaboration"], [526, 539, 539, 548, "elaboration"], [548, 768, 523, 548, "list"], [548, 568, 568, 655, "elaboration"], [568, 571, 571, 655, "elaboration"], [571, 587, 587, 599, "same_unit"], [571, 584, 584, 587, "elaboration"], [587, 599, 571, 587, "same_unit"], [587, 590, 590, 599, "elaboration"], [571, 599, 599, 655, "elaboration"], [599, 607, 607, 612, "same_unit"], [599, 602, 602, 607, "elaboration"], [607, 612, 599, 607, "same_unit"], [599, 612, 612, 655, "elaboration"], [612, 624, 624, 635, "elaboration"], [624, 625, 625, 635, "elaboration"], [612, 635, 635, 655, "elaboration"], [638, 655, 635, 638, "attribution"], [638, 648, 648, 655, "elaboration"], [548, 655, 655, 768, "elaboration"], [655, 731, 731, 768, "list"], [659, 682, 655, 659, "attribution"], [659, 667, 667, 682, "elaboration"], [655, 682, 682, 731, "example"], [682, 687, 687, 696, "elaboration"], [682, 696, 696, 731, "elaboration"], [696, 702, 702, 731, "elaboration"], [702, 709, 709, 710, "list"], [709, 710, 702, 709, "list"], [702, 710, 710, 731, "elaboration"], [710, 716, 716, 731, "elaboration"], [716, 723, 723, 731, "list"], [723, 731, 716, 723, "list"], [731, 768, 655, 731, "list"], [731, 750, 750, 768, "elaboration"], [750, 760, 760, 768, "elaboration"], [760, 761, 761, 768, "elaboration"]], "tokens": ["This", "paper", "explores", "the", "idea", "of", "utilizing", "a", "secret", "random", "permutation", "in", "the", "Fourier", "phase", "domain", "to", "defense", "against", "adversarial", "examples", ".", "The", "idea", "is", "drawn", "from", "cryptography", ",", "where", "the", "random", "permutation", "is", "treated", "as", "a", "secret", "key", "that", "the", "adversarial", "does", "not", "have", "access", "to", ".", "This", "setting", "has", "practical", "limitations", ",", "but", "is", "plausible", "in", "theory", ".", "While", "the", "defense", "technique", "is", "certainly", "novel", "and", "inspired", ",", "its", "use", "case", "seems", "limited", "to", "simple", "datasets", "such", "as", "MNIST", ".", "The", "permuted", "phase", "component", "does", "not", "admit", "weight", "sharing", "and", "invariances", "exploited", "by", "convolutional", "networks", ",", "which", "results", "in", "severely", "hindered", "clean", "accuracy", "--", "only", "96", "%", "on", "MNIST", "and", "45", "%", "on", "CIFAR-10", "for", "a", "single", "model", ".", "While", "the", "security", "of", "a", "model", "against", "adversarial", "attacks", "is", "important", ",", "a", "defense", "should", "not", "sacrifice", "clean", "accuracy", "to", "such", "an", "extent", ".", "For", "this", "weakness", ",", "I", "recommend", "rejection", "but", "encourage", "the", "authors", "to", "continue", "exploring", "in", "this", "direction", "for", "a", "more", "suitable", "scheme", "that", "does", "not", "compromise", "clean", "accuracy", ".", "Pros", ":", "-", "Novel", "defense", "technique", "against", "very", "challenging", "white-box", "attacks", ".", "-", "Sound", "threat", "model", "drawn", "from", "traditional", "security", ".", "-", "Clearly", "written", ".", "Cons", ":", "-", "Poor", "clean", "accuracy", "makes", "the", "technique", "very", "impractical", ".", "-", "Insufficient", "baselines", ".", "While", "the", "permutation", "is", "kept", "as", "a", "secret", ",", "it", "is", "plausible", "that", "the", "adversary", "may", "attempt", "to", "learn", "the", "transformation", "when", "given", "enough", "input-output", "pairs", ".", "Also", ",", "the", "adversary", "may", "attack", "an", "ensemble", "of", "PPD", "models", "for", "different", "random", "permutations", "-LRB-", "i.e.", "expectation", "over", "random", "permutations", "-RRB-", ".", "The", "authors", "should", "introduce", "an", "appropriate", "threat", "model", "and", "evaluate", "this", "defense", "against", "plausible", "attacks", "under", "that", "threat", "model", ".", "We", "thank", "the", "reviewer", "for", "the", "detailed", "feedback", "and", "address", "the", "comments", "below", ":", "Reviewer", "comment", ":", "Poor", "clean", "accuracy", "makes", "the", "technique", "very", "impractical", ".", "Our", "response", ":", "The", "48", "%", "accuracy", "on", "CIFAR-10", "is", "for", "a", "simple", "3", "layer", "dense", "neural", "network", "and", "our", "goal", "was", "to", "show", "that", "even", "with", "such", "a", "simple", "network", ",", "SOTA", "robustness", "can", "be", "achieved", ".", "We", "believe", "that", "high", "accuracy", "combined", "with", "adversarial", "robustness", "is", "possible", "for", "CIFAR-10", ",", "and", "transfer", "learning", "shows", "promise", "in", "this", "direction", ".", "What", "we", "plan", "to", "do", "as", "future", "work", "is", "to", "replace", "the", "neural", "network", "in", "the", "PPD", "pipeline", "with", "a", "pre-trained", "model", "on", "massive", "datasets", "such", "as", "ImageNet", "and", "retrain", "the", "final", "layers", "to", "fit", "the", "permutation-phase", "domain", ".", "Reviewer", "comment", ":", "Insufficient", "baselines", ".", "While", "the", "permutation", "is", "kept", "as", "a", "secret", ",", "it", "is", "plausible", "that", "the", "adversary", "may", "attempt", "to", "learn", "the", "transformation", "when", "given", "enough", "input-output", "pairs", ".", "Our", "response", ":", "Thanks", "for", "bringing", "this", "attack", "scenario", "to", "our", "attention", ".", "To", "test", "PPD", "against", "an", "adversary", "that", "tries", "to", "learn", "the", "transformation", ",", "we", "used", "Blackbox", "attack", "-LRB-", "https://arxiv.org/abs/1602.02697", "-RRB-", ".", "In", "this", "attack", ",", "adversary", "probes", "an", "ensemble", "of", "PPD", "models", "as", "a", "black", "box", "by", "enough", "input-output", "pairs", "and", "trains", "a", "substitute", "model", ".", "The", "substitute", "model", "is", "then", "used", "to", "craft", "adversarial", "examples", ".", "Table", "1", "is", "updated", "with", "the", "Blackbox", "results", ".", "Reviewer", "comment", ":", "The", "adversary", "may", "attack", "an", "ensemble", "of", "PPD", "models", "for", "different", "random", "permutations", "-LRB-", "i.e.", ",", "expectation", "over", "random", "permutations", "-RRB-", ".", "The", "authors", "should", "introduce", "an", "appropriate", "threat", "model", "and", "evaluate", "this", "defense", "against", "plausible", "attacks", "under", "that", "threat", "model", ".", "Our", "response", ":", "Per", "the", "reviewer", "'s", "request", ",", "we", "tested", "PPD", "against", "expectation", "over", "transformation", "-LRB-", "EoT", "-RRB-", "-LRB-", "https://arxiv.org/abs/1707.07397", "-RRB-", "where", "the", "permutation", "is", "considered", "as", "the", "transformation", ".", "30", "PPD", "models", "-LRB-", "with", "different", "permutations", "-RRB-", "are", "used", "for", "EoT", ".", "The", "adversarial", "examples", "are", "then", "fed", "to", "an", "ensemble", "of", "10", "PPD", "models", "-LRB-", "with", "different", "permutations", "from", "the", "30", "models", "-RRB-", ".", "Our", "experiments", "show", "that", "EoT", "can", "not", "decrease", "accuracy", "more", "than", "an", "adversary", "that", "attacks", "with", "a", "single", "model", ".", "One", "possible", "explanation", "is", "that", "EoT", "is", "mostly", "useful", "in", "the", "case", "that", "sampling", "a", "few", "transformations", "provides", "a", "good", "approximation", "of", "the", "expectation", "over", "transformation", ".", "For", "example", ",", "two", "scenarios", "that", "EoT", "is", "shown", "to", "be", "successful", "are", ":", "-LRB-", "1", "-RRB-", "synthesizing", "adversarial", "examples", "that", "are", "robust", "to", "camera", "viewpoint", "shift", "and", "-LRB-", "2", "-RRB-", "breaking", "a", "defense", "that", "randomly", "drops", "pixels", "of", "the", "image", "and", "replaces", "them", "with", "total", "variance", "minimization", ".", "In", "both", "of", "these", "two", "scenarios", ",", "sampling", "a", "few", "transformations", "gives", "a", "good", "idea", "of", "the", "expectation", ".", "However", ",", "in", "PPD", ",", "each", "transformation", "has", "its", "own", "fingerprint", "which", "is", "totally", "different", "from", "others", "."], "comment_id": "B1eu-5JYR7"}, {"rels": [[0, 16, 16, 943, "elaboration"], [16, 22, 22, 23, "elaboration"], [16, 23, 23, 44, "elaboration"], [23, 27, 27, 44, "elaboration"], [16, 44, 44, 943, "elaboration"], [44, 56, 56, 943, "elaboration"], [56, 74, 74, 943, "example"], [74, 117, 117, 943, "elaboration"], [117, 135, 135, 141, "elaboration"], [117, 141, 141, 943, "elaboration"], [141, 174, 174, 192, "sequence"], [141, 157, 157, 174, "elaboration"], [157, 166, 166, 174, "elaboration"], [174, 192, 141, 174, "sequence"], [174, 188, 188, 192, "elaboration"], [141, 192, 192, 943, "elaboration"], [192, 222, 222, 943, "list"], [192, 199, 199, 222, "elaboration"], [199, 205, 205, 222, "reason"], [205, 212, 212, 222, "contrast"], [212, 222, 205, 212, "contrast"], [222, 943, 192, 222, "list"], [222, 227, 227, 232, "list"], [227, 232, 222, 227, "list"], [222, 232, 232, 943, "elaboration"], [232, 239, 239, 264, "elaboration"], [239, 244, 244, 264, "list"], [244, 264, 239, 244, "list"], [244, 253, 253, 264, "purpose"], [232, 264, 264, 943, "elaboration"], [264, 274, 274, 943, "elaboration"], [276, 296, 274, 276, "attribution"], [274, 296, 296, 943, "elaboration"], [296, 314, 314, 322, "purpose"], [296, 322, 322, 943, "elaboration"], [322, 330, 330, 943, "list"], [330, 943, 322, 330, "list"], [330, 337, 337, 343, "elaboration"], [330, 343, 343, 943, "elaboration"], [343, 389, 389, 943, "elaboration"], [389, 404, 404, 418, "elaboration"], [404, 408, 408, 418, "list"], [408, 418, 404, 408, "list"], [408, 413, 413, 418, "list"], [413, 418, 408, 413, "list"], [389, 418, 418, 943, "elaboration"], [421, 437, 418, 421, "attribution"], [421, 427, 427, 437, "elaboration"], [418, 437, 437, 943, "elaboration"], [437, 449, 449, 943, "elaboration"], [449, 459, 459, 465, "list"], [459, 465, 449, 459, "list"], [449, 465, 465, 943, "elaboration"], [465, 479, 479, 943, "elaboration"], [479, 485, 485, 491, "list"], [485, 491, 479, 485, "list"], [479, 491, 491, 943, "manner"], [491, 498, 498, 506, "elaboration"], [491, 506, 506, 943, "explanation"], [506, 513, 513, 943, "elaboration"], [513, 550, 550, 943, "topic"], [513, 530, 530, 550, "elaboration"], [530, 547, 547, 550, "same_unit"], [530, 531, 531, 547, "elaboration"], [531, 543, 543, 547, "elaboration"], [547, 550, 530, 547, "same_unit"], [550, 943, 513, 550, "topic"], [550, 604, 604, 943, "list"], [550, 566, 566, 583, "contrast"], [566, 583, 550, 566, "contrast"], [550, 583, 583, 604, "elaboration"], [583, 588, 588, 604, "elaboration"], [588, 596, 596, 604, "purpose"], [596, 601, 601, 604, "purpose"], [604, 943, 550, 604, "list"], [604, 619, 619, 943, "elaboration"], [619, 624, 624, 943, "textualorganization"], [624, 943, 619, 624, "textualorganization"], [624, 632, 632, 943, "elaboration"], [632, 642, 642, 652, "elaboration"], [632, 652, 652, 943, "elaboration"], [652, 663, 663, 685, "elaboration"], [663, 674, 674, 685, "elaboration"], [674, 675, 675, 685, "elaboration"], [675, 679, 679, 685, "elaboration"], [652, 685, 685, 943, "elaboration"], [685, 710, 710, 727, "elaboration"], [710, 717, 717, 727, "elaboration"], [685, 727, 727, 943, "elaboration"], [731, 750, 727, 731, "attribution"], [731, 736, 736, 750, "attribution"], [736, 740, 740, 750, "purpose"], [742, 750, 740, 742, "attribution"], [727, 750, 750, 876, "elaboration"], [750, 759, 759, 778, "purpose"], [759, 765, 765, 778, "reason"], [765, 769, 769, 778, "purpose"], [750, 778, 778, 804, "elaboration"], [778, 782, 782, 804, "elaboration"], [782, 786, 786, 804, "purpose"], [786, 796, 796, 804, "comparison"], [750, 804, 804, 876, "elaboration"], [804, 809, 809, 876, "textualorganization"], [809, 876, 804, 809, "textualorganization"], [809, 826, 826, 847, "same_unit"], [809, 816, 816, 826, "elaboration"], [826, 847, 809, 826, "same_unit"], [826, 830, 830, 847, "elaboration"], [830, 835, 835, 847, "elaboration"], [809, 847, 847, 876, "elaboration"], [847, 859, 859, 876, "same_unit"], [847, 856, 856, 859, "elaboration"], [859, 876, 847, 859, "same_unit"], [859, 861, 861, 876, "elaboration"], [727, 876, 876, 943, "elaboration"], [876, 898, 898, 943, "list"], [876, 881, 881, 898, "elaboration"], [898, 943, 876, 898, "list"], [898, 907, 907, 917, "elaboration"], [898, 917, 917, 943, "circumstance"], [917, 921, 921, 943, "elaboration"], [921, 932, 932, 943, "purpose"], [932, 938, 938, 943, "elaboration"]], "tokens": ["This", "paper", "proposes", "TopicGAN", ",", "a", "generative", "adversarial", "approach", "to", "topic", "modeling", "and", "text", "generation", ".", "The", "model", "basically", "combines", "two", "steps", ":", "first", "to", "generate", "words", "-LRB-", "bag-of-words", "-RRB-", "for", "a", "topic", ",", "then", "second", "to", "generate", "the", "sequence", "of", "the", "words", ".", "While", "the", "idea", "is", "interesting", ",", "there", "are", "several", "important", "limitations", ".", "First", ",", "the", "paper", "is", "difficult", "to", "understand", ",", "and", "some", "of", "the", "explanations", "are", "not", "convincing", ".", "For", "example", ",", "in", "section", "4.1.1", ",", "it", "says", "''", "...", "our", "method", "assumes", "that", "the", "documents", "are", "produced", "from", "a", "single", "topic", "...", "Our", "assumption", "aligns", "well", "with", "human", "intuition", "that", "most", "documents", "are", "generated", "from", "a", "single", "main", "topic", ".", "''", "This", "goes", "very", "much", "against", "the", "common", "assumption", "of", "a", "generative", "topic", "model", ",", "such", "as", "LDA", ",", "which", "the", "model", "compares", "against", ".", "I", "do", "n't", "mean", "to", "argue", "either", "way", ",", "but", "if", "the", "paper", "presents", "a", "viewpoint", "which", "is", "quite", "different", "from", "the", "commonly", "accepted", "viewpoint", "-LRB-", "within", "the", "specific", "research", "field", "-RRB-", ",", "then", "there", "needs", "to", "be", "a", "much", "deeper", "explanation", ",", "ideally", "with", "concrete", "evidence", "to", "support", "it", ".", "Another", "sentence", "from", "the", "same", "paragraph", "states", "that", "their", "TICKTICK", "model", "outperforms", "LDA", "because", "LDA", "is", "a", "statistical", "model", ",", "while", "our", "generator", "is", "a", "deep", "generative", "model", ".", "''", "This", "argument", "also", "seems", "flawed", "and", "without", "concrete", "evidence", ".", "There", "are", "other", "parts", "in", "the", "paper", "where", "the", "logic", "seems", "strange", "and", "without", "evidence", ",", "and", "they", "make", "it", "difficult", "to", "understand", "and", "accept", "the", "major", "claims", "of", "the", "paper", ".", "Second", ",", "the", "model", "does", "not", "offer", "much", "novelty", ".", "It", "seems", "that", "the", "two-stage", "model", "simply", "puts", "the", "two", "pieces", ",", "a", "GAN-style", "generator", "and", "an", "LSTM", "sequence", "model", "together", ".", "Perhaps", "I", "am", "not", "understanding", "the", "model", ",", "but", "the", "model", "description", "was", "also", "not", "clear", "nor", "easy", "to", "understand", "with", "respect", "to", "its", "novelty", ".", "Third", ",", "the", "evaluation", "is", "somewhat", "weak", ".", "There", "are", "two", "main", "evaluations", "tasks", ":", "text", "classification", "and", "text", "generation", ".", "For", "the", "first", "task", ",", "classification", "is", "not", "the", "main", "purpose", "of", "topic", "models", ",", "and", "while", "text", "classification", "_", "is", "_", "used", "in", "many", "topic", "modeling", "papers", ",", "it", "is", "almost", "always", "accompanied", "by", "other", "evaluation", "metrics", "such", "as", "held-out", "perplexity", "and", "topic", "coherence", ".", "This", "is", "because", "the", "main", "purpose", "of", "topic", "modeling", "is", "to", "actually", "infer", "the", "topics", "-LRB-", "per-topic", "word", "distribution", "and", "per-document", "topic", "distribution", "-RRB-", "and", "model", "the", "corpus", ".", "Thus", "I", "feel", "it", "is", "not", "a", "fair", "evaluation", "to", "just", "compare", "the", "models", "using", "text", "classification", "tasks", ".", "The", "second", "evaluation", "task", "of", "text", "generation", "is", "not", "explained", "enough", ".", "For", "the", "human", "evaluation", ",", "who", "were", "the", "annotators", ",", "and", "how", "were", "they", "trained", "?", "How", "many", "people", "annotated", "each", "output", ",", "and", "what", "was", "the", "inter-rater", "agreement", "?", "How", "many", "sentences", "were", "evaluated", ",", "and", "how", "were", "they", "chosen", "?", "Without", "these", "details", ",", "it", "is", "difficult", "to", "judge", "whether", "this", "evaluation", "was", "valid", ".", "Lastly", ",", "the", "results", "are", "mediocre", ".", "Besides", "the", "classification", "task", ",", "the", "others", "do", "not", "show", "significant", "improvements", "over", "the", "baseline", "models", ".", "Perplexity", "-LRB-", "table", "3", "-RRB-", "shows", "similar", "results", "for", "DBPedia", "and", "worse", "results", "-LRB-", "than", "WGAN-gp", "-RRB-", "for", "Gigaword", ".", "Table", "4", "shows", "slightly", "better", "results", "for", "TICKTICK", "Preference", "''", "for", "TopicGAN", "with", "joint", "training", ",", "but", "TICKTICK", "Accuracy", "''", "is", "measured", "only", "for", "the", "proposed", "model", "and", "not", "the", "baseline", "model", ".", "-LRB-", "1", "-RRB-", "Writing", ":", "We", "have", "rewritten", "many", "parts", "of", "the", "article", "to", "make", "the", "paper", "easier", "to", "understand", ".", "In", "addition", ",", "some", "not", "convincing", "explanations", "mentioned", "in", "the", "review", "are", "also", "revised", ".", "-LRB-", "2", "-RRB-", "Assuming", "documents", "are", "generated", "from", "one", "single", "main", "topic", ":", "In", "our", "experiments", ",", "we", "conduct", "unsupervised", "document", "classification", ",", "in", "which", "the", "documents", "have", "only", "one", "single", "class", ".", "Therefore", ",", "for", "those", "unsupervised", "classification", "experiments", ",", "assuming", "each", "documents", "coming", "from", "a", "single", "main", "topic", "is", "a", "more", "appropriate", "assumption", ",", "which", "allows", "our", "model", "to", "learn", "more", "distinct", "topics", ".", "In", "addition", ",", "as", "the", "length", "of", "our", "training", "documents", "is", "short", ",", "it", "'s", "hard", "to", "break", "the", "short", "text", "into", "several", "topics", ",", "which", "is", "one", "of", "the", "possible", "reason", "that", "makes", "LDA", "works", "not", "well", "on", "short", "text", ".", "However", ",", "we", "acknowledge", "that", "for", "long", "documents", ",", "it", "'s", "more", "appropriate", "to", "assume", "they", "come", "from", "the", "mixture", "of", "topics", ".", "In", "fact", ",", "it", "'s", "feasible", "for", "our", "method", "to", "generate", "documents", "from", "several", "topics", "because", "info-GAN", "allows", "us", "to", "decide", "the", "distribution", "of", "the", "predicted", "code", ".", "We", "are", "conducting", "experiments", "on", "using", "several", "topics", "to", "generate", "longer", "documents", "and", "the", "current", "result", "seems", "better", "than", "generating", "from", "one", "single", "main", "topic", ".", "-LRB-", "3", "-RRB-", "Novelty", ":", "The", "novelty", "of", "our", "work", "is", "that", "-LRB-", "a", "-RRB-", "as", "far", "as", "we", "know", ",", "there", "is", "no", "previous", "work", "which", "tries", "to", "use", "GAN", "to", "achieve", "topic", "modeling", ",", "which", "is", "a", "worth", "exploring", "direction", ".", "-LRB-", "b", "-RRB-", "Some", "extra", "tricks", "for", "Info-GAN", "training", "-LRB-", "c", "-RRB-", "Two", "steps", "generation", "of", "text", "may", "also", "be", "a", "better", "and", "easier", "method", "for", "generating", "text", ".", "-LRB-", "4", "-RRB-", "Evaluation", ":", "We", "have", "evaluated", "the", "topic", "coherence", "score", "and", "reported", "the", "score", "on", "revised", "paper", "Table", "3", ".", "Our", "method", "outperformed", "baseline", "method", "on", "all", "datasets", ",", "which", "implies", "the", "effectiveness", "of", "our", "proposed", "topic", "model", ".", "When", "conducting", "human", "evaluation", "to", "evaluate", "the", "quality", "of", "sentences", ",", "we", "asked", "17", "annotators", "to", "compare", "13", "sets", "of", "sentences", "generated", "by", "different", "methods", "."], "comment_id": "B1eCntlsRQ"}, {"rels": [[0, 6, 6, 26, "purpose"], [6, 14, 14, 26, "same_unit"], [6, 10, 10, 14, "elaboration"], [14, 26, 6, 14, "same_unit"], [14, 21, 21, 26, "purpose"], [21, 25, 25, 26, "elaboration"], [0, 26, 26, 1583, "elaboration"], [26, 31, 31, 54, "elaboration"], [31, 39, 39, 54, "elaboration"], [26, 54, 54, 78, "means"], [26, 78, 78, 1583, "elaboration"], [78, 89, 89, 1583, "elaboration"], [89, 92, 92, 101, "elaboration"], [92, 96, 96, 101, "purpose"], [89, 101, 101, 1583, "elaboration"], [101, 121, 121, 1583, "elaboration"], [121, 126, 126, 131, "purpose"], [121, 131, 131, 144, "elaboration"], [121, 144, 144, 1583, "elaboration"], [144, 148, 148, 1583, "elaboration"], [150, 188, 148, 150, "attribution"], [150, 166, 166, 188, "contrast"], [150, 163, 163, 166, "elaboration"], [166, 188, 150, 166, "contrast"], [166, 171, 171, 188, "elaboration"], [148, 188, 188, 198, "elaboration"], [148, 198, 198, 1583, "elaboration"], [198, 214, 214, 230, "same_unit"], [198, 211, 211, 214, "same_unit"], [198, 206, 206, 211, "elaboration"], [211, 214, 198, 211, "same_unit"], [214, 230, 198, 214, "same_unit"], [214, 220, 220, 230, "elaboration"], [220, 229, 229, 230, "same_unit"], [220, 221, 221, 223, "elaboration"], [220, 223, 223, 229, "elaboration"], [229, 230, 220, 229, "same_unit"], [198, 230, 230, 1583, "elaboration"], [230, 261, 261, 1583, "elaboration"], [261, 266, 266, 282, "purpose"], [261, 282, 282, 1583, "explanation"], [282, 288, 288, 301, "purpose"], [288, 292, 292, 301, "elaboration"], [282, 301, 301, 313, "elaboration"], [282, 313, 313, 1583, "elaboration"], [313, 318, 318, 331, "means"], [318, 324, 324, 331, "elaboration"], [313, 331, 331, 1583, "elaboration"], [338, 346, 331, 338, "attribution"], [331, 346, 346, 1583, "elaboration"], [346, 368, 368, 1583, "elaboration"], [368, 386, 386, 1583, "list"], [386, 1583, 368, 386, "list"], [386, 391, 391, 405, "purpose"], [386, 405, 405, 1583, "elaboration"], [405, 418, 418, 434, "purpose"], [405, 434, 434, 1583, "elaboration"], [438, 449, 434, 438, "attribution"], [434, 449, 449, 1583, "elaboration"], [449, 486, 486, 493, "elaboration"], [449, 493, 493, 494, "elaboration"], [449, 494, 494, 1583, "elaboration"], [496, 538, 494, 496, "attribution"], [496, 499, 499, 538, "elaboration"], [499, 512, 512, 538, "elaboration"], [512, 523, 523, 538, "same_unit"], [512, 516, 516, 523, "elaboration"], [523, 538, 512, 523, "same_unit"], [523, 525, 525, 538, "elaboration"], [525, 532, 532, 538, "elaboration"], [494, 538, 538, 1583, "elaboration"], [538, 539, 539, 540, "elaboration"], [538, 540, 540, 547, "elaboration"], [538, 547, 547, 1583, "elaboration"], [547, 548, 548, 549, "elaboration"], [547, 549, 549, 573, "elaboration"], [549, 557, 557, 573, "elaboration"], [557, 566, 566, 573, "list"], [566, 573, 557, 566, "list"], [547, 573, 573, 1583, "example"], [573, 585, 585, 1583, "same_unit"], [573, 575, 575, 585, "elaboration"], [585, 1583, 573, 585, "same_unit"], [585, 601, 601, 1583, "list"], [585, 600, 600, 601, "elaboration"], [601, 1583, 585, 601, "list"], [601, 614, 614, 1583, "textualorganization"], [614, 1583, 601, 614, "textualorganization"], [614, 616, 616, 1583, "textualorganization"], [616, 1583, 614, 616, "textualorganization"], [616, 643, 643, 1583, "elaboration"], [643, 655, 655, 1583, "list"], [655, 1583, 643, 655, "list"], [655, 662, 662, 1583, "list"], [662, 1583, 655, 662, "list"], [662, 713, 713, 1583, "topic"], [662, 674, 674, 713, "question"], [674, 713, 662, 674, "question"], [674, 675, 675, 713, "elaboration"], [675, 679, 679, 713, "elaboration"], [679, 691, 691, 713, "elaboration"], [691, 696, 696, 713, "elaboration"], [696, 700, 700, 713, "elaboration"], [713, 1583, 662, 713, "topic"], [713, 1386, 1386, 1583, "list"], [713, 715, 715, 1386, "elaboration"], [715, 730, 730, 1386, "elaboration"], [732, 754, 730, 732, "attribution"], [732, 737, 737, 754, "elaboration"], [737, 747, 747, 754, "list"], [747, 754, 737, 747, "list"], [730, 754, 754, 1386, "elaboration"], [762, 771, 754, 762, "attribution"], [762, 767, 767, 771, "elaboration"], [754, 771, 771, 1386, "elaboration"], [771, 773, 773, 1386, "elaboration"], [773, 788, 788, 792, "elaboration"], [773, 792, 792, 1386, "elaboration"], [792, 799, 799, 1386, "textualorganization"], [799, 1386, 792, 799, "textualorganization"], [799, 801, 801, 803, "elaboration"], [799, 803, 803, 1386, "elaboration"], [803, 831, 831, 837, "elaboration"], [803, 837, 837, 1386, "elaboration"], [837, 845, 845, 867, "elaboration"], [845, 846, 846, 867, "elaboration"], [846, 861, 861, 867, "elaboration"], [837, 867, 867, 1386, "elaboration"], [867, 871, 871, 879, "elaboration"], [867, 879, 879, 1386, "elaboration"], [879, 880, 880, 890, "elaboration"], [880, 886, 886, 890, "elaboration"], [879, 890, 890, 896, "elaboration"], [890, 892, 892, 896, "elaboration"], [879, 896, 896, 1386, "elaboration"], [896, 898, 898, 954, "elaboration"], [898, 900, 900, 922, "list"], [900, 922, 898, 900, "list"], [900, 905, 905, 922, "list"], [905, 922, 900, 905, "list"], [905, 917, 917, 922, "elaboration"], [898, 922, 922, 954, "elaboration"], [922, 932, 932, 954, "elaboration"], [936, 954, 932, 936, "attribution"], [936, 944, 944, 954, "list"], [944, 954, 936, 944, "list"], [944, 950, 950, 954, "list"], [950, 954, 944, 950, "list"], [896, 954, 954, 1386, "elaboration"], [954, 961, 961, 969, "purpose"], [961, 965, 965, 969, "elaboration"], [954, 969, 969, 1386, "elaboration"], [969, 971, 971, 1007, "elaboration"], [971, 987, 987, 1007, "elaboration"], [987, 991, 991, 1007, "purpose"], [969, 1007, 1007, 1386, "elaboration"], [1007, 1027, 1027, 1098, "list"], [1007, 1014, 1014, 1027, "purpose"], [1014, 1018, 1018, 1027, "elaboration"], [1027, 1098, 1007, 1027, "list"], [1027, 1029, 1029, 1098, "elaboration"], [1029, 1058, 1058, 1069, "elaboration"], [1058, 1062, 1062, 1069, "elaboration"], [1029, 1069, 1069, 1098, "reason"], [1069, 1077, 1077, 1082, "elaboration"], [1069, 1082, 1082, 1098, "elaboration"], [1082, 1089, 1089, 1098, "same_unit"], [1082, 1086, 1086, 1089, "elaboration"], [1089, 1098, 1082, 1089, "same_unit"], [1007, 1098, 1098, 1386, "elaboration"], [1098, 1109, 1109, 1386, "elaboration"], [1133, 1137, 1109, 1133, "attribution"], [1109, 1114, 1114, 1133, "elaboration"], [1114, 1129, 1129, 1132, "elaboration"], [1114, 1132, 1132, 1133, "means"], [1109, 1137, 1137, 1386, "elaboration"], [1137, 1150, 1150, 1180, "elaboration"], [1152, 1180, 1150, 1152, "attribution"], [1152, 1163, 1163, 1180, "elaboration"], [1163, 1171, 1171, 1180, "purpose"], [1171, 1174, 1174, 1180, "purpose"], [1137, 1180, 1180, 1386, "elaboration"], [1180, 1191, 1191, 1203, "list"], [1191, 1203, 1180, 1191, "list"], [1193, 1203, 1191, 1193, "attribution"], [1180, 1203, 1203, 1386, "elaboration"], [1203, 1205, 1205, 1386, "textualorganization"], [1203, 1204, 1204, 1205, "elaboration"], [1205, 1386, 1203, 1205, "textualorganization"], [1205, 1216, 1216, 1386, "question"], [1216, 1386, 1205, 1216, "question"], [1216, 1217, 1217, 1218, "elaboration"], [1216, 1218, 1218, 1280, "elaboration"], [1218, 1220, 1220, 1245, "elaboration"], [1220, 1234, 1234, 1245, "elaboration"], [1218, 1245, 1245, 1280, "elaboration"], [1245, 1250, 1250, 1280, "elaboration"], [1250, 1266, 1266, 1280, "same_unit"], [1250, 1253, 1253, 1266, "elaboration"], [1266, 1280, 1250, 1266, "same_unit"], [1216, 1280, 1280, 1386, "elaboration"], [1280, 1282, 1282, 1303, "elaboration"], [1282, 1286, 1286, 1303, "purpose"], [1286, 1290, 1290, 1303, "elaboration"], [1280, 1303, 1303, 1386, "elaboration"], [1303, 1305, 1305, 1318, "elaboration"], [1310, 1318, 1305, 1310, "attribution"], [1310, 1311, 1311, 1318, "elaboration"], [1303, 1318, 1318, 1386, "elaboration"], [1318, 1341, 1341, 1386, "elaboration"], [1341, 1343, 1343, 1368, "elaboration"], [1343, 1352, 1352, 1368, "elaboration"], [1354, 1368, 1352, 1354, "attribution"], [1341, 1368, 1368, 1386, "elaboration"], [1377, 1386, 1368, 1377, "attribution"], [1386, 1583, 713, 1386, "list"], [1386, 1390, 1390, 1395, "elaboration"], [1390, 1391, 1391, 1395, "elaboration"], [1386, 1395, 1395, 1583, "elaboration"], [1395, 1415, 1415, 1423, "same_unit"], [1395, 1407, 1407, 1415, "elaboration"], [1415, 1423, 1395, 1415, "same_unit"], [1395, 1423, 1423, 1583, "elaboration"], [1423, 1425, 1425, 1583, "elaboration"], [1427, 1436, 1425, 1427, "attribution"], [1425, 1436, 1436, 1583, "elaboration"], [1440, 1463, 1436, 1440, "attribution"], [1436, 1463, 1463, 1583, "elaboration"], [1463, 1485, 1485, 1583, "list"], [1463, 1478, 1478, 1485, "elaboration"], [1485, 1583, 1463, 1485, "list"], [1485, 1487, 1487, 1583, "list"], [1487, 1583, 1485, 1487, "list"], [1507, 1583, 1487, 1507, "attribution"], [1507, 1520, 1520, 1583, "question"], [1513, 1520, 1507, 1513, "attribution"], [1520, 1583, 1507, 1520, "question"], [1521, 1558, 1520, 1521, "attribution"], [1527, 1558, 1521, 1527, "attribution"], [1527, 1542, 1542, 1558, "elaboration"], [1542, 1549, 1549, 1558, "purpose"], [1520, 1558, 1558, 1583, "elaboration"], [1558, 1566, 1566, 1583, "elaboration"], [1566, 1577, 1577, 1583, "elaboration"]], "tokens": ["This", "works", "propose", "a", "new", "approach", "to", "learn", "to", "sample", "-LRB-", "or", "generate", "-RRB-", "the", "parameters", "of", "a", "deep", "neural", "networks", "to", "solve", "a", "task", ".", "They", "propose", "a", "new", "architecture", "inspired", "by", "hyper", "networks", "and", "adversarial", "auto-encoders", ",", "where", "the", "parameters", "of", "the", "networks", "are", "generated", "from", "a", "low", "dimensional", "latent", "space", ".", "By", "using", "an", "ensemble", "of", "networks", "sampled", "with", "their", "approach", "they", "'re", "able", "to", "get", "state", "of", "the", "art", "results", "on", "uncertainty", "estimation", ".", "The", "notations", "are", "confusing", "and", "the", "paper", "contains", "several", "mistakes", ".", "In", "particular", ":", "-", "P_z", "is", "used", "to", "represent", "different", "distributions", ".", "It", "sometimes", "refers", "to", "the", "distribution", "of", "the", "latent", "variables", "and", "sometimes", "to", "the", "prior", "over", "the", "weight", "embeddings", ".", "Different", "notation", "should", "be", "used", "to", "represent", "different", "quantity", ".", "-", "D_z", "sometimes", "refers", "to", "the", "regularization", "term", "or", "to", "the", "discriminator", ".", "-", "Eq", "2", ".", "I", "believe", "there", "is", "a", "bug", "in", "the", "equation", ",", "the", "expectation", "is", "over", "Q", "-LRB-", "z", "-RRB-", "but", "it", "should", "be", "P_z", "-LRB-", "distribution", "of", "the", "latent", "variable", "z", "-RRB-", ",", "otherwise", "it", "does", "n't", "make", "much", "sense", ".", "-", "The", "equation", "for", "the", "cross", "entropy", "is", "wrong", ".", "If", "y_i", "are", "the", "true", "labels", "and", "F", "-LRB-", "x_i", ",", "theta", "-RRB-", "is", "the", "prediction", "then", "it", "should", "be", "y_i", "*", "log", "-LRB-", "F", "-LRB-", "x_i", ",", "theta", "-RRB-", "-RRB-", ".", "-", "It", "'s", "not", "clear", "if", "the", "loss", "of", "the", "discriminator", "should", "be", "maximized", "for", "the", "parameters", "of", "the", "discriminator", "and", "minimized", "with", "respect", "to", "the", "parameters", "of", "the", "encoder", ".", "Furthermore", "it", "would", "be", "interesting", "to", "study", "what", "is", "the", "impact", "of", "this", "particular", "choice", "of", "loss", "for", "the", "discriminator", ".", "In", "particular", "I", "invite", "the", "author", "to", "compare", "the", "loss", "proposed", "to", "the", "loss", "in", "-LSB-", "1", "-RSB-", ".", "Fixing", "these", ",", "would", "make", "the", "paper", "much", "easier", "to", "understand", ".", "The", "authors", "motivates", "their", "approach", "by", "drawing", "a", "link", "with", "wasserstein", "-LRB-", "WAE", "-RRB-", "and", "adversarial", "auto-encoders", ".", "While", "this", "could", "be", "interesting", "I", "think", "this", "link", "should", "be", "made", "more", "formal", ".", "Indeed", ",", "the", "WAE", "is", "derived", "from", "the", "wasserstein", "distance", "between", "the", "true", "data", "distribution", "and", "the", "distribution", "of", "the", "model", ".", "However", "it", "'s", "not", "clear", "if", "the", "approach", "proposed", "can", "still", "be", "derived", "from", "such", "a", "principle", ".", "I", "would", "invite", "the", "author", "to", "make", "the", "link", "between", "wasserstein", "distance", "minimization", "and", "their", "approach", "more", "explicit", ".", "To", "my", "knowledge", "the", "method", "proposed", "is", "novel", ",", "however", "using", "implicit", "posterior", "to", "learn", "the", "weights", "is", "not", "novel", "and", "several", "other", "works", "have", "looked", "at", "it", ".", "In", "particular", "I", "think", "-LSB-", "1,2", "-RSB-", "should", "be", "discussed", "in", "the", "related", "work", ".", "The", "difference", "with", "traditional", "bayesian", "approach", "such", "as", "variational", "inference", "should", "also", "be", "discussed", ",", "since", "the", "approach", "is", "really", "close", "to", "approximating", "the", "posterior", "with", "an", "implicit", "distribution", "and", "computing", "the", "KL", "term", "using", "a", "GAN", "-LRB-", "like", "in", "-LSB-", "3,4", "-RSB-", "-RRB-", ".", "I", "think", "one", "interesting", "novelty", "that", "needs", "to", "be", "emphasized", "is", "that", "the", "model", "has", "both", ":", "parameters", "that", "are", "point", "estimates", "-LRB-", "the", "parameters", "of", "the", "generators", "-RRB-", "and", "parameters", "that", "are", "sampled", "from", "a", "posterior", "distribution", "-LRB-", "the", "weight", "embeddings", "-RRB-", ".", "Pros", ":", "-", "Good", "and", "promising", "experimental", "results", ".", "Cons", ":", "-", "The", "paper", "combines", "several", "tricks", "and", "ideas", "but", "it", "'s", "not", "really", "clear", "what", "is", "important", "and", "why", "such", "an", "approach", "works", ".", "For", "example", "how", "important", "is", "the", "latent", "space", "and", "the", "encoder", "?", "Could", "we", "just", "sample", "directly", "the", "weight", "embeddings", "from", "a", "gaussian", "and", "remove", "the", "regularization", "?", "-", "The", "other", "points", "mentioned", "above", "about", "the", "clarity", "of", "the", "paper", ".", "Others", ":", "-", "The", "title", "is", "misleading", ",", "the", "manifold", "is", "not", "really", "explored", "...", "If", "the", "author", "really", "want", "to", "explore", "the", "manifold", "some", "interesting", "questions", "are", ":", "what", "happens", "if", "we", "try", "to", "interpolate", "between", "two", "latent", "variables", "?", "What", "do", "the", "latent", "variables", "represent", "?", "what", "'s", "the", "influence", "of", "the", "dimension", "of", "the", "latent", "space", "?", "-", "In", "the", "experiments", ":", "what", "is", "the", "number", "of", "networks", "used", "for", "the", "other", "methods", "?", "-", "It", "would", "be", "nice", "to", "have", "a", "plot", "showing", "the", "accuracy", "as", "a", "function", "of", "the", "perturbation", "in", "section", "4.5", ".", "Conclusion", ":", "The", "experimental", "results", "seem", "promising", "however", "the", "motivation", "for", "the", "approach", "is", "not", "clear", ".", "I", "think", "fixing", "some", "of", "the", "points", "mentioned", "above", "could", "greatly", "improve", "the", "clarity", "of", "the", "paper", "and", "make", "it", "a", "stronger", "submission", ".", "In", "the", "current", "state", "I", "do", "n't", "believe", "the", "paper", "is", "rigorous", "enough", "to", "be", "accepted", ".", "References", ":", "-LSB-", "1", "-RSB-", "Pawlowski", ",", "N.", ",", "Rajchl", ",", "M.", ",", "&", "Glocker", ",", "B.", "-LRB-", "2017", "-RRB-", ".", "Implicit", "weight", "uncertainty", "in", "neural", "networks", ".", "arXiv", ":", "1711.01297", ".", "-LSB-", "2", "-RSB-", "Wang", ",", "K.", "C.", ",", "Vicol", ",", "P.", ",", "Lucas", ",", "J.", ",", "Gu", ",", "L.", ",", "Grosse", ",", "R.", ",", "&", "Zemel", ",", "R.", "-LRB-", "2018", ",", "July", "-RRB-", ".", "Adversarial", "Distillation", "of", "Bayesian", "Neural", "Network", "Posteriors", ".", "ICML", "-LSB-", "3", "-RSB-", "Mescheder", ",", "L.", ",", "Nowozin", ",", "S.", ",", "&", "Geiger", ",", "A.", "-LRB-", "2017", ",", "July", "-RRB-", ".", "Adversarial", "Variational", "Bayes", ":", "Unifying", "Variational", "Autoencoders", "and", "Generative", "Adversarial", "Networks", ".", "ICML", "-LSB-", "4", "-RSB-", "Huszr", ",", "F.", "-LRB-", "2017", "-RRB-", ".", "Variational", "inference", "using", "implicit", "distributions", ".", "arXiv", ":", "1702.08235", ".", "We", "have", "revised", "the", "manuscript", "and", "addressed", "the", "notation", "and", "terminology", "concerns", "as", "well", "as", "the", "comments", "made", "by", "other", "reviewers", ".", "We", "have", "improved", "these", "to", "better", "describe", "our", "method", ".", "We", "would", "really", "appreciate", "if", "you", "can", "read", "the", "new", "Section", "3", "and", "give", "us", "a", "new", "evaluation", "and", "further", "feedback", ".", "With", "the", "revision", ",", "we", "still", "want", "to", "answer", "the", "questions", "laid", "out", "here", ".", "Question", ":", "The", "difference", "between", "a", "traditional", "Bayesian", "approach", "such", "as", "variational", "inference", "should", "also", "be", "discussed", ".", "It", "would", "be", "interesting", "to", "study", "what", "is", "the", "impact", "of", "this", "particular", "choice", "of", "loss", "for", "the", "discriminator", ".", "In", "particular", ",", "I", "invite", "the", "author", "to", "compare", "the", "loss", "proposed", "to", "the", "loss", "in", "-LSB-", "1", "-RSB-", ".", "Answer", ":", "From", "the", "new", "description", "one", "can", "see", "that", "there", "is", "a", "significant", "difference", "between", "our", "approach", "and", "variational", "Bayesian", "approach", "in", "that", "we", "never", "explicitly", "model", "the", "KL-divergence", "term", "that", "comes", "from", "p", "-LRB-", "z", "|", "\\", "theta", "-RRB-", ",", "because", "we", "do", "not", "have", "explicit", "theta", "samples", "nor", "had", "an", "encoder", ".", "In", "Bayes", "by", "Hypernetwork", "-LRB-", "BbH", "-RRB-", "-LSB-", "1", "-RSB-", ",", "we", "note", "two", "differences", ".", "First", ",", "the", "prior", "matching", "step", "treats", "each", "weight", "independently", ".", "This", "is", "different", "from", "HyperGAN", "where", "we", "perform", "the", "prior", "matching", "step", "between", "the", "prior", "and", "the", "continuous", "mixture", "Q", "-LRB-", "s", "-RRB-", "using", "the", "adversarial", "loss", ".", "Second", ",", "BbH", "uses", "independent", "noise", "samples", "as", "input", "to", "the", "generators", ".", "We", "found", "that", "this", "configuration", "hurt", "the", "diversity", "of", "our", "generated", "networks", ",", "which", "is", "why", "we", "use", "the", "mixer", "Q", "to", "introduce", "correlations", "to", "our", "single", "noise", "sample", ".", "In", "Table", "3", "and", "4", "we", "compare", "against", "using", "independent", "generators", "and", "find", "that", "we", "lose", "significant", "diversity", "in", "our", "generated", "ensembles", ".", "Question", ":", "What", "is", "the", "number", "of", "networks", "used", "for", "other", "methods", "?", "Answer", ":", "Each", "other", "-LRB-", "non-HyperGAN", "-RRB-", "method", "in", "Table", "2", "uses", "the", "mean", "of", "100", "samples", ",", "which", "corresponds", "to", "our", "strongest", "considered", "ensemble", "of", "100", "networks", ".", "We", "only", "used", "10", "networks", "for", "the", "L2", "-LRB-", "standard", "-RRB-", "ensembles", "in", "the", "adversarial", "detection", "experiments", "in", "Sec.", "4.5", ",", "because", "of", "the", "prohibitive", "cost", "of", "training", "100", "neural", "networks", "on", "each", "task", ".", "Question", ":", "It", "would", "be", "nice", "to", "have", "a", "plot", "showing", "the", "accuracy", "as", "a", "function", "of", "the", "perturbation", "in", "section", "4.5", ".", "Answer", ":", "We", "tested", "only", "on", "adversarial", "examples", "which", "succeeded", "in", "fooling", "our", "ensemble", ".", "This", "means", "the", "accuracy", "of", "the", "ensemble", "predictions", "under", "all", "perturbation", "levels", "is", "0", ",", "so", "we", "chose", "not", "to", "plot", "it", ".", "Question", ":", "Title", "is", "inaccurate", "We", "have", "also", "edited", "the", "title", "to", "reflect", "that", "we", "are", "generating", "diverse", "neural", "networks", ",", "instead", "of", "a", "whole", "manifold", ".", "-LSB-", "1", "-RSB-", "Pawlowski", ",", "Nick", ",", "et", "al.", "TICKTICK", "Implicit", "weight", "uncertainty", "in", "neural", "networks", ".", "''", "arXiv", "preprint", "arXiv", ":", "1711.01297", "-LRB-", "2017", "-RRB-", ".", "Thanks", "for", "the", "clarifications", ",", "the", "section", "3", "has", "been", "greatly", "improved", "-LRB-", "thus", "I", "slightly", "increased", "my", "score", "-RRB-", "but", "there", "is", "still", "room", "for", "improvement", ".", "1", ".", "I", "think", "the", "section", "3.1", "is", "unclear", "and", "potentially", "unnecessary", ".", "It", "is", "well", "known", "that", "minimizing", "the", "KL", "between", "the", "true", "data", "distribution", "and", "the", "model", "is", "equivalent", "to", "maximizing", "the", "log", "likelihood", "of", "the", "model", ".", "Plus", "there", "is", "a", "mistake", "in", "equation", "6", "the", "expectation", "should", "be", "taken", "over", "p", "-LRB-", "x", "|", "\\", "theta", "-RRB-", ".", "2", ".", "I", "'m", "not", "sure", "to", "understand", "table", "3", "&", "4", ",", "do", "you", "sample", "the", "q_n", "directly", "from", "P", "?", "If", "so", "I", "do", "n't", "understand", "why", "this", "would", "TICKTICK", "collapse", "''", "?", "since", "you", "actually", "argue", "in", "section", "3", "that", "TICKTICK", "This", "constraint", "makes", "it", "closer", "to", "the", "generated", "parameters", "and", "ensures", "that", "Q", "-LRB-", "s", "-RRB-", "itself", "does", "not", "collapse", "to", "always", "outputting", "the", "same", "latent", "code", "''", ".", "As", "a", "note", "I", "recommend", "for", "next", "time", "that", "you", "do", "n't", "share", "your", "code", "through", "a", "GitHub", "link", "as", "this", "can", "compromise", "anonymity", "."], "comment_id": "B1e3U8GQJ4"}, {"rels": [[0, 12, 12, 199, "elaboration"], [12, 20, 20, 44, "list"], [20, 44, 12, 20, "list"], [20, 29, 29, 44, "elaboration"], [12, 44, 44, 199, "elaboration"], [44, 60, 60, 199, "elaboration"], [60, 70, 70, 199, "list"], [70, 199, 60, 70, "list"], [70, 78, 78, 199, "elaboration"], [78, 87, 87, 100, "purpose"], [87, 93, 93, 100, "elaboration"], [78, 100, 100, 199, "elaboration"], [100, 109, 109, 130, "elaboration"], [109, 113, 113, 130, "means"], [113, 119, 119, 130, "elaboration"], [119, 120, 120, 130, "elaboration"], [100, 130, 130, 199, "elaboration"], [135, 165, 130, 135, "attribution"], [135, 140, 140, 165, "list"], [140, 165, 135, 140, "list"], [155, 165, 140, 155, "attribution"], [140, 145, 145, 155, "elaboration"], [145, 151, 151, 155, "elaboration"], [155, 156, 156, 165, "elaboration"], [130, 165, 165, 199, "elaboration"], [165, 176, 176, 184, "means"], [165, 184, 184, 199, "elaboration"], [184, 193, 193, 199, "purpose"]], "tokens": ["This", "paper", "proposes", "an", "new", "8-bit", "quantization", "strategy", "for", "rapid", "deployment", ".", "8-bit", "quantization", "has", "attracted", "many", "attentions", "recently", ".", "And", "it", "is", "already", "well", "used", "in", "GPU", "servers", "-LRB-", "cudnn", "-RRB-", ",", "phones", ",", "ARM", "chips", "and", "various", "ASIC", "neural", "network", "chips", ".", "In", "these", "situations", ",", "almost", "no", "performance", "drop", "is", "observed", "for", "classification", "and", "detection", "tasks", ".", "So", ",", "the", "novelty", "of", "this", "paper", "is", "limited", ".", "Thank", "you", "very", "much", "for", "your", "comments", ".", "Competing", "methods", "in", "other", "papers", "require", "retraining", "or", "needs", "to", "cope", "with", "high", "accuracy", "loss", "when", "quantized", "in", "a", "layer-wise", "fashion", ".", "The", "proposed", "method", "is", "the", "first", "of", "its", "kind", "to", "resolve", "these", "issues", "by", "incorporating", "channel-wise", "quantization", "and", "moment-analysis", "method", "which", "DOES", "NOT", "require", "retraining", "or", "the", "training", "dataset", ".", "Nave", "channel-wise", "quantization", "requires", "adding", "huge", "number", "of", "HW", "shifters", "and", "providing", "values", "for", "them", "which", "make", "it", "unrealistic", "for", "implementation", "-LRB-", "please", "see", "Figure", "1", "-LRB-", "b", "-RRB-", "in", "the", "revised", "manuscript", "-RRB-", ".", "The", "biggest", "contribution", "of", "our", "paper", "is", "the", "HW-friendly", "channel-wise", "quantization", "by", "manipulating", "the", "kernels", "prior", "to", "inference", ".", "For", "your", "reference", ",", "Figure", "1", "has", "been", "modified", "to", "make", "the", "distinction", "clearer", "."], "comment_id": "B1eFz3plRX"}, {"rels": [[0, 310, 310, 585, "topic"], [0, 15, 15, 310, "elaboration"], [15, 44, 44, 310, "elaboration"], [44, 56, 56, 310, "elaboration"], [56, 72, 72, 83, "elaboration"], [72, 73, 73, 83, "elaboration"], [73, 78, 78, 83, "elaboration"], [56, 83, 83, 310, "elaboration"], [83, 97, 97, 102, "means"], [83, 102, 102, 310, "elaboration"], [102, 125, 125, 310, "list"], [102, 110, 110, 125, "elaboration"], [110, 115, 115, 125, "attribution"], [125, 310, 102, 125, "list"], [125, 135, 135, 310, "elaboration"], [135, 143, 143, 310, "condition"], [143, 148, 148, 175, "elaboration"], [148, 158, 158, 175, "elaboration"], [143, 175, 175, 310, "elaboration"], [175, 186, 186, 310, "elaboration"], [186, 197, 197, 310, "list"], [197, 310, 186, 197, "list"], [197, 205, 205, 310, "elaboration"], [205, 207, 207, 310, "elaboration"], [207, 221, 221, 308, "list"], [207, 211, 211, 221, "elaboration"], [211, 218, 218, 221, "manner"], [221, 308, 207, 221, "list"], [221, 231, 231, 308, "elaboration"], [277, 308, 231, 277, "antithesis"], [231, 253, 253, 277, "elaboration"], [277, 290, 290, 308, "elaboration"], [207, 308, 308, 310, "elaboration"], [310, 585, 0, 310, "topic"], [310, 317, 317, 426, "condition"], [317, 322, 322, 351, "elaboration"], [322, 332, 332, 351, "elaboration"], [317, 351, 351, 426, "elaboration"], [351, 362, 362, 426, "elaboration"], [362, 373, 373, 387, "elaboration"], [373, 378, 378, 387, "purpose"], [378, 382, 382, 387, "elaboration"], [362, 387, 387, 426, "elaboration"], [387, 392, 392, 403, "condition"], [387, 403, 403, 426, "elaboration"], [403, 409, 409, 426, "elaboration"], [409, 411, 411, 426, "manner"], [411, 413, 413, 426, "list"], [413, 426, 411, 413, "list"], [415, 426, 413, 415, "attribution"], [310, 426, 426, 585, "elaboration"], [426, 428, 428, 585, "list"], [428, 585, 426, 428, "list"], [428, 440, 440, 585, "elaboration"], [440, 467, 467, 585, "list"], [440, 456, 456, 467, "elaboration"], [456, 457, 457, 467, "elaboration"], [457, 462, 462, 467, "elaboration"], [467, 585, 440, 467, "list"], [467, 481, 481, 486, "means"], [467, 486, 486, 585, "elaboration"], [486, 487, 487, 492, "elaboration"], [486, 492, 492, 517, "elaboration"], [486, 517, 517, 585, "elaboration"], [519, 531, 517, 519, "attribution"], [517, 531, 531, 585, "elaboration"], [531, 547, 547, 585, "elaboration"], [547, 556, 556, 585, "list"], [550, 556, 547, 550, "attribution"], [556, 585, 547, 556, "list"], [558, 585, 556, 558, "attribution"], [558, 564, 564, 585, "circumstance"]], "tokens": ["This", "paper", "studies", "the", "effect", "of", "batch", "normalization", "via", "a", "physics", "style", "mean-field", "theory", ".", "The", "theory", "yields", "a", "prediction", "of", "maximal", "learning", "rate", "for", "fully-connected", "and", "convolutional", "networks", ",", "and", "experimentally", "the", "max", "learning", "rate", "agrees", "very", "well", "with", "the", "theoretical", "prediction", ".", "This", "is", "a", "well-written", "paper", "with", "a", "clean", ",", "novel", "result", ":", "when", "we", "fix", "the", "BatchNorm", "parameter", "\\", "gamma", ",", "a", "smaller", "\\", "gamma", "stabilizes", "the", "training", "better", "-LRB-", "allowing", "a", "greater", "range", "of", "learning", "rates", "-RRB-", ".", "Though", "in", "practice", "the", "BatchNorm", "parameters", "are", "also", "trained", ",", "this", "result", "may", "suggest", "using", "a", "smaller", "initialization", ".", "A", "couple", "of", "things", "I", "was", "wondering", ":", "--", "As", "a", "baseline", ",", "how", "would", "the", "max", "learning", "rate", "behave", "without", "BatchNorm", "?", "Would", "the", "theories", "again", "match", "the", "experimental", "result", "there", "?", "--", "Is", "the", "presence", "of", "momentum", "important", "?", "If", "I", "set", "the", "momentum", "to", "be", "zero", ",", "it", "does", "not", "change", "the", "theory", "about", "the", "Fisher", "information", "and", "only", "affects", "the", "dependence", "of", "\\", "eta", "on", "the", "Fisher", "information", ".", "In", "this", "case", "would", "the", "theory", "still", "match", "the", "experiments", "?", "Thank", "you", "very", "much", "for", "your", "review", "and", "valuable", "comments", ".", "We", "address", "your", "questions", "and", "comments", "below", ":", "1", ".", "As", "a", "baseline", ",", "how", "would", "the", "max", "learning", "rate", "behave", "without", "BatchNorm", "?", "Would", "the", "theories", "again", "match", "the", "experimental", "result", "there", "?", "We", "also", "wondered", "how", "the", "max", "learning", "rate", "would", "behave", "without", "BatchNorm", ",", "and", "thus", "we", "did", "an", "experiment", "for", "a", "network", "without", "BatchNorm", "where", "we", "varied", "\\", "sigma_w", ",", "the", "weight", "initialization", "variance", ",", "and", "found", "that", "the", "theory", "again", "matches", "the", "experimental", "result", ".", "However", ",", "we", "did", "n't", "include", "this", "result", "in", "the", "previous", "draft", ".", "We", "have", "now", "added", "this", "result", "to", "the", "SM", "in", "the", "new", "revised", "version", "as", "a", "baseline", ".", "2", ".", "Is", "the", "presence", "of", "momentum", "important", "?", "If", "I", "set", "the", "momentum", "to", "be", "zero", ",", "it", "does", "not", "change", "the", "theory", "about", "the", "Fisher", "information", "and", "only", "affects", "the", "dependence", "of", "$", "\\", "eta", "$", "on", "the", "Fisher", "information", ".", "In", "this", "case", "would", "the", "theory", "still", "match", "the", "experiments", "?", "The", "presence", "of", "momentum", "does", "n't", "change", "the", "picture", "dramatically", ".", "We", "set", "momentum", "to", "0.9", "to", "match", "the", "value", "frequently", "used", "in", "practice", ".", "Indeed", ",", "changing", "the", "momentum", "only", "affects", "the", "dependency", "of", "\\", "eta", "on", "the", "FIM", ".", "We", "have", "performed", "an", "additional", "experiment", "on", "training", "without", "momentum", "and", "find", "that", "in", "this", "case", "the", "theory", "still", "matches", "the", "experiment", ".", "3", ".", "This", "is", "a", "well-written", "paper", "with", "a", "clean", ",", "novel", "result", ":", "when", "we", "fix", "the", "BatchNorm", "parameter", "\\", "gamma", ",", "a", "smaller", "\\", "gamma", "stabilizes", "the", "training", "better", "-LRB-", "allowing", "a", "greater", "range", "of", "learning", "rates", "-RRB-", ".", "Though", "in", "practice", "the", "BatchNorm", "parameters", "are", "also", "trained", ",", "this", "result", "may", "suggest", "using", "a", "smaller", "initialization", ".", "Thanks", "for", "the", "positive", "feedback", "!", "We", "performed", "additional", "experiments", "in", "the", "updated", "version", "of", "our", "paper", "with", "VGG11", "and", "Preact-Resnet18", ",", "with", "various", "\\", "gamma-initializations", ",", "trained", "on", "CIFAR-10", ".", "We", "find", "that", "the", "smaller", "\\", "gamma-initialization", "indeed", "increase", "the", "speed", "of", "convergence", ".", "This", "result", "can", "be", "found", "in", "the", "SM", "of", "the", "latest", "version", "of", "our", "paper", ".", "Thank", "you", "again", "for", "your", "review", "and", "comments", ".", "We", "believe", "that", "the", "inclusion", "of", "a", "baseline", "without", "BatchNorm", "as", "well", "as", "clarification", "on", "the", "role", "of", "momentum", "has", "improved", "the", "results", "and", "clarity", "of", "the", "paper", "."], "comment_id": "B1e2x7XI6m"}, {"rels": [[0, 19, 19, 52, "elaboration"], [19, 23, 23, 52, "elaboration"], [23, 38, 38, 52, "elaboration"], [38, 44, 44, 52, "list"], [44, 52, 38, 44, "list"], [44, 47, 47, 52, "means"], [0, 52, 52, 1483, "elaboration"], [52, 70, 70, 76, "list"], [70, 76, 52, 70, "list"], [52, 76, 76, 1483, "elaboration"], [76, 86, 86, 1483, "elaboration"], [86, 91, 91, 1483, "elaboration"], [91, 96, 96, 108, "elaboration"], [96, 101, 101, 108, "list"], [101, 108, 96, 101, "list"], [91, 108, 108, 133, "elaboration"], [108, 120, 120, 133, "means"], [91, 133, 133, 1483, "elaboration"], [133, 141, 141, 1483, "list"], [141, 1483, 133, 141, "list"], [141, 143, 143, 1483, "list"], [143, 1483, 141, 143, "list"], [143, 154, 154, 162, "elaboration"], [143, 162, 162, 242, "elaboration"], [162, 170, 170, 242, "elaboration"], [170, 175, 175, 242, "elaboration"], [175, 180, 180, 199, "elaboration"], [180, 183, 183, 199, "elaboration"], [175, 199, 199, 242, "elaboration"], [205, 221, 199, 205, "attribution"], [199, 221, 221, 242, "elaboration"], [224, 242, 221, 224, "attribution"], [224, 229, 229, 242, "purpose"], [229, 232, 232, 242, "elaboration"], [143, 242, 242, 1483, "elaboration"], [242, 244, 244, 1483, "list"], [244, 1483, 242, 244, "list"], [244, 255, 255, 267, "elaboration"], [244, 267, 267, 1483, "elaboration"], [267, 285, 285, 1483, "elaboration"], [285, 327, 327, 1483, "list"], [285, 302, 302, 327, "elaboration"], [305, 327, 302, 305, "attribution"], [305, 312, 312, 327, "list"], [312, 327, 305, 312, "list"], [327, 1483, 285, 327, "list"], [327, 329, 329, 1483, "elaboration"], [329, 337, 337, 1483, "elaboration"], [337, 346, 346, 1483, "list"], [346, 1483, 337, 346, "list"], [346, 359, 359, 371, "list"], [359, 371, 346, 359, "list"], [346, 371, 371, 1483, "elaboration"], [371, 434, 434, 1483, "list"], [371, 381, 381, 403, "elaboration"], [381, 389, 389, 403, "elaboration"], [371, 403, 403, 434, "elaboration"], [403, 411, 411, 413, "elaboration"], [403, 413, 413, 434, "elaboration"], [434, 1483, 371, 434, "list"], [434, 436, 436, 1483, "list"], [436, 1483, 434, 436, "list"], [436, 444, 444, 1483, "elaboration"], [444, 455, 455, 1483, "list"], [444, 446, 446, 455, "elaboration"], [455, 1483, 444, 455, "list"], [455, 459, 459, 1483, "elaboration"], [459, 479, 479, 490, "elaboration"], [459, 490, 490, 1483, "elaboration"], [490, 507, 507, 526, "elaboration"], [507, 518, 518, 526, "elaboration"], [490, 526, 526, 1483, "elaboration"], [534, 556, 526, 534, "attribution"], [534, 544, 544, 556, "same_unit"], [534, 535, 535, 544, "elaboration"], [544, 556, 534, 544, "same_unit"], [544, 548, 548, 556, "elaboration"], [526, 556, 556, 1483, "elaboration"], [556, 565, 565, 576, "elaboration"], [556, 576, 576, 1483, "elaboration"], [576, 602, 602, 1483, "elaboration"], [610, 619, 602, 610, "attribution"], [602, 619, 619, 749, "elaboration"], [619, 626, 626, 749, "list"], [619, 623, 623, 626, "purpose"], [626, 749, 619, 626, "list"], [626, 637, 637, 648, "elaboration"], [626, 648, 648, 749, "elaboration"], [680, 749, 648, 680, "attribution"], [648, 656, 656, 680, "elaboration"], [656, 660, 660, 680, "elaboration"], [660, 671, 671, 680, "elaboration"], [680, 708, 708, 749, "elaboration"], [708, 733, 733, 749, "elaboration"], [602, 749, 749, 1483, "elaboration"], [749, 758, 758, 776, "elaboration"], [758, 764, 764, 776, "elaboration"], [764, 768, 768, 776, "elaboration"], [749, 776, 776, 1483, "elaboration"], [776, 783, 783, 795, "elaboration"], [776, 795, 795, 1483, "elaboration"], [795, 834, 834, 849, "elaboration"], [834, 835, 835, 849, "elaboration"], [795, 849, 849, 1483, "elaboration"], [851, 890, 849, 851, "attribution"], [849, 890, 890, 1483, "elaboration"], [890, 906, 906, 1483, "elaboration"], [906, 925, 925, 1483, "list"], [906, 910, 910, 925, "elaboration"], [925, 1483, 906, 925, "list"], [925, 938, 938, 950, "list"], [938, 950, 925, 938, "list"], [925, 950, 950, 1002, "elaboration"], [950, 957, 957, 967, "elaboration"], [950, 967, 967, 1002, "elaboration"], [967, 972, 972, 1002, "elaboration"], [972, 976, 976, 1002, "elaboration"], [976, 981, 981, 1002, "elaboration"], [983, 1002, 981, 983, "attribution"], [983, 984, 984, 1002, "same_unit"], [984, 1002, 983, 984, "same_unit"], [984, 990, 990, 1002, "elaboration"], [925, 1002, 1002, 1483, "elaboration"], [1002, 1006, 1006, 1483, "elaboration"], [1008, 1022, 1006, 1008, "attribution"], [1006, 1022, 1022, 1483, "elaboration"], [1022, 1041, 1041, 1483, "topic"], [1022, 1029, 1029, 1041, "elaboration"], [1041, 1483, 1022, 1041, "topic"], [1045, 1073, 1041, 1045, "attribution"], [1057, 1073, 1045, 1057, "attribution"], [1057, 1065, 1065, 1073, "elaboration"], [1041, 1073, 1073, 1483, "elaboration"], [1073, 1097, 1097, 1483, "topic"], [1073, 1077, 1077, 1097, "elaboration"], [1083, 1097, 1077, 1083, "attribution"], [1083, 1090, 1090, 1097, "purpose"], [1092, 1097, 1090, 1092, "attribution"], [1097, 1483, 1073, 1097, "topic"], [1097, 1114, 1114, 1134, "elaboration"], [1097, 1134, 1134, 1483, "elaboration"], [1138, 1150, 1134, 1138, "attribution"], [1134, 1150, 1150, 1201, "elaboration"], [1150, 1158, 1158, 1169, "elaboration"], [1150, 1169, 1169, 1201, "elaboration"], [1171, 1201, 1169, 1171, "attribution"], [1134, 1201, 1201, 1483, "elaboration"], [1201, 1225, 1225, 1483, "list"], [1201, 1205, 1205, 1225, "elaboration"], [1225, 1483, 1201, 1225, "list"], [1225, 1241, 1241, 1483, "elaboration"], [1241, 1268, 1268, 1305, "same_unit"], [1241, 1252, 1252, 1268, "elaboration"], [1252, 1259, 1259, 1268, "elaboration"], [1268, 1305, 1241, 1268, "same_unit"], [1268, 1287, 1287, 1305, "elaboration"], [1241, 1305, 1305, 1483, "elaboration"], [1305, 1324, 1324, 1483, "elaboration"], [1328, 1354, 1324, 1328, "attribution"], [1328, 1335, 1335, 1354, "list"], [1335, 1354, 1328, 1335, "list"], [1335, 1338, 1338, 1354, "purpose"], [1338, 1341, 1341, 1354, "same_unit"], [1341, 1354, 1338, 1341, "same_unit"], [1324, 1354, 1354, 1483, "elaboration"], [1354, 1371, 1371, 1413, "circumstance"], [1354, 1413, 1413, 1483, "elaboration"], [1413, 1427, 1427, 1438, "list"], [1427, 1438, 1413, 1427, "list"], [1413, 1438, 1438, 1483, "elaboration"], [1438, 1446, 1446, 1450, "elaboration"], [1438, 1450, 1450, 1483, "elaboration"], [1450, 1469, 1469, 1483, "elaboration"], [1471, 1483, 1469, 1471, "attribution"], [1471, 1476, 1476, 1483, "purpose"]], "tokens": ["-LSB-", "Overview", "-RSB-", "In", "this", "paper", ",", "the", "authors", "studied", "the", "problem", "of", "composition", "and", "decomposition", "of", "GANs", ".", "Motivated", "by", "the", "observations", "that", "images", "are", "naturally", "composed", "of", "multiple", "layouts", ",", "the", "authors", "proposed", "a", "new", "framework", "to", "study", "the", "compositional", "image", "generation", "and", "its", "decomposition", "by", "defining", "several", "tasks", ".", "On", "those", "various", "tasks", ",", "the", "authors", "demonstrate", "the", "possibility", "of", "the", "proposed", "model", "to", "composing", "image", "components", "and", "decompose", "the", "images", "afterwards", ".", "These", "results", "are", "interesting", "and", "insightful", "to", "some", "extent", ".", "-LSB-", "Strengthes", "-RSB-", "1", ".", "The", "authors", "proposed", "a", "framework", "for", "compose", "images", "from", "components", "and", "decompose", "the", "images", "into", "components", ".", "Based", "on", "this", "new", "framework", ",", "the", "authors", "tried", "different", "settings", ",", "by", "fixing", "the", "learning", "of", "one", "or", "more", "modules", "in", "the", "model", ".", "The", "experiments", "on", "various", "tasks", "are", "appreciated", ".", "2", ".", "In", "the", "experiments", ",", "the", "authors", "tried", "both", "image", "and", "text", "to", "demonstrate", "the", "concepts", "in", "this", "paper", ".", "Moreover", ",", "some", "qualitative", "results", "are", "presented", ".", "-LSB-", "Weaknesses", "-RSB-", "1", ".", "The", "authors", "performed", "multiple", "experiments", "regarding", "various", "tasks", "defined", "in", "this", "paper.However", ",", "I", "can", "hardly", "find", "any", "quantitative", "evaluation", "for", "the", "results", ".", "It", "is", "not", "clear", "to", "me", "that", "how", "the", "quality", "of", "the", "composed", "images", "and", "the", "decomposed", "components", "from", "images", "are", ".", "I", "would", "suggest", "the", "authors", "derive", "some", "metric", "to", "measure", "quality", "quantitatively", ",", "provide", "some", "statistics", "on", "the", "whole", "datasets", ".", "2", ".", "In", "this", "paper", ",", "the", "authors", "proposed", "multiple", "tasks", "in", "terms", "of", "which", "parts", "are", "fixed", "and", "known", "in", "the", "training", "process", ".", "However", ",", "dominated", "by", "so", "many", "different", "tasks", ",", "the", "core", "idea", "is", "losses", "in", "the", "paper", ".", "From", "the", "paper", ",", "I", "can", "not", "get", "the", "core", "idea", "the", "authors", "want", "to", "deliver", ".", "I", "would", "suggest", "the", "authors", "focus", "on", "one", "certain", "task", "and", "perform", "more", "qualitative", "and", "quantitative", "analysis", "and", "comparisons", ",", "as", "also", "mentioned", "above", ".", "3", ".", "The", "proposed", "model", "has", "several", "tricky", "parts", ".", "First", ",", "the", "number", "of", "components", "are", "pre-determined", ".", "However", ",", "in", "realistic", "cases", ",", "the", "number", "of", "components", "are", "unknown", ",", "and", "thus", "how", "many", "component", "generators", "should", "be", "used", "is", "ill-posed", ".", "Second", ",", "the", "composing", "operation", "is", "simple", "and", "tricky", ".", "Such", "a", "simple", "composing", "operation", "make", "it", "hard", "to", "adapt", "to", "some", "more", "complicated", "data", ",", "such", "as", "cifar10", "or", "so", ".", "Thirdly", ",", "almost", "all", "tasks", "need", "some", "components", "known", ".", "Even", "for", "the", "Task", "4", ",", "c", "is", "known", ",", "and", "the", "model", "performs", "poorly", "for", "generating", "the", "disentangled", "components", ".", "4", ".", "The", "authors", "missed", "one", "very", "relevant", "paper", ":", "LR-GAN", ":", "Layered", "Recursive", "Generative", "Adversarial", "Networks", "for", "Image", "Generation", ".", "Yang", "et", "al.", ".", "In", "the", "above", "paper", ",", "the", "authors", "proposed", "an", "end-to-end", "model", "for", "generating", "images", "with", "background", "and", "foreground", "compositionally", ".", "It", "can", "be", "applied", "to", "a", "number", "of", "realistic", "datasets", ".", "Regardless", "of", "the", "decomposition", "part", "in", "this", "paper", ",", "the", "proposed", "method", "in", "the", "above", "paper", "seems", "to", "be", "clearly", "superior", "to", "the", "composition", "part", "in", "this", "paper", "considering", "this", "paper", "fails", "on", "Task", "4", ".", "The", "authors", "should", "give", "credit", "to", "the", "above", "paper", "-LRB-", "even", "the", "synthesized", "MNIST", "dataset", "looks", "similar", "-RRB-", "and", "pay", "some", "efforts", "to", "explain", "the", "advantages", "in", "comparison", "it", ".", "-LSB-", "Summary", "-RSB-", "This", "paper", "proposed", "a", "new", "framework", "to", "study", "the", "compositionally", "of", "images", "during", "generation", "and", "decomposition", ".", "Through", "several", "experiments", "on", "various", "tasks", ",", "the", "authors", "presented", "some", "interesting", "results", "and", "provided", "some", "insights", "on", "the", "potentials", "and", "difficulties", "in", "this", "direction", ".", "However", ",", "as", "pointed", "above", ",", "I", "think", "this", "paper", "lacks", "enough", "experimental", "analysis", "and", "comparison", ".", "Its", "core", "idea", "hard", "to", "capture", ".", "Also", ",", "it", "missed", "a", "comparison", "to", "some", "related", "work", ".", "We", "thank", "the", "reviewer", "for", "their", "detailed", "and", "thoughtful", "review", ".", "We", "have", "made", "some", "improvements", "to", "our", "paper", "based", "on", "these", "suggestions", "-", "adding", "quantitative", "evaluations", "and", "expanding", "our", "comparison", "to", "related", "work", "-", "please", "see", "inline", "for", "our", "detailed", "responses", ":", "Reply", "to", "1", ":", "First", ",", "we", "'d", "like", "to", "clarify", "that", "the", "primary", "intent", "of", "our", "work", "was", "to", "suggest", "a", "set", "of", "composition", "/", "decomposition", "subtasks", "-LRB-", "c.f.", "tasks", "1", "through", "4", "in", "our", "submission", "-RRB-", ",", "as", "well", "as", "deriving", "some", "basic", "theoretical", "results", "about", "the", "identifiability", "of", "these", "tasks", "-LRB-", "e.g.", ",", "conditions", "where", "one", "can", "learn", "component", "models", "from", "composed", "data", "etc", "-RRB-", ".", "The", "experimental", "results", "were", "intended", "more", "as", "illustrative", "examples", "of", "when", "such", "models", "were", "learnable", "-LRB-", "or", "not", "-RRB-", "which", "explained", "our", "lack", "of", "quantitative", "evaluations", ".", "However", ",", "we", "agree", "with", "the", "reviewer", "that", "providing", "a", "qualitative", "evaluation", "across", "the", "entire", "dataset", "is", "useful", ".", "We", "supplemented", "our", "original", "qualitative", "results", "with", "quantitative", "metrics", "-", "specifically", ",", "we", "evaluated", "the", "foreground", "generator", "learned", "from", "composed", "examples", "using", "a", "standard", "FID", "score", "and", "compared", "this", "to", "our", "base", "GAN", "model", "trained", "on", "the", "actual", "foreground", "dataset", "-LRB-", "as", "a", "theoretical", "upper", "bound", "on", "performance", "for", "the", "compositional", "model", "-RRB-", ".", "We", "show", "that", ",", "as", "expected", ",", "we", "do", "not", "do", "quite", "as", "well", "when", "we", "have", "to", "learn", "to", "decompose", "and", "model", "the", "foreground", "simultaneously", ",", "but", "are", "within", "range", "of", "the", "FID", "scores", "reported", "in", "literature", "on", "MNIST", ".", "We", "further", "evaluated", "FID", "scores", "on", "Fashion-MNIST", "in", "the", "same", "manner", "as", "an", "additional", "validation", ".", "Reply", "to", "2", ":", "We", "apologise", "for", "the", "lack", "of", "clarity", "in", "our", "presentation", "of", "the", "various", "sub-tasks", ".", "Part", "of", "the", "contribution", "of", "our", "work", "is", "to", "enumerate", "various", "composition/decomposition", "tasks", "and", "to", "demonstrate", "the", "feasibility", "of", "a", "subset", "of", "these", "tasks", ".", "However", ",", "we", "agree", "with", "the", "reviewer", "that", "this", "may", "result", "in", "confusion", "for", "the", "reader", ".", "We", "'ve", "edited", "the", "introduction", "to", "make", "it", "clearer", "that", "our", "main", "focus", "is", "to", "demonstrate", "that", "TICKTICK", "chain", "learning", "''", "is", "possible", "since", "it", "provides", "a", "simple", "proof-of-concept", "for", "modular", "extensions", "of", "GANs", ".", "Reply", "to", "3", ":", "We", "agree", "that", "having", "a", "pre-specified", "number", "of", "components", "is", "a", "limitation", "of", "this", "framework", ".", "We", "are", "definitely", "interested", "in", "exploring", "extensions", "of", "such", "models", "beyond", "a", "fixed", ",", "pre-specified", "number", "of", "components", ".", "However", ",", "we", "believe", "that", "even", "this", "constrained", "version", "of", "compositionality", "has", "not", "been", "extensively", "explored", "-", "especially", "in", "terms", "of", "our", "theoretical", "understanding", "of", "when", "such", "compositional", "training", "is", "possible", ".", "Regarding", "our", "compositional", "operation", "being", "too", "simple", ",", "we", "agree", "that", "our", "composition", "transformations", "are", "not", "sufficient", "to", "capture", "TICKTICK", "real-world", "''", "composition", ".", "Our", "goal", "was", "to", "show", "a", "proof-of-concept", "on", "a", "challenging", "but", "still", "feasible", "set", "of", "composition", "operations", "-LRB-", "e.g.", ",", "in", "our", "chain", "learning", "example", ",", "the", "composition", "consists", "of", "scaling", ",", "rotation", "and", "masking", "-RRB-", ".", "Lastly", ",", "we", "agree", "that", "most", "of", "the", "tasks", "assume", "knowledge", "of", "a", "component", "generator", ".", "This", "was", "the", "main", "motivation", "behind", "our", "work", "-LRB-", "how", "to", "re-use", "GANs", "in", "a", "modular", "fashion", "-RRB-", ",", "we", "believe", "that", "the", "chain", "learning", "example", "shows", "a", "possible", "approach", "for", "how", "one", "can", "iteratively", "build", "up", "a", "collection", "of", "component", "generators", "and", "hence", "handle", "compositional", "data", "of", "increasing", "complexity", ".", "Reply", "to", "4", ":", "We", "thank", "the", "reviewer", "for", "the", "pointer", "to", "LR-GANs", ",", "that", "is", "certainly", "very", "interesting", "and", "relevant", "related", "work", ".", "However", ",", "there", "are", "some", "key", "differences", "between", "our", "work", "and", "the", "work", "on", "LR-GANs", ".", "Firstly", ",", "we", "learn", "a", "marginal", "component", "model", "for", "the", "foreground", "that", "is", "able", "to", "generate", "foreground", "samples", "-LRB-", "instead", "of", "generating", "foreground", "conditioned", "on", "background", "-RRB-", "this", "is", "important", "for", "us", "to", "be", "able", "to", "reuse", "component", "generators", "as", "demonstrated", "in", "our", "chain", "learning", "examples", "-LRB-", "we", "have", "included", "a", "cross-domain", "chain", "learning", "example", "in", "the", "appendix", "to", "further", "illustrate", "this", "-RRB-", ".", "Secondly", ",", "the", "LR-GAN", "is", "restricted", "to", "modelling", "affine", "compositions", "and", "do", "not", "learn", "a", "corresponding", "decomposition", "operation", ".", "The", "authors", "also", "demonstrate", "that", "both", "having", "a", "good", "foreground", "mask", "and", "restricting", "composition", "to", "affine", "transformations", "is", "required", "for", "good", "performance", "of", "their", "model", "in", "their", "ablative", "analysis", ".", "We", "appreciate", "the", "insights", "provided", "by", "the", "authors", "of", "LR-GAN", ",", "and", "while", "these", "priors", "are", "useful", "when", "modeling", "images", "specifically", "and", "may", "be", "useful", "in", "our", "contexts", "as", "well", ",", "we", "are", "more", "focused", "on", "identifying", "where", "compositional", "learning", "is", "identifiable", "more", "generally", "without", "In", "summary", ",", "there", "are", "two", "main", "differences", "in", "the", "model", "formulation", "directly", ".", "First", ",", "in", "our", "framework", "the", "foreground", "generator", "and", "background", "generator", "are", "independent", ",", "while", "LR-GAN", "'s", "foreground", "generator", "is", "dependent", "on", "background", "generator", ".", "This", "independence", "is", "required", "for", "part", "generators", "learnt", "to", "be", "reusable", ".", "Second", ",", "in", "our", "framework", "there", "is", "a", "decomposition", "operation", "and", "a", "cycle", "consistency", "regularization", "in", "the", "model", ".", "We", "showed", "that", "this", "regularization", "is", "beneficial", "to", "learning", "a", "good", "part", "generators", "."], "comment_id": "B1eoKJXq0m"}, {"rels": [[0, 21, 21, 23, "elaboration"], [0, 23, 23, 417, "means"], [23, 41, 41, 86, "elaboration"], [41, 61, 61, 71, "same_unit"], [41, 54, 54, 61, "elaboration"], [61, 71, 41, 61, "same_unit"], [61, 64, 64, 71, "elaboration"], [64, 65, 65, 71, "elaboration"], [41, 71, 71, 86, "elaboration"], [71, 81, 81, 86, "list"], [81, 86, 71, 81, "list"], [23, 86, 86, 417, "elaboration"], [86, 95, 95, 118, "elaboration"], [95, 108, 108, 118, "same_unit"], [95, 99, 99, 108, "elaboration"], [108, 118, 95, 108, "same_unit"], [108, 109, 109, 118, "elaboration"], [86, 118, 118, 417, "elaboration"], [118, 125, 125, 417, "list"], [125, 417, 118, 125, "list"], [125, 137, 137, 163, "elaboration"], [137, 155, 155, 162, "elaboration"], [137, 162, 162, 163, "elaboration"], [125, 163, 163, 170, "elaboration"], [125, 170, 170, 417, "elaboration"], [170, 187, 187, 417, "list"], [187, 417, 170, 187, "list"], [187, 203, 203, 417, "list"], [203, 417, 187, 203, "list"], [203, 204, 204, 228, "elaboration"], [204, 207, 207, 228, "elaboration"], [203, 228, 228, 417, "elaboration"], [228, 245, 245, 417, "elaboration"], [245, 252, 252, 417, "list"], [252, 417, 245, 252, "list"], [276, 286, 252, 276, "attribution"], [276, 281, 281, 286, "elaboration"], [252, 286, 286, 336, "elaboration"], [286, 290, 290, 323, "elaboration"], [290, 308, 308, 323, "elaboration"], [308, 315, 315, 323, "elaboration"], [286, 323, 323, 336, "elaboration"], [325, 336, 323, 325, "attribution"], [332, 336, 325, 332, "attribution"], [252, 336, 336, 417, "means"], [336, 351, 351, 360, "same_unit"], [336, 343, 343, 351, "elaboration"], [351, 360, 336, 351, "same_unit"], [351, 356, 356, 360, "elaboration"], [336, 360, 360, 417, "elaboration"], [360, 370, 370, 375, "elaboration"], [360, 375, 375, 417, "elaboration"], [375, 385, 385, 395, "list"], [385, 395, 375, 385, "list"], [385, 392, 392, 395, "purpose"], [375, 395, 395, 417, "elaboration"], [405, 417, 395, 405, "attribution"], [405, 409, 409, 417, "purpose"], [0, 417, 417, 2482, "elaboration"], [424, 455, 417, 424, "attribution"], [424, 432, 432, 455, "temporal"], [432, 438, 438, 455, "elaboration"], [417, 455, 455, 2482, "elaboration"], [455, 462, 462, 473, "elaboration"], [462, 465, 465, 473, "elaboration"], [455, 473, 473, 2482, "means"], [473, 498, 498, 502, "elaboration"], [473, 502, 502, 2482, "elaboration"], [502, 510, 510, 2482, "textualorganization"], [510, 2482, 502, 510, "textualorganization"], [510, 528, 528, 2482, "elaboration"], [549, 604, 528, 549, "attribution"], [549, 568, 568, 604, "elaboration"], [568, 573, 573, 604, "circumstance"], [573, 587, 587, 604, "elaboration"], [528, 604, 604, 2482, "elaboration"], [604, 647, 647, 2482, "topic"], [604, 620, 620, 647, "elaboration"], [620, 632, 632, 647, "elaboration"], [632, 638, 638, 647, "elaboration"], [647, 2482, 604, 647, "topic"], [647, 690, 690, 2482, "elaboration"], [690, 704, 704, 705, "same_unit"], [690, 700, 700, 704, "elaboration"], [704, 705, 690, 704, "same_unit"], [690, 705, 705, 740, "elaboration"], [705, 721, 721, 740, "same_unit"], [705, 706, 706, 721, "elaboration"], [721, 740, 705, 721, "same_unit"], [721, 730, 730, 740, "elaboration"], [690, 740, 740, 2482, "elaboration"], [740, 748, 748, 758, "elaboration"], [740, 758, 758, 2482, "elaboration"], [758, 763, 763, 776, "elaboration"], [758, 776, 776, 796, "elaboration"], [776, 785, 785, 796, "elaboration"], [758, 796, 796, 2482, "elaboration"], [796, 803, 803, 2482, "elaboration"], [803, 820, 820, 832, "same_unit"], [803, 813, 813, 820, "elaboration"], [820, 832, 803, 820, "same_unit"], [821, 832, 820, 821, "attribution"], [803, 832, 832, 2482, "elaboration"], [832, 854, 854, 863, "elaboration"], [832, 863, 863, 2482, "elaboration"], [863, 892, 892, 893, "elaboration"], [863, 893, 893, 956, "elaboration"], [863, 956, 956, 2482, "elaboration"], [956, 962, 962, 990, "elaboration"], [962, 968, 968, 990, "circumstance"], [956, 990, 990, 2482, "elaboration"], [990, 1005, 1005, 2482, "elaboration"], [1005, 1024, 1024, 1039, "elaboration"], [1024, 1027, 1027, 1039, "same_unit"], [1027, 1039, 1024, 1027, "same_unit"], [1027, 1038, 1038, 1039, "same_unit"], [1027, 1031, 1031, 1038, "elaboration"], [1038, 1039, 1027, 1038, "same_unit"], [1005, 1039, 1039, 2482, "circumstance"], [1039, 1047, 1047, 1052, "elaboration"], [1039, 1052, 1052, 2482, "elaboration"], [1052, 1074, 1074, 1075, "same_unit"], [1052, 1063, 1063, 1074, "elaboration"], [1063, 1066, 1066, 1074, "elaboration"], [1074, 1075, 1052, 1074, "same_unit"], [1052, 1075, 1075, 1076, "elaboration"], [1052, 1076, 1076, 1097, "attribution"], [1076, 1084, 1084, 1097, "elaboration"], [1052, 1097, 1097, 2482, "elaboration"], [1097, 1107, 1107, 1114, "attribution"], [1097, 1114, 1114, 1161, "elaboration"], [1114, 1117, 1117, 1161, "elaboration"], [1117, 1143, 1143, 1161, "elaboration"], [1097, 1161, 1161, 2482, "elaboration"], [1161, 1174, 1174, 1207, "elaboration"], [1174, 1190, 1190, 1207, "elaboration"], [1161, 1207, 1207, 2482, "elaboration"], [1207, 1230, 1230, 1258, "list"], [1207, 1223, 1223, 1230, "elaboration"], [1230, 1258, 1207, 1230, "list"], [1230, 1238, 1238, 1258, "elaboration"], [1238, 1246, 1246, 1258, "elaboration"], [1207, 1258, 1258, 2482, "elaboration"], [1258, 1267, 1267, 1290, "elaboration"], [1258, 1290, 1290, 1319, "elaboration"], [1293, 1319, 1290, 1293, "attribution"], [1293, 1297, 1297, 1319, "same_unit"], [1293, 1296, 1296, 1297, "elaboration"], [1297, 1319, 1293, 1297, "same_unit"], [1297, 1301, 1301, 1319, "elaboration"], [1258, 1319, 1319, 2482, "elaboration"], [1319, 1335, 1335, 2482, "list"], [1319, 1329, 1329, 1335, "means"], [1335, 2482, 1319, 1335, "list"], [1335, 1352, 1352, 1383, "elaboration"], [1362, 1383, 1352, 1362, "antithesis"], [1362, 1365, 1365, 1383, "circumstance"], [1372, 1383, 1365, 1372, "attribution"], [1335, 1383, 1383, 2482, "elaboration"], [1383, 1391, 1391, 1418, "elaboration"], [1391, 1413, 1413, 1418, "elaboration"], [1383, 1418, 1418, 1474, "elaboration"], [1418, 1431, 1431, 1474, "elaboration"], [1444, 1451, 1431, 1444, "attribution"], [1444, 1447, 1447, 1451, "elaboration"], [1431, 1451, 1451, 1474, "elaboration"], [1451, 1453, 1453, 1474, "purpose"], [1453, 1461, 1461, 1474, "elaboration"], [1461, 1465, 1465, 1474, "purpose"], [1465, 1469, 1469, 1474, "elaboration"], [1383, 1474, 1474, 2482, "elaboration"], [1481, 1510, 1474, 1481, "attribution"], [1481, 1504, 1504, 1510, "list"], [1481, 1494, 1494, 1504, "elaboration"], [1494, 1503, 1503, 1504, "same_unit"], [1494, 1499, 1499, 1503, "elaboration"], [1503, 1504, 1494, 1503, "same_unit"], [1504, 1510, 1481, 1504, "list"], [1474, 1510, 1510, 2482, "elaboration"], [1510, 1511, 1511, 1524, "elaboration"], [1510, 1524, 1524, 1545, "means"], [1524, 1534, 1534, 1545, "elaboration"], [1510, 1545, 1545, 2482, "circumstance"], [1545, 1562, 1562, 2482, "elaboration"], [1562, 1606, 1606, 1666, "elaboration"], [1606, 1617, 1617, 1625, "elaboration"], [1606, 1625, 1625, 1646, "elaboration"], [1625, 1626, 1626, 1646, "elaboration"], [1606, 1646, 1646, 1666, "elaboration"], [1646, 1653, 1653, 1666, "explanation"], [1653, 1655, 1655, 1666, "elaboration"], [1562, 1666, 1666, 2482, "elaboration"], [1666, 1672, 1672, 1676, "elaboration"], [1666, 1676, 1676, 1678, "elaboration"], [1666, 1678, 1678, 2482, "elaboration"], [1678, 1687, 1687, 2482, "elaboration"], [1687, 1697, 1697, 1701, "same_unit"], [1687, 1691, 1691, 1697, "elaboration"], [1691, 1692, 1692, 1697, "elaboration"], [1697, 1701, 1687, 1697, "same_unit"], [1687, 1701, 1701, 2482, "elaboration"], [1701, 1710, 1710, 2482, "list"], [1710, 2482, 1701, 1710, "list"], [1711, 1722, 1710, 1711, "attribution"], [1712, 1722, 1711, 1712, "attribution"], [1710, 1722, 1722, 2482, "temporal"], [1727, 1751, 1722, 1727, "condition"], [1727, 1732, 1732, 1751, "reason"], [1722, 1751, 1751, 2482, "elaboration"], [1753, 1763, 1751, 1753, "attribution"], [1753, 1757, 1757, 1763, "elaboration"], [1751, 1763, 1763, 2482, "temporal"], [1763, 1784, 1784, 2482, "list"], [1763, 1775, 1775, 1784, "elaboration"], [1784, 2482, 1763, 1784, "list"], [1784, 2231, 2231, 2482, "textualorganization"], [1784, 1790, 1790, 2231, "elaboration"], [1790, 1812, 1812, 2231, "elaboration"], [1812, 1835, 1835, 1839, "elaboration"], [1812, 1839, 1839, 2231, "elaboration"], [1839, 1846, 1846, 1849, "manner"], [1839, 1849, 1849, 2231, "elaboration"], [1853, 1875, 1849, 1853, "attribution"], [1853, 1864, 1864, 1875, "same_unit"], [1853, 1863, 1863, 1864, "same_unit"], [1853, 1859, 1859, 1863, "elaboration"], [1863, 1864, 1853, 1863, "same_unit"], [1864, 1875, 1853, 1864, "same_unit"], [1849, 1875, 1875, 2231, "elaboration"], [1875, 1887, 1887, 1902, "elaboration"], [1887, 1897, 1897, 1902, "elaboration"], [1875, 1902, 1902, 2231, "elaboration"], [1903, 1933, 1902, 1903, "attribution"], [1903, 1924, 1924, 1933, "elaboration"], [1924, 1928, 1928, 1933, "circumstance"], [1902, 1933, 1933, 2231, "elaboration"], [1933, 1943, 1943, 1953, "elaboration"], [1933, 1953, 1953, 2231, "elaboration"], [1953, 1970, 1970, 1976, "same_unit"], [1953, 1958, 1958, 1970, "elaboration"], [1970, 1976, 1953, 1970, "same_unit"], [1953, 1976, 1976, 2231, "elaboration"], [1976, 1980, 1980, 1992, "same_unit"], [1980, 1992, 1976, 1980, "same_unit"], [1980, 1984, 1984, 1992, "elaboration"], [1976, 1992, 1992, 2231, "elaboration"], [1992, 2020, 2020, 2231, "elaboration"], [2020, 2030, 2030, 2038, "elaboration"], [2030, 2034, 2034, 2035, "means"], [2030, 2035, 2035, 2038, "elaboration"], [2020, 2038, 2038, 2071, "elaboration"], [2038, 2058, 2058, 2071, "same_unit"], [2038, 2039, 2039, 2058, "elaboration"], [2058, 2071, 2038, 2058, "same_unit"], [2058, 2062, 2062, 2071, "elaboration"], [2062, 2070, 2070, 2071, "same_unit"], [2062, 2063, 2063, 2070, "elaboration"], [2070, 2071, 2062, 2070, "same_unit"], [2020, 2071, 2071, 2231, "elaboration"], [2075, 2082, 2071, 2075, "attribution"], [2071, 2082, 2082, 2231, "condition"], [2082, 2098, 2098, 2231, "elaboration"], [2098, 2106, 2106, 2112, "elaboration"], [2098, 2112, 2112, 2126, "elaboration"], [2098, 2126, 2126, 2231, "elaboration"], [2126, 2131, 2131, 2231, "elaboration"], [2131, 2136, 2136, 2155, "same_unit"], [2131, 2135, 2135, 2136, "elaboration"], [2136, 2155, 2131, 2136, "same_unit"], [2136, 2151, 2151, 2155, "elaboration"], [2131, 2155, 2155, 2231, "elaboration"], [2155, 2160, 2160, 2172, "purpose"], [2155, 2172, 2172, 2231, "elaboration"], [2172, 2188, 2188, 2189, "same_unit"], [2172, 2185, 2185, 2188, "elaboration"], [2188, 2189, 2172, 2188, "same_unit"], [2172, 2189, 2189, 2231, "elaboration"], [2189, 2201, 2201, 2209, "elaboration"], [2189, 2209, 2209, 2230, "purpose"], [2209, 2226, 2226, 2230, "elaboration"], [2189, 2230, 2230, 2231, "elaboration"], [2231, 2482, 1784, 2231, "textualorganization"], [2231, 2243, 2243, 2482, "list"], [2243, 2482, 2231, 2243, "list"], [2243, 2273, 2273, 2482, "list"], [2243, 2246, 2246, 2273, "elaboration"], [2246, 2262, 2262, 2273, "elaboration"], [2262, 2267, 2267, 2273, "elaboration"], [2273, 2482, 2243, 2273, "list"], [2273, 2280, 2280, 2308, "elaboration"], [2280, 2290, 2290, 2308, "elaboration"], [2290, 2300, 2300, 2308, "same_unit"], [2290, 2293, 2293, 2300, "same_unit"], [2290, 2292, 2292, 2293, "purpose"], [2293, 2300, 2290, 2293, "same_unit"], [2300, 2308, 2290, 2300, "same_unit"], [2273, 2308, 2308, 2482, "elaboration"], [2308, 2332, 2332, 2482, "list"], [2308, 2316, 2316, 2332, "condition"], [2321, 2332, 2316, 2321, "attribution"], [2332, 2482, 2308, 2332, "list"], [2333, 2364, 2332, 2333, "attribution"], [2333, 2340, 2340, 2364, "elaboration"], [2340, 2342, 2342, 2364, "purpose"], [2345, 2364, 2342, 2345, "attribution"], [2332, 2364, 2364, 2482, "elaboration"], [2374, 2394, 2364, 2374, "attribution"], [2374, 2384, 2384, 2394, "elaboration"], [2364, 2394, 2394, 2482, "elaboration"], [2394, 2397, 2397, 2415, "purpose"], [2397, 2410, 2410, 2415, "purpose"], [2394, 2415, 2415, 2482, "elaboration"], [2415, 2429, 2429, 2482, "elaboration"], [2429, 2437, 2437, 2482, "list"], [2437, 2482, 2429, 2437, "list"], [2437, 2447, 2447, 2464, "elaboration"], [2447, 2451, 2451, 2464, "elaboration"], [2437, 2464, 2464, 2482, "elaboration"], [2464, 2473, 2473, 2482, "list"], [2464, 2467, 2467, 2473, "elaboration"], [2473, 2482, 2464, 2473, "list"]], "tokens": ["##", "Summary", "This", "work", "presents", "a", "probabilistic", "training", "method", "for", "binary", "Neural", "Network", "with", "stochastic", "versions", "of", "Batch", "Normalization", "and", "max", "pooling", ".", "By", "sampling", "from", "the", "weight", "distribution", "an", "ensemble", "of", "Binary", "Neural", "Networks", "could", "further", "improve", "the", "performance", ".", "In", "the", "experimental", "section", ",", "the", "authors", "compare", "proposed", "PBNet", "with", "Binarized", "NN", "-LRB-", "Hubara", "et", "al.", ",", "2016", "-RRB-", "in", "two", "image", "datasets", "-LRB-", "MNIST", "and", "CIFAR10", "-RRB-", ".", "In", "general", ",", "the", "paper", "was", "written", "in", "poor", "quality", "and", "without", "enough", "details", ".", "The", "idea", "behind", "the", "paper", "is", "not", "novel", ".", "Stochastic", "binarization", "and", "the", "-LRB-", "local", "-RRB-", "reparametrization", "trick", "were", "used", "to", "training", "binary", "-LRB-", "quantized", "-RRB-", "neural", "networks", "in", "previous", "works", ".", "The", "empirical", "results", "are", "not", "significant", ".", "##", "Detail", "comments", "Issues", "with", "the", "training", "algorithm", "of", "stochastic", "neural", "network", "The", "authors", "did", "not", "give", "details", "of", "the", "training", "method", "and", "vaguely", "mentioned", "that", "the", "variational", "optimization", "framework", "-LRB-", "Staines", "&", "Barber", ",", "2012", "-RRB-", ".", "I", "do", "not", "understand", "equation", "1", ".", "Since", "B", "is", "binary", ",", "the", "left", "part", "of", "equation", "2", "is", "a", "combination", "optimization", "problem", ".", "If", "B", "is", "sampled", "during", "the", "training", ",", "the", "gradient", "would", "suffer", "from", "high", "variance", ".", "Issues", "with", "propagating", "distributions", "throughout", "the", "network", "Equation", "3", "is", "based", "on", "the", "assumption", "of", "that", "the", "activations", "are", "random", "variables", "from", "Bernoulli", "distribution", ".", "In", "equation", "4", ",", "the", "activations", "of", "the", "current", "layer", "become", "random", "variables", "from", "Gaussian", "distribution", ".", "How", "the", "activations", "to", "further", "propagate", "?", "Issues", "with", "ternary", "Neural", "Networks", "in", "section", "2.4", "For", "a", "ternary", "NN", ",", "the", "weight", "will", "be", "from", "a", "multinomial", "distribution", ",", "I", "think", "it", "will", "break", "the", "assumption", "used", "by", "equation", "3", ".", "Issues", "with", "empirical", "evidences", "Since", "the", "activations", "are", "sampled", "in", "PBNET-S", ",", "a", "more", "appropriate", "baseline", "should", "be", "BNN", "with", "stochastic", "binarization", "-LRB-", "Hubara", "et", "al.", ",", "2016", "-RRB-", "which", "achieved", "89.85", "%", "accuracy", "on", "CIFAR-10", ".", "It", "means", "that", "the", "proposed", "methods", "did", "not", "show", "any", "significant", "improvements", ".", "By", "the", "way", "BNN", "with", "stochastic", "binarization", "-LRB-", "Hubara", "et", "al.", ",", "2016", "-RRB-", "can", "also", "allow", "for", "ensemble", "predictions", "to", "improve", "performance", ".", "Dear", "reviewer", ",", "We", "have", "tried", "to", "address", "the", "questions/remarks", "raised", "in", "the", "review", ".", "Moreover", ",", "we", "have", "updated", "the", "writing", "in", "the", "paper", "and", "hope", "the", "presentation", "is", "now", "easier", "to", "follow", ".", "Our", "response", "follows", "the", "structure", "of", "the", "original", "review", "such", "that", "it", "is", "easy", "to", "refer", "back", "to", "the", "original", "remarks", ".", "#", "On", "the", "general", "remarks", "We", "agree", "that", "the", "local", "reparametrization", "trick", "has", "been", "used", "before", "in", "order", "to", "train", "binary", "-LRB-", "or", "quantized", "-RRB-", "neural", "networks", ",", "however", ",", "we", "binarize", "both", "the", "weights", "and", "activations", ".", "Moreover", ",", "we", "propagate", "the", "activation", "distribution", "throughout", "the", "network/layer", "in", "order", "to", "backpropagate", "through", "binarization", "functions", ".", "By", "doing", "so", ",", "the", "gradient", "of", "the", "binarization", "function", "with", "respect", "to", "the", "parameters", "of", "the", "pre-activation", "distribution", "exists", "and", "can", "easily", "be", "computed", "using", "standard", "tools", ".", "Although", "our", "method", "does", "n't", "achieve", "better", "performance", "when", "compared", "to", "the", "Binarized", "Neural", "Networks", "by", "Hubara", "et", "al.", ",", "the", "performance", "is", "on", "par", ".", "For", "this", "reason", ",", "we", "also", "do", "not", "make", "claims", "about", "outperforming", "existing", "methods", ",", "however", ",", "we", "do", "argue", "that", "our", "stochastic", "training", "method", "has", "various", "favorable", "properties", ",", "i.e.", ",", "we", "obtain", "a", "distribution", "over", "binary", "network", "parameters", "that", "allow", "for", "any-time", "ensembles", "without", "retraining", "anything", ",", "it", "allows", "for", "more", "complex", "network", "architectures", "than", "earlier", "work", "-LRB-", "on", "probabilistic", "networks", "-RRB-", ",", "and", "it", "is", "easily", "implemented", "in", "existing", "deep", "learning", "frameworks", ".", "Moreover", ",", "the", "probabilistic", "approach", "allows", "for", "straightforward", "inclusion", "of", "priors", "on", "the", "weights", "and/or", "activations", "which", "can", "help", "to", "impose", "more", "structure", "on", "the", "Binary", "Neural", "Network", "-LRB-", "e.g.", ",", "sparsity", "priors", "-RRB-", "that", "can", "lead", "to", "even", "more", "efficient", "networks", ".", "##", "Response", "to", "TICKTICK", "Issues", "with", "the", "training", "algorithm", "of", "stochastic", "neural", "network", "''", ":", "We", "indeed", "did", "n't", "elaborate", "in", "much", "detail", "on", "the", "training", "method", "because", "in", "many", "aspects", "our", "training", "method", "follows", "the", "standard", "approach", "in", "the", "current", "literature", ".", "Since", "we", "ensured", "that", "all", "the", "operations", "in", "the", "PBNet", "-LRB-", "-", "S", "-RRB-", "are", "differentiable", "-LRB-", "w.r.t.", "the", "parameters", "of", "the", "input", "distributions", "for", "most", "of", "the", "operations", "-RRB-", ",", "we", "can", "train", "the", "PBNet", "as", "any", "other", "network", "-LRB-", "and", "thus", "leverage", "existing", "Deep", "Learning", "frameworks", "-RRB-", ".", "For", "more", "specifics", ",", "see", "algorithm", "1", ",", "which", "outlines", "the", "forward", "pass", "for", "a", "single", "layer", ".", "##", "Response", "to", "equation", "1", "being", "unclear", "Equation", "1", "states", "the", "upper", "bound", "on", "the", "training", "objective", ".", "Our", "actual", "objective", "is", "to", "obtain", "the", "binary", "weights", "that", "minimize", "the", "loss", "as", "states", "on", "the", "left-hand", "side", ".", "This", "is", "indeed", "a", "combinatorial", "problem", ".", "As", "such", "we", "make", "use", "of", "the", "variational", "optimization", "framework", "-LRB-", "Staines", "&", "Barber", ",", "2012", "-RRB-", "in", "order", "to", "obtain", "an", "upper", "bound", "on", "the", "training", "objective", ".", "I.e.", ",", "we", "introduce", "a", "distribution", "over", "the", "binary", "parameters", "of", "the", "network", "and", "instead", "of", "optimizing", "the", "binary", "parameters", "directly", ",", "we", "optimize", "the", "parameters", "of", "the", "binary", "distributions", ".", "As", "pointed", "out", "by", "the", "reviewer", ",", "optimizing", "this", "upper", "bound", "may", "result", "in", "high", "variance", "on", "the", "gradients", ",", "but", "we", "deal", "with", "this", "in", "the", "following", "way", ":", "-", "For", "PBNet", ",", "we", "never", "sample", "weights", "but", "instead", "propagate", "the", "variance", "throughout", "the", "network", ",", "i.e.", ",", "the", "forward", "pass", "is", "deterministic", "and", "we", "do", "n't", "suffer", "from", "high", "variance", "on", "the", "gradients", "-", "For", "PBNet-S", ",", "we", "leverage", "the", "local", "reparametrization", "trick", ",", "which", "is", "known", "to", "have", "lower", "gradient", "variance", "compared", "to", "simply", "sampling", "the", "weights", "during", "training", ".", "However", ",", "instead", "of", "sampling", "the", "-LRB-", "pre", "-", "-RRB-", "activations", "directly", "after", "computing", "the", "linear", "operation", "of", "a", "layer", ",", "we", "sample", "the", "activations", "at", "the", "very", "last", "operation", "of", "the", "layer", ".", "Moreover", ",", "the", "gradient", "variance", "is", "related", "to", "the", "variance", "of", "the", "weight", "distribution", ".", "For", "this", "reason", ",", "we", "initialize", "the", "parameters", "from", "a", "pre-trained", "network", "and", "specifically", "initialize", "the", "weight", "distribution", "q", "-LRB-", "B", "-RRB-", "to", "have", "low", "variance", "-LRB-", "compared", "to", "a", "random", "initialization", "-RRB-", ".", "Following", "this", ",", "we", "empirically", "find", "no", "issues", "with", "training", "these", "networks", ".", "##", "Response", "to", "TICKTICK", "Issues", "with", "propagating", "distributions", "throughout", "the", "network", "TICKTICK", "The", "activations", "-LRB-", "and", "the", "weights", "for", "that", "matter", "-RRB-", "are", "distributed", "according", "to", "a", "scaled", "and", "translated", "Bernoulli", "distribution", "--", "which", "we", "have", "called", "the", "Binary", "distribution", "of", "ease", "of", "notation", ".", "Any", "inner", "product", "between", "two", "Binary", "distributed", "vectors", "is", "distributed", "according", "to", "a", "Poisson", "Binomial", "distribution", ".", "Given", "the", "fact", "that", "computing", "the", "CDF", "of", "a", "Poisson", "binomial", "is", "not", "straightforward", "-LSB-", "1", "-RSB-", "and", "that", "the", "CDF", "is", "well-approximated", "by", "the", "CDF", "of", "a", "Gaussian", "-LRB-", "under", "some", "assumptions", "-RRB-", ",", "we", "approximate", "the", "distribution", "of", "the", "pre-activation", "by", "a", "Gaussian", "distribution", ".", "Since", "the", "actual", "activations", "of", "a", "layer", "are", "obtained", "by", "applying", "a", "binarization", "-LRB-", "activation", "-RRB-", "function", "to", "the", "pre-activation", ",", "we", "again", "obtain", "a", "binary", "distribution", "as", "activations", "-LRB-", "for", "which", "we", "obtain", "the", "parameters", "by", "evaluating", "the", "CDF", "of", "the", "Gaussian", "distribution", "-RRB-", ".", "As", "such", ",", "for", "the", "PBNet", ",", "the", "input", "to", "a", "layer", "is", "a", "Binary", "distribution", "-LRB-", "i.e.", ",", "the", "parameters", "thereof", "-RRB-", "and", "the", "output", "is", "also", "a", "Binary", "distribution", "-LRB-", "i.e.", ",", "the", "parameters", "thereof", "-RRB-", ",", "which", "allows", "us", "to", "stack", "multiple", "layers", "in", "a", "Neural", "Network", ".", "##", "Response", "to", "TICKTICK", "Issues", "with", "ternary", "Neural", "Networks", "TICKTICK", "We", "obtain", "a", "Ternary", "Neural", "Network", "as", "a", "post-processing", "step", ",", "i.e.", ",", "after", "training", ",", "we", "obtain", "a", "binary", "distribution", ".", "We", "only", "claim", "that", "we", "can", "--", "as", "a", "post-processing", "step", "--", "set", "some", "of", "the", "weights", "in", "a", "BNN", "to", "zero", "to", "obtain", "a", "Ternary", "Neural", "Network", ".", "I.e.", ",", "we", "remove", "the", "noisy", "weights", "from", "the", "network", "by", "setting", "them", "to", "zero", ".", "This", "can", "either", "be", "interpreted", "as", "a", "Ternary", "Neural", "Network", "or", "a", "Sparse", "Binary", "Neural", "Network", ".", "In", "short", ",", "we", "never", "train", "a", "Ternary", "Network", ",", "but", "obtain", "one", "after", "training", "a", "BNN", ",", "and", "observe", "that", "the", "results", "improve", "slightly", "by", "using", "this", "post-processing", "step", ".", "##", "Response", "on", "TICKTICK", "Issues", "with", "empirical", "evidences", "TICKTICK", "We", "indeed", "do", "not", "improve", "over", "earlier", "work", ",", "however", ",", "our", "results", "are", "competitive", "and", "our", "method", "has", "favorable", "properties", "compared", "to", "earlier", "work", ".", "For", "this", "we", "refer", "back", "to", "the", "first", "paragraph", "of", "this", "response", ".", "Moreover", ",", "we", "are", "aware", "of", "the", "results", "reported", "by", "Hubara", "et", "al.", "-LRB-", "2016", "-RRB-", "using", "stochastic", "activations", ".", "We", "chose", "to", "compare", "to", "the", "BNN", "using", "deterministic", "activiations", "since", "we", "were", "unable", "to", "reproduce", "the", "results", "presented", "on", "stochastic", "activations", ".", "Furthermore", ",", "we", "like", "to", "point", "out", "that", "the", "architecture", "used", "in", "our", "paper", "uses", "one", "fully", "connected", "layer", "less", "-LRB-", "following", "Shayer", "et", "al.", "-LRB-", "2018", "-RRB-", "-RRB-", ",", "and", "thus", "has", "less", "parameters", ".", "In", "-LRB-", "Hubara", "et", "al.", ",", "2016", "-RRB-", ",", "the", "binary", "weights", "are", "trained", "using", "full", "precision", "shadow", "weights", "and", "a", "deterministic", "binarization", "function", "-LRB-", "only", "stochastic", "binarization", "of", "the", "activations", "is", "considered", "-RRB-", ".", "As", "such", ",", "after", "training", ",", "there", "is", "only", "a", "point", "estimate", "of", "the", "binary", "weights", ".", "Although", "it", "is", ",", "of", "course", ",", "possible", "to", "train", "multiple", "networks", "to", "obtain", "an", "ensemble", ",", "in", "our", "work", ",", "we", "train", "a", "single", "PBNet-S", "once", "and", "obtain", "multiple", "network", "instantiations", "from", "the", "binary", "weight", "distribution", "in", "order", "to", "create", "an", "ensemble", ".", "As", "such", ",", "it", "is", "possible", "to", "perform", "any-time", "ensemble", "predictions", "-LRB-", "without", "any", "extra", "cost", "during", "training", "-RRB-", ",", "which", "improve", "both", "accuracy", "and", "uncertainty", "estimates", "as", "is", "shown", "in", "Table", "1", "and", "Figure", "3a", "in", "our", "paper", ".", "-LSB-", "1", "-RSB-", "Hong", ",", "Yili", ".", "TICKTICK", "On", "computing", "the", "distribution", "function", "for", "the", "Poisson", "binomial", "distribution", ".", "''", "Computational", "Statistics", "&", "Data", "Analysis", "59", "-LRB-", "2013", "-RRB-", ":", "41-51", ".", "I", "still", "do", "not", "understand", "the", "training", "method", ".", "Equation", "1", "and", "Algorithm", "1", "-LRB-", "the", "forward", "pass", "-RRB-", "are", "not", "enough", ".", "Please", "describe", "also", "the", "backward", "and", "the", "update", ".", "Please", "explain", "why", "this", "upper", "bound", "and", "how", "about", "the", "tightness", ".", "After", "reading", "the", "response", ",", "I", "will", "keep", "my", "rating", "because", "TICKTICK", "the", "idea", "behind", "the", "paper", "is", "not", "novel", "and", "the", "empirical", "results", "are", "not", "significant", ".", "''", "Thank", "you", "for", "taking", "the", "time", "to", "respond", "to", "our", "rebuttal", ".", "Since", "not", "everything", "is", "clear", "yet", ",", "we", "will", "take", "the", "time", "to", "give", "some", "clarifications", "on", "the", "points", "raised", ".", "#", "On", "the", "training", "algorithm", ":", "We", "noticed", "that", "one", "small", "detail", "is", "missing", "from", "our", "paper", ",", "i.e.", ",", "the", "parameters", "NN", "are", "constrained", "to", "lie", "in", "-LSB-", "-1", ",", "1", "-RSB-", ",", "for", "this", "reason", ",", "we", "update", "a", "set", "of", "unconstrained", "parameters", "NN", "and", "obtain", "NN", "=", "tanh", "-LRB-", "NN", "-RRB-", ".", "As", "such", ",", "NN", "can", "be", "updated", "without", "constraints", ".", "we", "explicitly", "made", "sure", "that", "all", "operations", "in", "the", "PBNet", "-LRB-", "-", "S", "-RRB-", "are", "TICK", "auto-diffable", "'", "both", "with", "respect", "to", "weight", "and", "input", ".", "For", "all", "layers", ",", "the", "inputs", "to", "the", "layers", "are", "the", "parameters", "-LRB-", "i.e.", ",", "sufficient", "statistics", "-RRB-", "of", "the", "binary", "distributions", "that", "describe", "the", "activations", ".", "Note", "that", "the", "binary", "distribution", "includes", "deterministic", "activations", "of", "either", "-1", "or", "+1", "as", "a", "corner", "case", ",", "which", "also", "allows", "modeling", "observed", ",", "sampled", "activations", "as", "encountered", "in", "PBNet-S", ".", "All", "operations", "we", "apply", "on", "these", "sufficient", "statistics", "are", "differentiable", "-LRB-", "and", "can", "be", "computed", "using", "auto-diff", "implementations", "-RRB-", ".", "Hence", ",", "the", "forward", "pass", "-LRB-", "which", "is", "specified", "for", "a", "single", "layer", "in", "algorithm", "1", "-RRB-", "completely", "defines", "the", "backward", "pass", ".", "The", "update", "of", "NN", "is", "performed", "using", "Adam", "-LRB-", "as", "stated", "in", "our", "paper", "-RRB-", ".", "Since", "we", "can", "backpropagate", "throughout", "the", "whole", "model", ",", "the", "gradient", "for", "NN", "is", "easily", "obtained", "using", "any", "standard", "backpropagation/auto-diff", "implementation", ",", "such", "as", "available", "in", "PyTorch", ".", "This", "training", "method", "is", "very", "similar", "to", "various", "other", "works", "that", "optimize", "an", "ELBO", "using", "-LRB-", "local", "-RRB-", "reparametrization", "-LRB-", "such", "as", "-LSB-", "1", "-RSB-", "-RRB-", ",", "only", "instead", "of", "optimizing", "the", "ELBO", ",", "we", "optimize", "the", "expected", "-LRB-", "binary", "-RRB-", "cross", "entropy", "-LRB-", "similar", "to", "-LSB-", "2", "-RSB-", "-RRB-", ".", "We", "hope", "this", "clarifies", "the", "backward", "pass", "and", "update", "step", ".", "If", "not", ",", "maybe", "the", "reviewer", "can", "kindly", "point", "out", "the", "source", "of", "the", "ambiguities", "?", "Of", "course", ",", "we", "will", "update", "the", "paper", "to", "include", "the", "discussion", "above", ".", "Moreover", ",", "we", "are", "also", "planning", "to", "release", "the", "code", "for", "our", "experiments", ".", "#", "On", "the", "bound", ":", "We", "use", "this", "specific", "bound", "as", "it", "is", "a", "differentiable", "bound", "on", "the", "minimum", "of", "the", "non-differentiable", "objective", "function", "L", "-LRB-", "B", "-RRB-", ".", "Thus", ",", "it", "allows", "us", "to", "train", "a", "Neural", "Network", "with", "discrete", "weights", "using", "gradient-based", "methods", ".", "On", "the", "tightness", "of", "the", "bound", ",", "we", "quote", "from", "Staines", "&", "Barber", "-LRB-", "2012", "-RRB-", ":", "TICKTICK", "This", "bound", "can", "be", "trivially", "made", "tight", "provided", "the", "distribution", "q", "-LRB-", "B", "|", "NN", "-RRB-", "is", "flexible", "enough", "to", "allow", "all", "its", "mass", "to", "be", "placed", "in", "the", "optimal", "state", "B", "'", "=", "argmax_B", "L", "-LRB-", "B", "-RRB-", ".", "''", "were", "we", "have", "changed", "the", "variable", "names", "to", "match", "our", "case", ".", "It", "is", "easy", "to", "see", "that", "in", "our", "case", "all", "the", "mass", "can", "be", "placed", "on", "the", "optimal", "state", "as", "this", "is", "the", "case", "where", "NN", "=", "B", "'", ".", "#", "On", "the", "lack", "of", "novelty", ":", "To", "our", "knowledge", ",", "our", "paper", "introduces", "various", "novel", "aspects", "with", "respect", "to", "-LRB-", "probabilistic", "-RRB-", "Binary", "Neural", "Networks", ",", "as", "pointed", "out", "in", "our", "earlier", "responses", ".", "We", "would", "like", "to", "kindly", "ask", "the", "reviewer", "if", "we", "missed", "any", "references", "that", "we", "should", "compare", "the", "novelty", "of", "our", "work", "to", "?", "#", "On", "the", "significance", "of", "the", "experiments", ":", "We", "like", "to", "point", "out", "that", "the", "main", "goal", "of", "our", "paper", "was", "to", "introduce", "a", "novel", "method", "for", "training", "Binary", "Neural", "Networks", ".", "In", "the", "experiments", "presented", "in", "the", "paper", ",", "we", "investigate", "if", "our", "method", "is", "on", "par", "with", "an", "existing", "method", "in", "which", "an", "equivalent", "Binary", "Neural", "Network", "is", "obtained", ".", "We", "would", "like", "to", "ask", "how", "we", "should", "extend", "our", "experiments", "in", "order", "for", "the", "reviewer", "to", "consider", "them", "significant", "?", "-LSB-", "1", "-RSB-", "Diederik", "P", "Kingma", ",", "Tim", "Salimans", ",", "and", "Max", "Welling", ".", "Variational", "dropout", "and", "the", "local", "reparameteri-zation", "trick", ".", "In", "Advances", "in", "Neural", "Information", "Processing", "Systems", ",", "pp.", "2575", "--", "2583", ",", "2015", "-LSB-", "2", "-RSB-", "Oran", "Shayer", ",", "Dan", "Levi", ",", "and", "Ethan", "Fetaya", ".", "Learning", "discrete", "weights", "using", "the", "local", "repa-rameterization", "trick", ".", "In", "International", "Conference", "on", "Learning", "Representations", ",", "2018", "."], "comment_id": "B1eJDnWmy4"}, {"rels": [[0, 45, 45, 1743, "elaboration"], [45, 71, 71, 108, "list"], [45, 56, 56, 71, "elaboration"], [56, 65, 65, 71, "elaboration"], [71, 108, 45, 71, "list"], [45, 108, 108, 1743, "elaboration"], [114, 145, 108, 114, "attribution"], [108, 145, 145, 1743, "elaboration"], [145, 158, 158, 164, "elaboration"], [145, 164, 164, 1743, "elaboration"], [164, 170, 170, 190, "explanation"], [170, 181, 181, 190, "elaboration"], [181, 186, 186, 190, "elaboration"], [164, 190, 190, 1743, "elaboration"], [190, 196, 196, 209, "purpose"], [198, 209, 196, 198, "attribution"], [190, 209, 209, 1743, "elaboration"], [209, 216, 216, 221, "elaboration"], [209, 221, 221, 1743, "elaboration"], [221, 234, 234, 1743, "elaboration"], [234, 254, 254, 262, "same_unit"], [234, 246, 246, 254, "elaboration"], [254, 262, 234, 254, "same_unit"], [234, 262, 262, 1743, "example"], [262, 287, 287, 1743, "elaboration"], [287, 302, 302, 1743, "list"], [287, 293, 293, 302, "elaboration"], [302, 1743, 287, 302, "list"], [302, 310, 310, 1743, "list"], [302, 306, 306, 310, "elaboration"], [310, 1743, 302, 310, "list"], [310, 313, 313, 1743, "elaboration"], [313, 324, 324, 1743, "list"], [313, 315, 315, 324, "elaboration"], [324, 1743, 313, 324, "list"], [324, 330, 330, 366, "elaboration"], [333, 366, 330, 333, "attribution"], [334, 366, 333, 334, "attribution"], [334, 354, 354, 366, "elaboration"], [324, 366, 366, 1743, "elaboration"], [366, 402, 402, 1743, "list"], [366, 395, 395, 402, "elaboration"], [402, 1743, 366, 402, "list"], [402, 436, 436, 1743, "list"], [402, 410, 410, 436, "elaboration"], [410, 414, 414, 436, "list"], [414, 436, 410, 414, "list"], [414, 424, 424, 436, "elaboration"], [436, 1743, 402, 436, "list"], [436, 483, 483, 1743, "list"], [436, 463, 463, 482, "elaboration"], [436, 482, 482, 483, "elaboration"], [483, 1743, 436, 483, "list"], [483, 509, 509, 1743, "list"], [483, 489, 489, 509, "elaboration"], [489, 496, 496, 509, "elaboration"], [509, 1743, 483, 509, "list"], [509, 529, 529, 1743, "list"], [529, 1743, 509, 529, "list"], [529, 559, 559, 1743, "list"], [529, 534, 534, 559, "elaboration"], [535, 559, 534, 535, "attribution"], [559, 1743, 529, 559, "list"], [559, 566, 566, 580, "elaboration"], [559, 580, 580, 1743, "example"], [580, 606, 606, 1743, "list"], [580, 593, 593, 606, "elaboration"], [593, 596, 596, 606, "elaboration"], [606, 1743, 580, 606, "list"], [606, 613, 613, 1743, "list"], [613, 1743, 606, 613, "list"], [613, 646, 646, 1743, "question"], [613, 635, 635, 636, "elaboration"], [613, 636, 636, 646, "purpose"], [646, 1743, 613, 646, "question"], [646, 665, 665, 1743, "list"], [665, 1743, 646, 665, "list"], [665, 671, 671, 683, "purpose"], [665, 683, 683, 1743, "elaboration"], [683, 686, 686, 1743, "elaboration"], [686, 729, 729, 1743, "list"], [691, 729, 686, 691, "attribution"], [691, 699, 699, 729, "elaboration"], [729, 1743, 686, 729, "list"], [729, 740, 740, 1743, "list"], [731, 740, 729, 731, "attribution"], [740, 1743, 729, 740, "list"], [742, 764, 740, 742, "attribution"], [742, 751, 751, 764, "elaboration"], [751, 757, 757, 764, "elaboration"], [740, 764, 764, 1743, "elaboration"], [764, 767, 767, 1743, "elaboration"], [772, 802, 767, 772, "attribution"], [775, 802, 772, 775, "attribution"], [775, 779, 779, 802, "purpose"], [781, 802, 779, 781, "attribution"], [781, 785, 785, 802, "elaboration"], [767, 802, 802, 1743, "elaboration"], [804, 830, 802, 804, "attribution"], [804, 807, 807, 830, "purpose"], [809, 830, 807, 809, "attribution"], [816, 830, 809, 816, "attribution"], [816, 825, 825, 830, "purpose"], [802, 830, 830, 1743, "elaboration"], [830, 870, 870, 1743, "list"], [830, 852, 852, 870, "list"], [830, 844, 844, 852, "elaboration"], [852, 870, 830, 852, "list"], [852, 857, 857, 870, "elaboration"], [870, 1743, 830, 870, "list"], [870, 874, 874, 888, "elaboration"], [870, 888, 888, 1743, "elaboration"], [888, 908, 908, 1743, "list"], [890, 908, 888, 890, "attribution"], [893, 908, 890, 893, "attribution"], [893, 901, 901, 908, "same_unit"], [893, 894, 894, 901, "elaboration"], [901, 908, 893, 901, "same_unit"], [901, 902, 902, 908, "same_unit"], [902, 908, 901, 902, "same_unit"], [908, 1743, 888, 908, "list"], [908, 916, 916, 940, "elaboration"], [916, 924, 924, 940, "purpose"], [924, 933, 933, 940, "elaboration"], [908, 940, 940, 1743, "elaboration"], [940, 964, 964, 969, "purpose"], [940, 969, 969, 1743, "elaboration"], [969, 979, 979, 1005, "list"], [979, 1005, 969, 979, "list"], [979, 982, 982, 1005, "elaboration"], [982, 989, 989, 1005, "contrast"], [982, 983, 983, 989, "elaboration"], [989, 1005, 982, 989, "contrast"], [969, 1005, 1005, 1743, "elaboration"], [1005, 1026, 1026, 1743, "elaboration"], [1026, 1048, 1048, 1116, "same_unit"], [1026, 1043, 1043, 1048, "elaboration"], [1048, 1116, 1026, 1048, "same_unit"], [1059, 1116, 1048, 1059, "attribution"], [1048, 1058, 1058, 1059, "same_unit"], [1048, 1051, 1051, 1058, "elaboration"], [1058, 1059, 1048, 1058, "same_unit"], [1072, 1116, 1059, 1072, "attribution"], [1072, 1085, 1085, 1089, "elaboration"], [1072, 1089, 1089, 1116, "elaboration"], [1094, 1116, 1089, 1094, "attribution"], [1094, 1099, 1099, 1116, "same_unit"], [1094, 1095, 1095, 1099, "elaboration"], [1099, 1116, 1094, 1099, "same_unit"], [1099, 1108, 1108, 1116, "elaboration"], [1026, 1116, 1116, 1743, "elaboration"], [1116, 1124, 1124, 1165, "same_unit"], [1116, 1119, 1119, 1124, "elaboration"], [1124, 1165, 1116, 1124, "same_unit"], [1124, 1154, 1154, 1165, "elaboration"], [1116, 1165, 1165, 1743, "elaboration"], [1165, 1172, 1172, 1743, "elaboration"], [1172, 1206, 1206, 1743, "topic"], [1172, 1185, 1185, 1206, "same_unit"], [1172, 1180, 1180, 1185, "elaboration"], [1185, 1206, 1172, 1185, "same_unit"], [1185, 1197, 1197, 1206, "same_unit"], [1185, 1193, 1193, 1197, "elaboration"], [1197, 1206, 1185, 1197, "same_unit"], [1197, 1201, 1201, 1206, "elaboration"], [1206, 1743, 1172, 1206, "topic"], [1210, 1243, 1206, 1210, "attribution"], [1210, 1223, 1223, 1243, "elaboration"], [1223, 1232, 1232, 1233, "elaboration"], [1223, 1233, 1233, 1243, "elaboration"], [1234, 1243, 1233, 1234, "attribution"], [1206, 1243, 1243, 1743, "elaboration"], [1243, 1283, 1283, 1743, "list"], [1243, 1245, 1245, 1283, "list"], [1245, 1283, 1243, 1245, "list"], [1245, 1262, 1262, 1283, "elaboration"], [1262, 1269, 1269, 1283, "same_unit"], [1262, 1268, 1268, 1269, "same_unit"], [1262, 1263, 1263, 1268, "elaboration"], [1268, 1269, 1262, 1268, "same_unit"], [1269, 1283, 1262, 1269, "same_unit"], [1269, 1276, 1276, 1283, "list"], [1276, 1283, 1269, 1276, "list"], [1276, 1277, 1277, 1283, "elaboration"], [1283, 1743, 1243, 1283, "list"], [1283, 1327, 1327, 1437, "list"], [1283, 1285, 1285, 1327, "elaboration"], [1285, 1315, 1315, 1327, "elaboration"], [1327, 1437, 1283, 1327, "list"], [1327, 1341, 1341, 1356, "same_unit"], [1327, 1336, 1336, 1341, "elaboration"], [1341, 1356, 1327, 1341, "same_unit"], [1341, 1342, 1342, 1356, "attribution"], [1342, 1349, 1349, 1356, "list"], [1349, 1356, 1342, 1349, "list"], [1349, 1350, 1350, 1356, "elaboration"], [1327, 1356, 1356, 1437, "elaboration"], [1356, 1362, 1362, 1386, "purpose"], [1365, 1386, 1362, 1365, "attribution"], [1365, 1378, 1378, 1386, "elaboration"], [1356, 1386, 1386, 1437, "elaboration"], [1386, 1389, 1389, 1437, "elaboration"], [1389, 1414, 1414, 1437, "elaboration"], [1414, 1425, 1425, 1437, "elaboration"], [1283, 1437, 1437, 1743, "elaboration"], [1437, 1443, 1443, 1454, "elaboration"], [1437, 1454, 1454, 1743, "elaboration"], [1454, 1480, 1480, 1487, "elaboration"], [1454, 1487, 1487, 1743, "elaboration"], [1487, 1501, 1501, 1743, "elaboration"], [1507, 1545, 1501, 1507, "attribution"], [1507, 1514, 1514, 1545, "elaboration"], [1501, 1545, 1545, 1743, "elaboration"], [1545, 1575, 1575, 1743, "elaboration"], [1575, 1586, 1586, 1743, "elaboration"], [1586, 1597, 1597, 1607, "elaboration"], [1586, 1607, 1607, 1743, "elaboration"], [1617, 1633, 1607, 1617, "attribution"], [1607, 1633, 1633, 1743, "elaboration"], [1633, 1678, 1678, 1698, "same_unit"], [1633, 1671, 1671, 1678, "elaboration"], [1678, 1698, 1633, 1678, "same_unit"], [1678, 1679, 1679, 1698, "elaboration"], [1679, 1691, 1691, 1698, "circumstance"], [1633, 1698, 1698, 1743, "elaboration"], [1698, 1706, 1706, 1743, "elaboration"], [1706, 1713, 1713, 1743, "elaboration"], [1713, 1736, 1736, 1743, "same_unit"], [1713, 1729, 1729, 1736, "elaboration"], [1736, 1743, 1713, 1736, "same_unit"]], "tokens": ["The", "focus", "of", "this", "paper", "is", "to", "show", "that", "finite-width", "deep", "neural", "networks", "with", "fully", "connected", "layers", "and", "ReLU", "activations", "are", "rate-distortion", "optimal", "approximators", "of", "certain", "classes", "of", "functions", ",", "meaning", "the", "approximation", "error", "decays", "exponentially", "in", "the", "number", "of", "neurons", "in", "the", "network", ".", "The", "function", "classes", "explored", "in", "this", "paper", "are", ":", "1-d", "polynomials", "-LRB-", "on", "bounded", "intervals", "-RRB-", ",", "1-d", "sinusoidal", "functions", "-LRB-", "on", "bounded", "intervals", "-RRB-", ",", "and", "other", "1-d", "functions", "built", "from", "compositions", "or", "linear", "combinations", "of", "these", ",", "such", "as", "the", "so-called", "class", "of", "TICKTICK", "oscillatory", "textures", "''", "and", "a", "class", "of", "continuous", "but", "nowhere", "differentiable", "functions", "known", "as", "Weierstrass", "functions", ".", "Finally", ",", "the", "paper", "also", "shows", "that", "as", "the", "desired", "approximation", "accuracy", "goes", "to", "zero", "finite-width", "deep", "ReLU", "networks", "require", "asymptotically", "fewer", "neurons", "than", "finite-depth", "wide", "ReLU", "networks", "in", "approximating", "a", "broad", "class", "of", "smooth", "functions", ".", "The", "paper", "is", "well-written", "and", "the", "technical", "results", "are", "presented", "in", "a", "way", "that", "is", "easy", "to", "understand", ".", "The", "results", "are", "somewhat", "novel", ",", "although", "they", "do", "build", "off", "other", "recent", "works", ",", "namely", "Yarotsky", "-LRB-", "2016", "-RRB-", "and", "Telgarsky", "-LRB-", "2015", "-RRB-", ".", "However", ",", "the", "authors", "were", "careful", "to", "cite", "when", "they", "reuse", "proof", "techniques", "from", "these", "and", "other", "works", ".", "The", "results", "in", "the", "main", "text", "appear", "to", "be", "technically", "sound", ".", "I", "did", "not", "check", "carefully", "all", "the", "proofs", "in", "the", "supplemental", "materials", ".", "My", "major", "criticism", "is", "that", "the", "focus", "on", "certain", "specific", "function", "classes", "-LRB-", "oscillatory", "textures", ",", "Weierstrauss", "functions", "-RRB-", "seems", "arbitrary", ",", "and", "leaves", "open", "many", "questions", ".", "For", "example", ",", "there", "is", "existing", "work", "on", "the", "approximation", "ability", "of", "deep", "ReLU", "networks", "for", "functions", "in", "more", "general", "Holder", "and", "Sobolev", "spaces", ":", "Hadrien", "Montanelli", "and", "Qiang", "Du", ".", "Deep", "ReLU", "networks", "lessen", "the", "curse", "of", "dimensionality", ".", "arXiv", "preprint", "arXiv", ":", "1712.08688", ",", "2017", ".", "J.", "Schmidt-Hieber", ".", "Nonparametric", "regression", "using", "deep", "neural", "networks", "with", "ReLU", "activation", "function", ".", "ArXiv", "e-prints", ",", "August", "2017", ".", "I", "was", "left", "wondering", "how", "the", "present", "results", "relate", "to", "these", "works", ",", "and", "what", "insight", "we", "get", "from", "understanding", "these", "particular", "function", "classes", "that", "we", "do", "n't", "get", "from", "understanding", "Holder", "or", "Sobolev", "spaces", ".", "Major", "comments", "In", "Section", "3", ",", "I", "found", "the", "progression", "of", "the", "results", "from", "approximation", "of", "x", "^", "2", ",", "to", "multiplication", "xy", ",", "and", "to", "general", "smooth", "functions", "to", "be", "very", "natural", "and", "well-motivated", ".", "However", ",", "sections", "4", "and", "5", "seem", "lack", "somewhat", "in", "motivation", ",", "since", "here", "the", "authors", "focus", "on", "very", "specific", "function", "classes", "-LRB-", "sinusoidal", "functions", ",", "oscillatory", "textures", ",", "and", "Weierstrass", "functions", "-RRB-", ".", "While", "these", "results", "are", "still", "interesting", ",", "focusing", "on", "such", "specific", "functions", "is", "less", "satisfactory", ",", "since", "it", "raises", "questions", "about", "the", "true", "scope", "of", "the", "results", "-LRB-", "e.g.", ",", "will", "similar", "approximation", "rates", "extend", "to", "other", "fractal", "functions", ",", "or", "just", "Weierstrauss", "functions", "?", "-RRB-", ".", "Could", "the", "authors", "give", "further", "justification", "for", "why", "these", "function", "classes", "are", "interesting", "to", "focus", "on", ",", "or", "why", "they", "limit", "themselves", "in", "this", "way", "?", "Can", "the", "authors", "also", "put", "these", "results", "more", "into", "context", "with", "existing", "results", "on", "the", "approximation", "with", "ReLU", "networks", "?", "The", "authors", "state", "multiple", "times", "that", "TICKTICK", "all", "our", "results", "apply", "to", "the", "multivariate", "case", "''", "but", "that", "they", "restrict", "themselves", "to", "the", "univariate", "case", "for", "simplicity", "of", "presentation", ".", "While", "this", "is", "fine", ",", "some", "indication", "of", "how", "the", "results", "are", "altered", "in", "the", "multivariate", "case", "would", "be", "useful", ".", "For", "example", ",", "does", "the", "fixed-width", "M", "in", "multivariate", "generalizations", "of", "Prop", "3.1", "--", "3.3", "need", "to", "be", "bigger", ",", "smaller", ",", "or", "the", "same", "?", "What", "other", "constants", "are", "dimensionally", "dependent", "?", "Do", "the", "multivariate", "generalization", "of", "their", "results", "bear", "the", "TICKTICK", "curse", "of", "dimensionality", "''", ",", "i.e.", ",", "does", "the", "number", "of", "neurons", "needed", "to", "reach", "epsilon", "accuracy", "depend", "geometrically", "on", "the", "dimension", "?", "Minor", "comments", "A", "conclusion", "or", "discussion", "section", "summarizing", "the", "overall", "technical", "contribution", "would", "be", "useful", "for", "the", "reader", ".", "Also", ",", "it", "would", "be", "useful", "to", "include", "some", "discussion", "on", "remaining", "open", "problems", "or", "future", "work", ".", "On", "pg", ".", "2", ",", "the", "authors", "state", "TICKTICK", "the", "approximation", "results", "throughout", "the", "paper", "guarantee", "that", "the", "magnitude", "of", "the", "weights", "in", "the", "network", "does", "not", "grow", "faster", "than", "polynomially", "in", "the", "cardinality", "of", "of", "the", "domain", "over", "which", "the", "approximation", "takes", "place", "''", ".", "What", "does", "TICKTICK", "cardinality", "of", "the", "domain", "''", "here", "mean", "?", "I", "think", "the", "authors", "mean", "the", "size", "D", "of", "the", "interval", "-LSB-", "-", "D", ",", "D", "-RSB-", "over", "which", "the", "approximation", "is", "valid", ".", "On", "pg", ".", "7", ",", "the", "authors", "say", "TICKTICK", "We", "note", "that", "this", "result", "allows", "to", "show", "that", "local", "cosine", "bases", "-LRB-", "cite", "-RRB-", "can", "be", "approximated", "by", "deep", "ReLU", "networks", "with", "exponential", "error", "decay", "...", "''", ".", "I", "think", "the", "authors", "mean", "to", "say", "TICKTICK", "...", "this", "result", "allows", "us", "to", "show", "...", "''", "or", "TICKTICK", "this", "result", "allows", "one", "to", "show", "...", "''", ".", "Although", "it", "'s", "not", "clear", "to", "me", "whether", "this", "means", "it", "has", "been", "shown", "-LRB-", "it", "'s", "a", "direct", "corollary", "-RRB-", ",", "or", "could", "possible", "be", "shown", "-LRB-", "it", "'s", "a", "corollary", ",", "but", "needs", "some", "non-trivial", "work", "-RRB-", ".", "Also", ",", "one", "line", "to", "specify", "what", "a", "TICKTICK", "local", "cosine", "basis", "''", "is", "would", "be", "helpful", ".", "Thank", "you", "for", "pointing", "out", "references", "-LRB-", "Montanelli", "et", "al.", ",", "2017", "-RRB-", "and", "-LRB-", "Schmidt-Hieber", ",", "2017", "-RRB-", ".", "We", "considered", "the", "Weierstrass", "function", "and", "oscillatory", "textures", "as", "these", "functions", "are", "known", "to", "be", "hard", "to", "approximate", "and", "there", "are", "no", "known", "classical", "methods", "that", "would", "yield", "exponential", "approximation", "accuracy", ".", "The", "main", "point", "of", "our", "results", "here", "is", "that", "deep", "ReLU", "networks", "do", "provide", "exponential", "approximation", "accuracy", "and", "are", "hence", "the", "first", "approximation", "method", "to", "deliver", "exponential", "accuracy", ".", "Moreover", ",", "the", "Weierstrass", "function", "does", "not", "have", "weak", "derivatives", "and", "possesses", "Hlder", "smoothness", "which", "can", "be", "infinitely", "small", ";", "it", "can", "therefore", "not", "be", "considered", "an", "element", "of", "a", "particular", "Hlder", "or", "Sobolev", "space", ".", "Regarding", "our", "other", "results", ",", "we", "achieve", "faster", "approximation", "rates", "than", "the", "ones", "obtained", "for", "general", "Sobolev", "and", "Hlder", "spaces", ".", "The", "ReLU", "network", "approximation", "results", "for", "functions", "in", "the", "unit", "ball", "in", "Sobolev", "spaces", "first", "obtained", "in", "-LRB-", "Yarotsky", ",", "2017", "-RRB-", "and", "cited", "in", "-LRB-", "Montanelli", "et", "al.", ",", "2017", "-RRB-", "show", "that", "the", "number", "of", "nonzero", "weights", "needed", "in", "the", "approximating", "ReLU", "network", "grows", "TICKTICK", "polynomially", "''", "in", "the", "inverse", "of", "the", "approximation", "error", ",", "e.g.", "O", "-LRB-", "\\", "eps", "^", "-LCB-", "-", "d/m", "-RCB-", "\\", "log", "-LRB-", "1/eps", "-RRB-", "-RRB-", "for", "W", "^", "-LCB-", "m", ",", "\\", "infty", "-RCB-", "-LRB-", "-LSB-", "0,1", "-RSB-", "^", "d", "-RRB-", ".", "Theorem", "5", "in", "-LRB-", "Schmidt-Hieber", ",", "2017", "-RRB-", "also", "states", "that", "in", "the", "approximation", "of", "functions", "in", "the", "unit", "ball", "in", "Hlder", "spaces", ",", "the", "number", "of", "nonzero", "weights", "needed", "in", "the", "approximating", "ReLU", "network", "has", "to", "grow", "TICKTICK", "polynomially", "''", "in", "the", "inverse", "of", "the", "approximation", "error", ".", "In", "contrast", ",", "we", "show", "1", ".", "Exponential", "approximation", "accuracy", "for", "highly", "oscillatory", "sinusoidal", "functions", "-LRB-", "Theorem", "4.1", "-RRB-", ",", "leading", "to", "exponential", "approximation", "accuracy", "for", "oscillatory", "textures", "-LRB-", "Proposition", "5.2", "-RRB-", "and", "the", "Weierstrass", "function", "-LRB-", "Proposition", "5.4", "-RRB-", ".", "Exponential", "approximation", "accuracy", "means", "that", "the", "approximation", "error", "decays", "exponentially", "in", "the", "number", "of", "nonzero", "weights", ",", "which", "is", "equivalent", "to", "the", "number", "of", "nonzero", "weights", "required", "growing", "TICKTICK", "logarithmically", "''", "in", "the", "inverse", "approximation", "error", ".", "2", ".", "Our", "results", "are", "stated", "for", "arbitrary", "domains", ",", "in", "contrast", "to", "a", "restriction", "to", "the", "unit", "ball", "in", "-LRB-", "Yarotsky", ",", "2017", "-RRB-", ",", "-LRB-", "Montanelli", "et", "al.", ",", "2017", "-RRB-", "and", "-LRB-", "Schmidt-Hieber", ",", "2017", "-RRB-", ".", "3", ".", "We", "establish", "that", "the", "weights", "in", "the", "networks", "we", "construct", "grow", "no", "faster", "than", "polynomial", "in", "the", "size", "of", "the", "domain", "over", "which", "approximation", "is", "carried", "out", ",", "a", "result", "that", "is", "crucial", "to", "be", "able", "to", "conclude", "exponential", "approximation", "accuracy", ".", "Such", "a", "result", "is", "not", "available", "in", "existing", "work", "-LRB-", "Yarotsky", ",", "2017", "-RRB-", ",", "-LRB-", "Montanelli", "et", "al.", ",", "2017", "-RRB-", "and", "-LRB-", "Schmidt-Hieber", ",", "2017", "-RRB-", ".", "These", "three", "novel", "aspects", "allow", "us", "to", "then", "conclude", "that", "the", "approximation", "results", "we", "found", "are", "best", "possible", "in", "the", "sense", "of", "-LRB-", "Blcskei", "et", "al.", ",", "2017", "-RRB-", ".", "--", "Major", "comments", "--", "On", "the", "motivation", "to", "focus", "on", "specific", "function", "classes", "We", "find", "these", "results", "interesting", "as", "they", "demonstrate", "that", "deep", "ReLU", "networks", "can", "deliver", "something", "that", "to", "date", "has", "not", "been", "accomplished", ",", "namely", "to", "approximate", "-LRB-", "certain", "-RRB-", "fractal", "functions", "and", "oscillatory", "textures", "with", "exponential", "accuracy", ".", "We", "chose", "these", "two", "function", "classes", "as", "they", "are", "known", "to", "be", "notoriously", "hard", "to", "approximate", ".", "In", "fact", ",", "the", "best", "approximation", "results", "available", "in", "the", "literature", "for", "these", "function", "classes", "exhibit", "low-order", "polynomial", "approximation", "accuracy", ",", "i.e.", ",", "polynomial", "error", "decay", "as", "opposed", "to", "exponential", "error", "decay", ".", "In", "practice", ",", "the", "functional", "dependence", "a", "network", "is", "to", "learn", "is", "unknown", ".", "In", "this", "sense", "our", "results", "say", "that", "even", "very", "unusual", "functional", "dependencies", "can", "be", "learned", ",", "in", "fact", ",", "optimally", "so", "in", "an", "approximation-theoretic", "sense", ",", "by", "a", "deep", "ReLU", "network", ",", "thus", "speaking", "to", "the", "universal", "approximation", "capability", "of", "deep", "ReLU", "networks", ".", "The", "results", "on", "the", "approximation", "of", "the", "Weierstrass", "function", "can", "be", "extended", "in", "a", "straightforward", "way", "to", "certain", "fractal", "functions", "of", "the", "same", "nature", ",", "e.g.", "the", "Blancmange", "curve", ".", "The", "generalization", "to", "all", "fractal", "functions", "remains", "an", "open", "problem", ".", "On", "the", "curse", "of", "dimensionality", "The", "multivariate", "generalizations", "of", "Props", ".", "3.1", "&", "3.2", "follow", "straightforwardly", "from", "the", "univariate", "case", ".", "For", "the", "multivariate", "generalization", "of", "Prop.", "3.3", "one", "can", "show", "that", "the", "width", "grows", "linearly", ",", "and", "hence", "optimally", ",", "in", "the", "number", "of", "dimensions", ".", "The", "multivariate", "generalizations", "of", "our", "results", "do", "not", "suffer", "from", "a", "TICKTICK", "curse", "of", "dimensionality", "''", ";", "in", "fact", ",", "our", "results", "exhibit", "the", "same", "qualitative", "behavior", "as", "those", "reported", "previously", "in", "Prop.", "3.3", "and", "Lemma", "3.8", "in", "-LRB-", "Schwab", "&", "Zech", ",", "2017", "-RRB-", ",", "which", "show", "that", "the", "TICKTICK", "curse", "of", "dimensionality", "''", "can", "be", "overcome", "when", "approximating", "polynomials", "by", "ReLU", "networks", ".", "In", "addition", ",", "it", "was", "shown", "recently", "in", "-LRB-", "Grohs", "et", "al.", ",", "2018", "-RRB-", "that", "deep", "ReLU", "networks", "can", "approximate", "certain", "solution", "families", "of", "parametric", "PDEs", "depending", "on", "a", "large", "-LRB-", "possibly", "infinite", "-RRB-", "number", "of", "parameters", "while", "overcoming", "the", "curse", "of", "dimensionality", "."], "comment_id": "B1eFQNnYCQ"}, {"rels": [[0, 20, 20, 457, "textualorganization"], [0, 2, 2, 20, "elaboration"], [20, 457, 0, 20, "textualorganization"], [20, 36, 36, 457, "elaboration"], [36, 48, 48, 54, "elaboration"], [36, 54, 54, 58, "manner"], [36, 58, 58, 457, "elaboration"], [58, 66, 66, 77, "elaboration"], [66, 71, 71, 77, "same_unit"], [66, 70, 70, 71, "elaboration"], [71, 77, 66, 71, "same_unit"], [58, 77, 77, 457, "elaboration"], [77, 87, 87, 94, "elaboration"], [77, 94, 94, 457, "elaboration"], [94, 103, 103, 118, "contrast"], [103, 118, 94, 103, "contrast"], [106, 118, 103, 106, "attribution"], [94, 118, 118, 457, "elaboration"], [118, 119, 119, 120, "elaboration"], [118, 120, 120, 142, "elaboration"], [120, 128, 128, 142, "elaboration"], [118, 142, 142, 153, "elaboration"], [142, 150, 150, 153, "elaboration"], [118, 153, 153, 457, "elaboration"], [153, 174, 174, 181, "elaboration"], [153, 181, 181, 457, "elaboration"], [181, 331, 331, 457, "list"], [181, 182, 182, 183, "elaboration"], [181, 183, 183, 193, "elaboration"], [181, 193, 193, 224, "elaboration"], [193, 196, 196, 224, "purpose"], [196, 198, 198, 224, "purpose"], [198, 207, 207, 224, "list"], [207, 224, 198, 207, "list"], [181, 224, 224, 234, "elaboration"], [181, 234, 234, 331, "elaboration"], [247, 259, 234, 247, "condition"], [247, 253, 253, 259, "elaboration"], [234, 259, 259, 331, "elaboration"], [259, 279, 279, 331, "elaboration"], [279, 286, 286, 300, "purpose"], [286, 290, 290, 300, "elaboration"], [279, 300, 300, 331, "elaboration"], [300, 308, 308, 331, "elaboration"], [308, 312, 312, 331, "list"], [312, 331, 308, 312, "list"], [314, 331, 312, 314, "attribution"], [314, 315, 315, 331, "circumstance"], [331, 457, 181, 331, "list"], [331, 344, 344, 367, "elaboration"], [344, 359, 359, 367, "elaboration"], [331, 367, 367, 457, "elaboration"], [367, 375, 375, 407, "purpose"], [377, 407, 375, 377, "attribution"], [377, 401, 401, 407, "elaboration"], [367, 407, 407, 457, "elaboration"], [427, 457, 407, 427, "attribution"], [427, 440, 440, 457, "elaboration"]], "tokens": ["Summary", ":", "The", "role", "of", "auxiliary", "tasks", "is", "to", "improve", "the", "generalization", "performance", "of", "the", "principal", "task", "of", "interest", ".", "So", "far", ",", "hand-crafted", "auxiliary", "tasks", "are", "generated", ",", "tailored", "for", "a", "problem", "of", "interest", ".", "The", "current", "work", "addresses", "a", "meta-learning", "approach", "to", "automatically", "generate", "auxiliary", "tasks", "suited", "to", "the", "principal", "task", ",", "without", "human", "knowledge", ".", "The", "key", "components", "of", "the", "method", "are", ":", "-LRB-", "1", "-RRB-", "meta-generator", ";", "-LRB-", "2", "-RRB-", "multi-task", "evaluator", ".", "These", "two", "models", "are", "trained", "using", "the", "gradient-based", "meta-learning", "technique", "-LRB-", "for", "instance", ",", "MAML", "-RRB-", ".", "The", "problem", "of", "image", "classification", "is", "considered", "only", ",", "while", "authors", "claimed", "the", "method", "can", "be", "easily", "applied", "to", "other", "problems", "as", "well", ".", "Strengths", ":", "-", "To", "my", "best", "knowledge", ",", "the", "idea", "of", "applying", "the", "meta-learning", "to", "the", "automatic", "generation", "of", "auxiliary", "tasks", "is", "novel", ".", "-", "The", "paper", "is", "well", "written", "and", "easy", "to", "read", ".", "-", "The", "method", "nicely", "blends", "a", "few", "components", "such", "as", "self-supervised", "learning", ",", "meta-learning", ",", "auxiliary", "tasks", "into", "a", "single", "model", "to", "tackle", "the", "meta", "auxiliary", "learning", ".", "Weakness", ":", "-", "The", "performance", "gain", "is", "not", "substantial", "in", "experiments", ".", "I", "would", "like", "to", "suggest", "to", "use", "the", "state-of-the-arts", "classifier", "for", "the", "principal", "task", "and", "to", "evaluate", "how", "much", "gain", "your", "method", "can", "get", "with", "the", "help", "of", "auxiliary", "tasks", ".", "You", "can", "refer", "to", "the", "state-of-the-arts", "performance", "on", "CIFAR", ".", "-", "If", "the", "information", "on", "the", "hierarchy", "of", "sub-categories", "is", "not", "available", ",", "it", "will", "be", "an", "annoying", "hyperparameters", "that", "should", "be", "well", "tuned", ".", "We", "thank", "for", "the", "reviewer", "for", "their", "positive", "comments", "on", "our", "work", ",", "and", "we", "share", "our", "responses", "below", ".", "The", "purpose", "of", "our", "work", "is", "not", "to", "achieve", "state-of-the-art", "performance", "simply", "by", "incorporating", "the", "latest", "network", "architectures", "and", "optimisers", ".", "Instead", ",", "we", "provide", "a", "novel", "general", "framework", "for", "automating", "generalisation", ",", "and", "show", "that", "when", "used", "with", "standard", "classification", "networks", "across", "all", "baselines", ",", "our", "method", "performs", "the", "best", ".", "Furthermore", ",", "as", "we", "also", "explained", "in", "Reviewer", "#", "3", ",", "the", "hyper-parameters", "for", "defining", "a", "hierarchy", "is", "not", "critical", ",", "and", "we", "can", "choose", "an", "arbitrary", "hierarchy", "whilst", "still", "achieving", "better", "performance", "than", "baselines", ".", "In", "the", "future", "work", ",", "we", "would", "like", "to", "explore", "how", "to", "find", "the", "optimal", "hierarchy", "in", "an", "automatic", "manner", ",", "or", "provide", "an", "alternative", "solution", "on", "building", "a", "general", "type", "of", "auxiliary", "tasks", "-LRB-", "such", "as", "regression", "-RRB-", ".", "However", ",", "this", "is", "the", "first", "work", "to", "present", "a", "double-gradient", "method", "for", "auxiliary", "task", "generation", ",", "and", "we", "believe", "that", "it", "is", "important", "to", "present", "the", "success", "of", "this", "initial", "method", "now", "given", "how", "simple", "and", "general", "it", "is", ",", "and", "then", "fine-tune", "other", "aspects", "in", "future", "work", "."], "comment_id": "B1esP4YtAm"}, {"rels": [[0, 8, 8, 17, "list"], [8, 17, 0, 8, "list"], [8, 15, 15, 17, "elaboration"], [0, 17, 17, 1161, "elaboration"], [17, 26, 26, 87, "elaboration"], [29, 41, 26, 29, "attribution"], [26, 41, 41, 87, "elaboration"], [17, 87, 87, 1161, "elaboration"], [87, 112, 112, 147, "elaboration"], [112, 137, 137, 147, "means"], [87, 147, 147, 1161, "elaboration"], [147, 164, 164, 1161, "list"], [147, 152, 152, 164, "elaboration"], [155, 164, 152, 155, "attribution"], [155, 161, 161, 164, "purpose"], [164, 1161, 147, 164, "list"], [164, 177, 177, 1161, "topic"], [164, 174, 174, 177, "same_unit"], [174, 177, 164, 174, "same_unit"], [177, 1161, 164, 177, "topic"], [177, 221, 221, 1161, "elaboration"], [221, 231, 231, 241, "elaboration"], [221, 241, 241, 1161, "elaboration"], [241, 256, 256, 1161, "elaboration"], [256, 267, 267, 1161, "elaboration"], [270, 298, 267, 270, "attribution"], [273, 298, 270, 273, "attribution"], [273, 281, 281, 298, "manner"], [281, 284, 284, 298, "elaboration"], [267, 298, 298, 1161, "elaboration"], [298, 321, 321, 1161, "elaboration"], [321, 338, 338, 1161, "list"], [321, 323, 323, 338, "elaboration"], [338, 1161, 321, 338, "list"], [338, 350, 350, 354, "elaboration"], [338, 354, 354, 399, "elaboration"], [354, 359, 359, 399, "elaboration"], [359, 377, 377, 399, "elaboration"], [338, 399, 399, 1161, "elaboration"], [399, 405, 405, 419, "elaboration"], [399, 419, 419, 444, "elaboration"], [430, 444, 419, 430, "attribution"], [430, 439, 439, 444, "elaboration"], [399, 444, 444, 1161, "elaboration"], [448, 463, 444, 448, "attribution"], [448, 459, 459, 463, "elaboration"], [444, 463, 463, 1161, "elaboration"], [463, 475, 475, 503, "same_unit"], [463, 465, 465, 475, "elaboration"], [475, 503, 463, 475, "same_unit"], [475, 490, 490, 503, "list"], [475, 484, 484, 490, "elaboration"], [490, 503, 475, 490, "list"], [463, 503, 503, 1161, "elaboration"], [503, 512, 512, 524, "elaboration"], [503, 524, 524, 529, "elaboration"], [503, 529, 529, 552, "elaboration"], [529, 542, 542, 552, "elaboration"], [542, 548, 548, 552, "elaboration"], [503, 552, 552, 1161, "elaboration"], [552, 565, 565, 1161, "elaboration"], [565, 597, 597, 619, "elaboration"], [565, 619, 619, 620, "elaboration"], [565, 620, 620, 1161, "circumstance"], [620, 811, 811, 1161, "topic"], [620, 643, 643, 653, "elaboration"], [620, 653, 653, 811, "elaboration"], [653, 666, 666, 811, "elaboration"], [666, 688, 688, 700, "same_unit"], [666, 682, 682, 688, "elaboration"], [688, 700, 666, 688, "same_unit"], [688, 693, 693, 700, "elaboration"], [666, 700, 700, 811, "elaboration"], [700, 705, 705, 717, "elaboration"], [700, 717, 717, 738, "elaboration"], [700, 738, 738, 811, "elaboration"], [738, 755, 755, 773, "purpose"], [755, 761, 761, 773, "elaboration"], [761, 762, 762, 773, "purpose"], [762, 769, 769, 773, "elaboration"], [738, 773, 773, 811, "elaboration"], [773, 778, 778, 788, "elaboration"], [778, 785, 785, 788, "purpose"], [773, 788, 788, 811, "elaboration"], [788, 792, 792, 811, "elaboration"], [792, 796, 796, 801, "elaboration"], [792, 801, 801, 811, "elaboration"], [801, 808, 808, 811, "elaboration"], [811, 1161, 620, 811, "topic"], [811, 814, 814, 1161, "elaboration"], [814, 825, 825, 844, "means"], [825, 829, 829, 837, "elaboration"], [825, 837, 837, 844, "elaboration"], [814, 844, 844, 1161, "explanation"], [844, 853, 853, 865, "elaboration"], [844, 865, 865, 1161, "elaboration"], [865, 871, 871, 1161, "textualorganization"], [867, 871, 865, 867, "attribution"], [871, 1161, 865, 871, "textualorganization"], [871, 880, 880, 898, "elaboration"], [871, 898, 898, 1161, "elaboration"], [898, 977, 977, 1161, "list"], [898, 903, 903, 977, "elaboration"], [903, 922, 922, 928, "elaboration"], [903, 928, 928, 977, "elaboration"], [928, 930, 930, 956, "elaboration"], [930, 935, 935, 956, "elaboration"], [935, 939, 939, 956, "elaboration"], [928, 956, 956, 977, "elaboration"], [956, 964, 964, 977, "elaboration"], [977, 1161, 898, 977, "list"], [977, 991, 991, 1037, "elaboration"], [991, 1025, 1025, 1037, "same_unit"], [991, 999, 999, 1025, "elaboration"], [1025, 1037, 991, 1025, "same_unit"], [1036, 1037, 1025, 1036, "attribution"], [977, 1037, 1037, 1161, "elaboration"], [1037, 1042, 1042, 1161, "elaboration"], [1042, 1065, 1065, 1069, "elaboration"], [1042, 1069, 1069, 1095, "elaboration"], [1042, 1095, 1095, 1161, "elaboration"], [1095, 1129, 1129, 1139, "elaboration"], [1095, 1139, 1139, 1161, "elaboration"], [1139, 1151, 1151, 1161, "elaboration"]], "tokens": ["We", "first", "thank", "the", "reviewers", "for", "their", "reviews", "and", "now", "answer", "individually", "to", "the", "concerns", "raised", ".", "-", "Review", "#", "1", ":", "Thanks", "a", "lot", ".", "We", "are", "glad", "that", "the", "interest", "of", "our", "contributions", "has", "been", "understood", "and", "appreciated", ".", "On", "top", "of", "the", "contributions", "mentioned", ",", "we", "also", "would", "like", "to", "mention", "the", "sound", "probabilistic", "formulation", "of", "our", "model", "which", "we", "think", "can", "be", "valuable", "since", "the", "probabilistic", "interpretation", "of", "the", "attributes", "allows", "to", "perform", "meaningful", "interpolations", "and", "to", "introduce", "a", "new", "sampling", "procedure", ".", "Indeed", ",", "understanding", "the", "interaction", "and", "the", "dynamics", "between", "all", "the", "elements", "highly", "interests", "us", "and", "we", "will", "work", "on", "that", "in", "the", "future", ":", "Especially", ",", "we", "would", "like", "to", "investigate", "how", "the", "dimensionality", "of", "the", "attribute", "space", "affects", "the", "learnt", "attributes", "and", "how", "we", "can", "shape", "these", "attributes", "by", "providing", ",", "for", "instance", ",", "weaker", "attribute", "functions", ".", "-", "Review", "#", "2", ":", "We", "are", "sorry", "that", "you", "find", "our", "paper", "hard", "to", "follow", ".", "Can", "you", "be", "more", "specific", "or", "provide", "us", "with", "ideas", "for", "improvement", "?", "We", "are", "quite", "surprised", "about", "this", "statement", "since", "we", "tried", "to", "be", "as", "detailed", "as", "possible", ":", "all", "aspects", "of", "the", "model", "are", "discussed", ",", "motivated", "and", "progressively", "introduced", ";", "we", "also", "provided", "a", "detailed", "algorithm", "together", "with", "a", "figure", "of", "our", "architecture", ".", "The", "experimental", "part", "illustrates", "the", "different", "and", "novel", "sampling", "schemes", "offered", "by", "VarNet", "on", "a", "well-known", "and", "simple", "dataset", ".", "It", "is", "here", "for", "illustration", "purposes", "and", "it", "is", "not", "intended", "to", "prove", "anything", ".", "Our", "paper", "is", "not", "about", "a", "specific", "model", "or", "implementation", ".", "We", "chose", "MNIST", "because", "it", "allows", "to", "easily", "understand", "what", "this", "framework", "provides", ",", "without", "the", "need", "to", "focus", "on", "the", "implementation", "of", "the", "encoder", ",", "decoder", "and", "attribute", "function", ".", "That", "'s", "why", "we", "chose", "simple", "MLPs", "for", "the", "encoder", ",", "decoder", "and", "attribute", "function", "and", "put", "this", "experimental", "part", "in", "appendix", ".", "The", "paper", "you", "propose", "is", "indeed", "relevant", "and", "we", "will", "include", "it", "in", "the", "related", "works", ".", "But", "this", "approach", ",", "like", "the", "Fader", "networks", ",", "requires", "known", "attributes", "-LRB-", "appearance", "-RRB-", ".", "Concerning", "the", "last", "question", ",", "what", "prevents", "z", "*", "to", "be", "independent", "of", "x", "is", "that", "the", "attribute", "space", "is", "of", "low", "dimensionality", "-LRB-", "as", "in", "the", "Style", "Tokens", "paper", "-RRB-", ",", "so", "you", "can", "not", "fully", "reconstruct", "x", "by", "only", "considering", "its", "attributes", ".", "In", "the", "degenerate", "case", ",", "z", "*", "is", "a", "noise", "independent", "of", "x", "and", "VarNet", "amounts", "to", "a", "WAE", ".", "-", "Review", "#", "3", ":", "See", "reply", "to", "reviewer", "#", "2", "concerning", "the", "clarity", "of", "our", "paper", "or", "the", "discussion", "concerning", "the", "experimental", "part", ".", "Indeed", ",", "we", "believe", "that", "the", "part", "in", "appendix", "is", "optional", "and", "is", "just", "here", "for", "illustrative", "purposes", ".", "\\", "phi", "-LRB-", "x", ",", "m", "-RRB-", "is", "just", "any", "neural", "network", "TICKTICK", "This", "attribute", "function", "is", "a", "deterministic", "neural", "network", "that", "will", "be", "learned", "during", "training", "and", "whose", "aim", "is", "to", "compute", "attributes", "of", "x", "''", "Sect.", "2.1", ".", "In", "the", "experiments", ",", "it", "is", "just", "a", "MLP", "-LRB-", "depending", "on", "x", "only", "or", "on", "x", "and", "m", "-RRB-", ".", "We", "will", "precise", "that", ".", "Concerning", "your", "3rd", "paragraph", ",", "we", "would", "like", "to", "stress", "upon", "the", "fact", "that", "there", "is", "no", "ground", "truth", "for", "the", "attributes", ".", "The", "purpose", "of", "this", "framework", "is", "not", "about", "that", "nor", "about", "disentanglement", ".", "Also", ",", "this", "is", "a", "framework", "to", "devise", "generative", "models", "with", "novel", "sampling", "properties", ",", "not", "about", "a", "specific", "implementation", ",", "so", "there", "is", "no", "point", "in", "showing", "log-likelihood", "of", "the", "reconstructions", "-LRB-", "even", "if", "we", "take", "the", "same", "encoder", "and", "decoder", "networks", ",", "how", "to", "fairly", "compare", "this", "with", "a", "VAE", "?", "-RRB-", ".", "When", "applied", "bluntly", "on", "CelebA", "and", "by", "considering", "the", "TICKTICK", "Eyeglasses", "''", "attribute", ",", "we", "are", "for", "instance", "capable", "of", "adding", "different", "style", "of", "glasses", "on", "the", "same", "face", "simply", "by", "sampling", ".", "The", "attribute", "function", "learns", "in", "this", "case", "some", "kind", "of", "color", "palette", ".", "On", "Dsprites", ",", "we", "can", "obtain", "two-dimensional", "planes", "of", "variations", "accounting", "for", "the", "scale", "and", "y-position", "-LRB-", "controlled", "by", "the", "x-axis", "-RRB-", "and", "the", "rotation", "and", "x-position", "-LRB-", "controlled", "by", "the", "y-axis", "-RRB-", ".", "There", "is", "indeed", "no", "reason", "why", "we", "could", "obtain", "a", "dimension", "accounting", "for", "only", "one", "attribute", ".", "We", "also", "applied", "this", "framework", "to", "the", "generation", "of", "sequences", "of", "discrete", "symbols", "and", "on", "sound", "generation", "with", "successful", "results", ".", "Since", "these", "experiments", "require", "more", "tuning", "about", "the", "encoder", ",", "decoder", "and", "attribute", "functions", ",", "we", "preferred", "to", "only", "display", "the", "simplest", "experiment", "allowing", "to", "understand", "and", "focus", "on", "the", "possibilities", "offered", "by", "VarNet", ".", "Here", "there", "are", "some", "specifics", "about", "why", "I", "found", "the", "paper", "difficult", "to", "follow", ".", "There", "are", "isolated", "statements", "that", "lack", "a", "motivation", "that", "can", "guide", "the", "reader", "about", "why", "this", "was", "a", "logical", "step", "to", "do", ".", "Two", "examples", ":", "TICKTICK", "The", "idea", "is", "then", "to", "compute", "z", "from", "z", "CD", "by", "applying", "a", "transformation", "parametrized", "only", "by", "the", "feature", "space", "NN", "''", "--", ">", "what", "is", "the", "motivation", "?", "TICKTICK", "We", "now", "consider", "the", "regularization", "over", "Z", ".", "This", "regularization", "is", "in", "fact", "superfluous", "and", "could", "be", "removed", ".", "''", "--", ">", "why", "is", "that", "?", "The", "is", "a", "lack", "of", "justification", "in", "many", "places", "in", "which", "many", "things", "are", "taken", "for", "granted", ",", "or", "there", "is", "not", "a", "clear", "cause-effect", "flow", ".", "To", "mention", "three", "examples", ":", "-", "TICKTICK", "However", ",", "there", "is", "no", "reason", ",", "for", "a", "random", "attribute", "NN", "CD", "NN", "/", "=", "NN", "-LRB-", "x", ",", "m", "-RRB-", ",", "that", "p", "-LRB-", "x", "|", "z", "-RRB-", "where", "z", "FW", "q", "-LRB-", "z", "|", "x", ",", "NN", "-RRB-", "generates", "variations", "of", "the", "original", "x", "with", "features", "VBP", "''", "--", ">", "what", "is", "the", "role", "of", "NN", "given", "that", "it", "is", "not", "mentioned", "in", "the", "rest", "of", "the", "sentence", "?", "-", "Regarding", "2.3.1", ",", "it", "is", "not", "clear", "why", "the", "distribution", "_", "turns", "out", "to", "be", "similar", "to", "the", "outputs", "of", "_i", "-LRB-", "even", "more", "so", "if", "the", "discriminator", "encourages", "them", "to", "be", "turned", "apart", ",", "and", "so", "making", "it", "easy", "to", "separate", "z", "*", "and", "NN", ",", "while", "allowing", "z", "*", "to", "contain", "all", "information", "about", "x", "-RRB-", ".", "-", "In", "sec.", "3.1", ".", "TICKTICK", "This", "degenerate", "behavior", "is", "a", "side-effect", "of", "our", "adversarial", "regularization", "since", "stochastic", "encoders", "have", "been", "successfully", "used", "in", "WAEs", "Rubenstein", "et", "al.", "-LRB-", "2018", "-RRB-", "''", "it", "is", "not", "clear", "what", "adversarial", "regularization", "has", "to", "do", "with", "the", "degenerate", "behavior", ",", "and", "how", "the", "reference", "gives", "any", "support", "to", "that", "claim", ".", "Overall", ",", "given", "that", "the", "proposed", "model", "has", "a", "fair", "degree", "of", "complexity", "and", "thus", "is", "difficult", "to", "explain", ",", "it", "may", "be", "helpful", "to", "illustrate", "and", "motivate", "its", "parts", "with", "a", "specific", "example", "-LRB-", "e.g.", "an", "image", "of", "a", "particular", "thing", "-RRB-", ",", "describing", "for", "each", "element", "of", "the", "approach", ",", "the", "kind", "of", "information", "it", "is", "supposed", "to", "contain", "for", "that", "particular", "case", "."], "comment_id": "B1efH9Ngg4"}, {"rels": [[0, 256, 256, 1116, "textualorganization"], [0, 2, 2, 256, "textualorganization"], [2, 256, 0, 2, "textualorganization"], [2, 7, 7, 21, "elaboration"], [2, 21, 21, 256, "elaboration"], [21, 26, 26, 38, "same_unit"], [21, 25, 25, 26, "elaboration"], [26, 38, 21, 26, "same_unit"], [26, 33, 33, 38, "elaboration"], [21, 38, 38, 256, "elaboration"], [38, 59, 59, 71, "elaboration"], [38, 71, 71, 83, "elaboration"], [38, 83, 83, 256, "elaboration"], [83, 85, 85, 92, "elaboration"], [83, 92, 92, 128, "elaboration"], [92, 97, 97, 128, "elaboration"], [97, 110, 110, 111, "elaboration"], [97, 111, 111, 115, "elaboration"], [97, 115, 115, 128, "elaboration"], [115, 118, 118, 128, "elaboration"], [118, 127, 127, 128, "same_unit"], [118, 123, 123, 127, "elaboration"], [127, 128, 118, 127, "same_unit"], [83, 128, 128, 256, "elaboration"], [128, 131, 131, 256, "elaboration"], [131, 133, 133, 140, "elaboration"], [131, 140, 140, 256, "elaboration"], [140, 154, 154, 159, "same_unit"], [140, 148, 148, 154, "elaboration"], [154, 159, 140, 154, "same_unit"], [154, 155, 155, 159, "elaboration"], [140, 159, 159, 256, "elaboration"], [159, 173, 173, 182, "elaboration"], [159, 182, 182, 201, "elaboration"], [159, 201, 201, 256, "elaboration"], [201, 237, 237, 256, "same_unit"], [201, 213, 213, 237, "elaboration"], [213, 217, 217, 237, "elaboration"], [217, 221, 221, 237, "elaboration"], [221, 231, 231, 237, "elaboration"], [237, 256, 201, 237, "same_unit"], [237, 248, 248, 256, "elaboration"], [248, 252, 252, 256, "elaboration"], [256, 1116, 0, 256, "textualorganization"], [256, 280, 280, 299, "sequence"], [256, 276, 276, 280, "elaboration"], [280, 299, 256, 280, "sequence"], [256, 299, 299, 1116, "circumstance"], [299, 318, 318, 1116, "list"], [318, 1116, 299, 318, "list"], [318, 335, 335, 1116, "elaboration"], [335, 355, 355, 1116, "list"], [335, 337, 337, 355, "elaboration"], [337, 345, 345, 355, "purpose"], [345, 348, 348, 355, "comparison"], [355, 1116, 335, 355, "list"], [355, 366, 366, 1116, "list"], [366, 1116, 355, 366, "list"], [366, 375, 375, 1116, "list"], [366, 369, 369, 375, "purpose"], [375, 1116, 366, 375, "list"], [375, 389, 389, 1116, "elaboration"], [389, 415, 415, 1116, "list"], [407, 415, 389, 407, "attribution"], [415, 1116, 389, 415, "list"], [415, 424, 424, 1116, "elaboration"], [429, 457, 424, 429, "attribution"], [429, 433, 433, 457, "elaboration"], [424, 457, 457, 1116, "elaboration"], [457, 475, 475, 1116, "elaboration"], [475, 484, 484, 1116, "elaboration"], [484, 487, 487, 495, "purpose"], [484, 495, 495, 1116, "elaboration"], [495, 504, 504, 1116, "list"], [504, 1116, 495, 504, "list"], [504, 512, 512, 1116, "elaboration"], [514, 524, 512, 514, "attribution"], [514, 520, 520, 524, "elaboration"], [512, 524, 524, 1116, "elaboration"], [526, 569, 524, 526, "attribution"], [526, 540, 540, 569, "elaboration"], [540, 556, 556, 569, "manner"], [556, 561, 561, 569, "elaboration"], [524, 569, 569, 1116, "elaboration"], [569, 571, 571, 589, "elaboration"], [579, 589, 571, 579, "attribution"], [579, 582, 582, 589, "elaboration"], [569, 589, 589, 1116, "elaboration"], [589, 604, 604, 622, "elaboration"], [604, 616, 616, 622, "purpose"], [589, 622, 622, 1116, "elaboration"], [622, 626, 626, 633, "elaboration"], [622, 633, 633, 652, "elaboration"], [633, 638, 638, 652, "elaboration"], [622, 652, 652, 1116, "elaboration"], [652, 656, 656, 1116, "textualorganization"], [656, 1116, 652, 656, "textualorganization"], [656, 671, 671, 1116, "elaboration"], [671, 675, 675, 684, "purpose"], [671, 684, 684, 1116, "elaboration"], [684, 693, 693, 1116, "list"], [684, 686, 686, 693, "same_unit"], [686, 693, 684, 686, "same_unit"], [693, 1116, 684, 693, "list"], [693, 707, 707, 737, "same_unit"], [693, 695, 695, 707, "manner"], [707, 737, 693, 707, "same_unit"], [707, 712, 712, 737, "elaboration"], [693, 737, 737, 1116, "elaboration"], [737, 746, 746, 754, "elaboration"], [746, 749, 749, 754, "list"], [749, 754, 746, 749, "list"], [749, 750, 750, 754, "elaboration"], [737, 754, 754, 1116, "elaboration"], [754, 761, 761, 774, "elaboration"], [761, 765, 765, 774, "elaboration"], [754, 774, 774, 1116, "elaboration"], [774, 796, 796, 1116, "elaboration"], [798, 815, 796, 798, "attribution"], [796, 815, 815, 1116, "elaboration"], [817, 844, 815, 817, "attribution"], [817, 818, 818, 844, "elaboration"], [815, 844, 844, 1116, "elaboration"], [844, 875, 875, 1116, "list"], [844, 851, 851, 858, "elaboration"], [844, 858, 858, 864, "elaboration"], [844, 864, 864, 875, "circumstance"], [864, 871, 871, 875, "elaboration"], [875, 1116, 844, 875, "list"], [875, 886, 886, 1116, "elaboration"], [886, 957, 957, 1116, "list"], [886, 898, 898, 957, "elaboration"], [898, 902, 902, 903, "elaboration"], [898, 903, 903, 957, "elaboration"], [903, 907, 907, 957, "elaboration"], [907, 909, 909, 957, "elaboration"], [909, 925, 925, 957, "elaboration"], [929, 957, 925, 929, "attribution"], [929, 941, 941, 951, "same_unit"], [929, 937, 937, 941, "elaboration"], [941, 951, 929, 941, "same_unit"], [941, 946, 946, 951, "elaboration"], [929, 951, 951, 957, "means"], [951, 953, 953, 957, "elaboration"], [957, 1116, 886, 957, "list"], [957, 975, 975, 1116, "list"], [959, 975, 957, 959, "attribution"], [975, 1116, 957, 975, "list"], [975, 1002, 1002, 1116, "list"], [977, 1002, 975, 977, "attribution"], [978, 1002, 977, 978, "attribution"], [978, 987, 987, 1002, "elaboration"], [987, 999, 999, 1002, "example"], [1002, 1116, 975, 1002, "list"], [1002, 1009, 1009, 1116, "list"], [1009, 1116, 1002, 1009, "list"], [1009, 1023, 1023, 1116, "list"], [1010, 1023, 1009, 1010, "attribution"], [1010, 1017, 1017, 1023, "purpose"], [1023, 1116, 1009, 1023, "list"], [1023, 1034, 1034, 1116, "list"], [1023, 1026, 1026, 1034, "same_unit"], [1023, 1025, 1025, 1026, "same_unit"], [1025, 1026, 1023, 1025, "same_unit"], [1026, 1034, 1023, 1026, "same_unit"], [1026, 1028, 1028, 1034, "purpose"], [1034, 1116, 1023, 1034, "list"], [1036, 1076, 1034, 1036, "attribution"], [1036, 1051, 1051, 1076, "elaboration"], [1034, 1076, 1076, 1116, "elaboration"], [1076, 1098, 1098, 1116, "elaboration"], [1098, 1105, 1105, 1116, "purpose"]], "tokens": ["Summary", ":", "This", "paper", "presents", "a", "way", "to", "combine", "existing", "factorized", "second", "order", "representations", "with", "a", "codebook", "style", "hard", "assignment", ".", "The", "number", "of", "parameters", "required", "to", "produce", "this", "encoded", "representation", "is", "shown", "to", "be", "very", "low", ".", "Like", "other", "factorized", "representations", ",", "the", "number", "of", "computations", "as", "well", "as", "the", "size", "of", "any", "intermediate", "representations", "is", "low", ".", "The", "overall", "embedding", "is", "trained", "for", "retrieval", "using", "a", "triplet", "loss", ".", "Results", "are", "shown", "on", "Stanford", "online", ",", "CUB", "and", "Cars-196", "datasets", ".", "Comments", ":", "Review", "of", "relevant", "works", "seems", "adequate", ".", "The", "results", "seem", "reproducible", ".", "The", "only", "contribution", "of", "this", "paper", "is", "combining", "the", "factorized", "second", "order", "representations", "of", "-LRB-", "Kim", "et", ".", "al.", "2017", "-RRB-", "with", "a", "codebook", "style", "assignment", "-LRB-", "sec.", "3.2", "-RRB-", ".", "Seems", "marginal", ".", "The", "scheme", "described", "in", "Sec.", "3.2", "needs", "clarification", ".", "The", "assignment", "is", "applied", "to", "x", "as", "h", "-LRB-", "x", "-RRB-", "\\", "kron", "x", "in", "-LRB-", "7", "-RRB-", ".", "Then", "the", "entire", "N", "^", "2", "D", "^", "2", "dimensional", "second", "order", "descriptor", "h", "-LRB-", "x", "-RRB-", "\\", "kron", "x", "\\", "kron", "h", "-LRB-", "x", "-RRB-", "\\", "kron", "x", "is", "projected", "on", "a", "N", "^", "2", "D", "^", "2", "dim", "w_i", ".", "The", "latter", "is", "factorized", "into", "p_i", ",", "q_i", "\\", "in", "\\", "mathbb", "-LCB-", "R", "-RCB-", "^", "-LCB-", "Nd", "-RCB-", ",", "which", "are", "further", "factorized", "into", "codebook", "specific", "projections", "u", "_", "-LCB-", "i", ",", "j", "-RCB-", ",", "v", "_", "-LCB-", "i", ",", "j", "-RCB-", "\\", "in", "\\", "mathbb", "-LCB-", "R", "-RCB-", "^", "-LCB-", "d", "-RCB-", ".", "Is", "this", "different", "from", "classical", "assignment", ",", "where", "x", "is", "hard", "assigned", "to", "one", "of", "the", "N", "codewords", "as", "h", "-LRB-", "x", "-RRB-", ",", "then", "projected", "using", "\\", "mathbb", "-LCB-", "R", "-RCB-", "^", "d", "dimensional", "p_i", ",", "q_i", "specific", "to", "that", "codeword", "?", "In", "section", "4.1", "and", "Table", "2", ",", "is", "the", "HPBP", "with", "codebook", "the", "same", "as", "the", "proposed", "CHPBP", "?", "The", "wording", "in", "TICKTICK", "Then", "we", "re-implement", "...", "naively", "to", "a", "codebook", "strategy", "''", "seems", "confusing", ".", "The", "method", "denoted", "TICKTICK", "Margin", "''", "in", "Table", "4", "seems", "to", "be", "better", "than", "the", "proposed", "approach", "on", "CUB", ".", "How", "does", "it", "compare", "in", "terms", "of", "efficiency", ",", "memory/computation", "?", "Is", "it", "possible", "to", "see", "any", "classification", "results", "?", "Most", "of", "the", "relevant", "second", "order", "embeddings", "have", "been", "evaluated", "in", "that", "setting", ".", "===============", "After", "rebuttal", "===============================", "After", "reading", "all", "reviews", ",", "considering", "author", "rebuttal", "and", "AC", "inputs", ",", "I", "believe", "my", "initial", "rating", "is", "a", "bit", "generous", ".", "I", "would", "like", "to", "downgrade", "it", "to", "4", ".", "It", "has", "been", "pointed", "out", "that", "many", "recent", "works", "that", "are", "of", "a", "similar", "flavor", ",", "published", "in", "CVPR", "2018", "and", "ECCV", "2018", ",", "have", "slightly", "better", "results", "on", "the", "same", "dataset", ".", "Further", ",", "the", "only", "novelty", "of", "this", "work", "is", "the", "proposed", "factorization", "and", "not", "the", "encoding", "scheme", ".", "This", "alone", "is", "not", "sufficient", "to", "merit", "acceptance", ".", "We", "would", "like", "to", "thank", "you", "for", "the", "high-quality", "review", ".", "We", "clarify", "our", "contributions", "and", "the", "pointed", "formulation", ".", "Finally", ",", "we", "also", "report", "classification", "results", ".", "Q", "-RRB-", "The", "only", "contribution", "of", "this", "paper", "...", "Seems", "marginal", ".", "A", "-RRB-", "We", "are", "convinced", "by", "the", "novelty", "of", "this", "paper", ",", "as", "the", "few", "methods", "that", "combined", "second", "order", "representations", "and", "codebook", "strategies", "faced", "the", "very", "high", "dimensionality", "of", "the", "representation", "without", "proposing", "compact", "factorization", "schemes", "-LRB-", "as", "shown", "in", "Table", "1", "-RRB-", ".", "E.g.", "MFAFVNet", "-LRB-", "Li", "et", "al.", ",", "2017b", "-RRB-", "extend", "this", "second", "order", "pooling", "to", "codebook", "with", "factorization", "scheme", ".", "However", ",", "even", "with", "such", "factorization", ",", "their", "proposed", "method", "leads", "to", "500k", "dimension", "representations", "-LRB-", "i.e.", "2x", "Bilinear", "Pooling", "-RRB-", ",", "27M", "parameters", "and", "around", "40GOps", "to", "compute", "the", "output", "representation", ".", "JCF", "provides", "512d", "representation", "-LRB-", "1/1000", "factor", "-RRB-", ",", "4M", "parameters", "-LRB-", "1/7", "-RRB-", "and", "3GOps", "-LRB-", "1/10", "-RRB-", "with", "the", "same", "performances", "as", "well-known", "second", "order", "factorization", "scheme", ".", "To", "sum", "up", ":", "Combining", "second", "order", "representation", "with", "a", "codebook", "is", "not", "trivial", "due", "to", "computation", "concerns", ".", "We", "are", "the", "first", "to", "provide", "an", "efficient", "scheme", "for", "such", "combination", ".", "Q", "-RRB-", "Is", "this", "different", "from", "classical", "assignment", "?", "A", "-RRB-", "Without", "the", "introduction", "of", "rank", "factorization", ",", "there", "is", "no", "difference", ":", "the", "two", "projections", "u", "_", "-LCB-", "i", ",", "j", "-RCB-", "and", "v", "_", "-LCB-", "i", ",", "j", "-RCB-", "play", "a", "similar", "roles", "as", "intra-projection", "in", "VLAD", "representation", "for", "example", ".", "This", "insight", "is", "developed", "in", "section", "3.2", "between", "equations", "-LRB-", "9", "-RRB-", "and", "-LRB-", "10", "-RRB-", ".", "However", "this", "approach", "is", "not", "tractable", ",", "which", "is", "the", "reason", "we", "proposed", "our", "joint", "factorization", "and", "codebook", "method", ".", "Moreover", ",", "to", "make", "the", "method", "end-to-end", "trainable", ",", "x", "is", "soft-assigned", "to", "the", "codebook", "instead", "of", "the", "hard-assignment", "of", "VLAD", ".", "Q", "-RRB-", "The", "wording", "in", "TICKTICK", "Then", "we", "re-implement", "...", "naively", "to", "a", "codebook", "strategy", "''", "seems", "confusing", ".", "A", "-RRB-", "Thanks", "to", "point", "out", "this", "ambiguity", ",", "we", "update", "this", "sentence", "in", "the", "new", "paper", "version", "also", "following", "TICKTICK", "Reviewer3", "''", "remark", "on", "the", "terms", "used", ".", "For", "clarity", ",", "we", "implement", "Bilinear", "Pooling", "-LRB-", "BP", "-RRB-", "and", "Compact", "Bilinear", "Pooling", "-LRB-", "CBP", "-RRB-", "and", "not", "HPBP", "as", "we", "do", "not", "add", "the", "non-linearity", "nor", "the", "projection", ".", "However", ",", "we", "also", "train", "the", "projection", "matrices", "for", "CBP", ".", "Then", ",", "we", "extend", "these", "two", "methods", "naively", "to", "codebook", "strategy", ",", "that", "is", "by", "computing", ":", "-", "W", "^", "T", "-LSB-", "h", "-LRB-", "x", "-RRB-", "\\", "kron", "x", "\\", "kron", "x", "-RSB-", "where", "W", "\\", "in", "\\", "mathbb", "-LCB-", "R", "-RCB-", "^", "-LCB-", "Nd", "^", "2", "\\", "times", "D", "-RCB-", "-LRB-", "named", "C-BP", "-RRB-", "-", "CBP", "extended", "to", "codebook", "-LRB-", "named", "C-CBP", "-RRB-", ",", "using", "equation", "-LRB-", "10", "-RRB-", ".", "Q", "-RRB-", "TICKTICK", "Margin", "''", "in", "Table", "4", "performs", "better", "on", "CUB", ",", "how", "does", "it", "compare", "?", "A", "-RRB-", "The", "TICKTICK", "Margin", "''", "method", "proposed", "a", "new", "sampling", "strategy", "that", "allows", "to", "explore", "much", "more", "informative", "triplet", "than", "standard", "strategies", ",", "including", "ours", ".", "Also", ",", "they", "use", "larger", "images", ".", "Note", "that", "we", "can", "exploit", "their", "sampling", "method", "to", "improve", "our", "training", "procedure", ".", "Q", "-RRB-", "Is", "it", "possible", "to", "see", "any", "classification", "results", "?", "A", "-RRB-", "As", "mentioned", "in", "the", "general", "comment", ",", "we", "added", "results", "on", "3", "fine-grained", "visual", "classification", "-LRB-", "FGVC", "-RRB-", "datasets", ",", "CUB", "and", "CARS", "using", "the", "standard", "split", "in", "FGVC", "and", "Aircraft", "which", "are", "3", "common", "datasets", "for", "FGVC", "task", ".", "We", "compare", "our", "method", "to", "other", "factorization", "scheme", "and", "we", "report", "comparable", "results", "to", "the", "state-of-the-art", "with", "much", "more", "compact", "representation", ".", "For", "more", "details", ",", "we", "invite", "you", "to", "read", "the", "general", "comment", "and", "the", "new", "paper", "version", "."], "comment_id": "B1ehE56B0X"}, {"rels": [[0, 2, 2, 53, "elaboration"], [2, 5, 5, 53, "elaboration"], [5, 20, 20, 53, "elaboration"], [25, 53, 20, 25, "attribution"], [25, 35, 35, 53, "same_unit"], [25, 27, 27, 35, "purpose"], [35, 53, 25, 35, "same_unit"], [44, 53, 35, 44, "attribution"], [44, 49, 49, 53, "elaboration"], [0, 53, 53, 91, "elaboration"], [54, 91, 53, 54, "attribution"], [54, 56, 56, 91, "elaboration"], [68, 91, 56, 68, "attribution"], [68, 76, 76, 91, "purpose"], [76, 84, 84, 91, "purpose"], [0, 91, 91, 177, "elaboration"], [91, 92, 92, 177, "elaboration"], [100, 130, 92, 100, "attribution"], [100, 126, 126, 130, "elaboration"], [92, 130, 130, 163, "elaboration"], [130, 135, 135, 163, "elaboration"], [135, 139, 139, 163, "elaboration"], [139, 146, 146, 163, "elaboration"], [148, 163, 146, 148, "attribution"], [148, 150, 150, 163, "purpose"], [92, 163, 163, 177, "elaboration"], [163, 165, 165, 177, "elaboration"], [165, 170, 170, 177, "elaboration"]], "tokens": ["Hi", "!", "Interesting", "work", "!", "This", "question", "is", "more", "on", "the", "particular", "writing", "style", "and", "not", "on", "the", "method", ".", "About", "the", "claim", "of", "being", "TICKTICK", "able", "to", "discover", "both", "convolutional", "and", "recurrent", "networks", "''", "as", "mentioned", "in", "text", ",", "I", "do", "n't", "think", "it", "'s", "an", "accurate", "way", "to", "remark", "that", ".", "Given", "that", "here", "you", "search", "for", "a", "computation", "cell", ",", "and", "quoting", "from", "section", "2.1", "TICKTICK", "The", "learned", "cell", "could", "either", "be", "stacked", "to", "form", "a", "convolutional", "network", "or", "recursively", "connected", "to", "form", "a", "recurrent", "network", ".", "''", ".", "In", "my", "opinion", ",", "this", "does", "n't", "imply", "that", "the", "method", "discovered", "recurrence", "or", "convolutional", "architecture", ",", "but", "instead", "it", "was", "explicitly", "done", "by", "stacking", "cells", "in", "a", "recurrent", "manner", "or", "providing", "a", "convolution", "as", "candidate", "operation", ".", "I", "would", "request", "the", "authors", "to", "reconsider", "their", "way", "of", "writing", "this", "and", "maybe", "say", "something", "like", ",", "TICKTICK", "able", "to", "discover", "effective", "cells", "for", "use", "in", "convolutional", "and", "recurrent", "networks", "''", ".", "Thanks", "!", "Thanks", "for", "the", "suggestion", ".", "We", "will", "revise", "our", "writing", "accordingly", "."], "comment_id": "B1eNZMVcnX"}, {"rels": [[0, 499, 499, 508, "topic"], [0, 15, 15, 27, "same_unit"], [0, 9, 9, 15, "elaboration"], [15, 27, 0, 15, "same_unit"], [15, 23, 23, 27, "list"], [23, 27, 15, 23, "list"], [0, 27, 27, 499, "elaboration"], [27, 38, 38, 45, "elaboration"], [27, 45, 45, 63, "elaboration"], [27, 63, 63, 133, "elaboration"], [63, 64, 64, 78, "elaboration"], [63, 78, 78, 133, "elaboration"], [78, 83, 83, 88, "elaboration"], [78, 88, 88, 97, "elaboration"], [78, 97, 97, 133, "elaboration"], [97, 104, 104, 117, "elaboration"], [104, 106, 106, 117, "list"], [106, 117, 104, 106, "list"], [106, 107, 107, 117, "elaboration"], [97, 117, 117, 133, "elaboration"], [117, 121, 121, 133, "purpose"], [27, 133, 133, 499, "elaboration"], [133, 141, 141, 150, "purpose"], [133, 150, 150, 499, "elaboration"], [150, 155, 155, 162, "purpose"], [150, 162, 162, 171, "elaboration"], [150, 171, 171, 499, "elaboration"], [171, 184, 184, 499, "elaboration"], [220, 499, 184, 220, "circumstance"], [184, 189, 189, 220, "list"], [189, 220, 184, 189, "list"], [189, 191, 191, 220, "purpose"], [191, 206, 206, 220, "elaboration"], [206, 210, 210, 220, "elaboration"], [220, 230, 230, 239, "same_unit"], [220, 225, 225, 230, "elaboration"], [230, 239, 220, 230, "same_unit"], [220, 239, 239, 499, "elaboration"], [239, 252, 252, 274, "elaboration"], [252, 253, 253, 274, "elaboration"], [253, 257, 257, 274, "elaboration"], [239, 274, 274, 499, "elaboration"], [274, 281, 281, 298, "elaboration"], [281, 287, 287, 298, "elaboration"], [274, 298, 298, 499, "elaboration"], [298, 300, 300, 344, "same_unit"], [300, 344, 298, 300, "same_unit"], [300, 313, 313, 329, "elaboration"], [300, 329, 329, 344, "manner"], [298, 344, 344, 499, "example"], [344, 360, 360, 365, "elaboration"], [344, 365, 365, 499, "elaboration"], [365, 382, 382, 499, "elaboration"], [389, 410, 382, 389, "attribution"], [389, 401, 401, 410, "elaboration"], [382, 410, 410, 499, "elaboration"], [410, 442, 442, 499, "elaboration"], [442, 451, 451, 467, "elaboration"], [453, 467, 451, 453, "attribution"], [453, 460, 460, 467, "elaboration"], [442, 467, 467, 469, "elaboration"], [442, 469, 469, 487, "elaboration"], [442, 487, 487, 499, "elaboration"], [499, 508, 0, 499, "topic"], [499, 503, 503, 508, "elaboration"], [503, 504, 504, 508, "elaboration"]], "tokens": ["This", "work", "does", "not", "cite", "or", "compare", "with", "work", "that", "appeared", "almost", "6", "months", "ago", "on", "attacking", "object", "detectors", "in", "the", "physical", "world", "and", "showing", "transferability", ".", "The", "work", "of", "Eykholt", "et", "al", "show", "a", "similar", "camouflage", "attack", "in", "making", "a", "stop", "sign", "disappear", ".", "curious", "about", "the", "differences", "to", "this", "paper", ",", "and", "what", "intellectual", "contributions", "it", "provides", "over", "existing", "work", ".", "Eykholt", "et", "al.", ",", "Physical", "Adversarial", "Examples", "for", "Object", "Detectors", ",", "USENIX", "WOOT", "2018", ".", "https://www.usenix.org/conference/woot18/presentation/eykholt", "Thanks", "for", "the", "pointer", "to", "-LSB-", "1", "-RSB-", ".", "We", "will", "add", "it", "to", "our", "final", "version", ".", "We", "did", "have", "cited", "a", "similar", "paper", "-LSB-", "2", "-RSB-", "which", "also", "aims", "to", "physically", "perturb", "the", "stop-sign", "detectors", ".", "We", "will", "be", "glad", "to", "discuss", "the", "differences", "between", "our", "work", "and", "-LSB-", "1,2", "-RSB-", ".", "The", "discussion", "will", "also", "facilitate", "the", "other", "readers", "to", "understand", "the", "motivation", "of", "our", "paper", "better", ".", "Good", "physical", "camouflages", "are", "supposed", "to", "fail", "object", "detectors", "for", "any", "images", "taken", "about", "the", "camouflaged", "object", "under", "all", "conditions", ":", "object-to-camera", "distance", ",", "background", ",", "lighting", "condition", ",", "view", "angle", ",", "etc.", ".", "When", "we", "formalize", "the", "problem", "and", "try", "to", "optimize", "with", "respect", "to", "the", "camouflage", ",", "however", ",", "the", "TICKTICK", "imaging", "function", "''", "which", "transforms", "the", "camouflage", "to", "camouflaged", "object", "and", "eventually", "various", "images", "is", "unknown", ".", "Hence", ",", "the", "key", "challenge", "to", "learning", "the", "physical", "camouflage", "is", "how", "to", "tackle", "this", "unknown", "imaging", "function", ".", "Both", "-LSB-", "1", "-RSB-", "and", "-LSB-", "2", "-RSB-", "perturb", "the", "detectors", "of", "stop", "signs", "which", "are", "planar", "objects", "whose", "images", ",", "under", "changes", "in", "camera", "geometry", ",", "are", "related", "by", "linear", "2D", "projective", "transformations", ".", "This", "is", "in", "contrast", "to", "non-planar", "objects", "-LRB-", "e.g.", ",", "a", "car", "-RRB-", "whose", "images", "are", "related", "by", "more", "complex", "range-dependent", "nonlinear", "transformations", ".", "Hence", ",", "-LSB-", "1,2", "-RSB-", "are", "able", "to", "simplify", "such", "imaging", "function", "to", "projective", "transformations", "-LRB-", "cf.", "Section", "4.2.2", "in", "-LSB-", "1", "-RSB-", "and", "Section", "4.1", "in", "-LSB-", "2", "-RSB-", "-RRB-", "without", "breaking", "the", "gradient", "chain", "between", "the", "perturbation", "and", "the", "detector", "'", "output", "score", ".", "Complex", "nonlinear", "transformations", ",", "however", ",", "require", "a", "dedicated", "3D", "simulation", ",", "for", "instance", "the", "one", "used", "in", "our", "paper", ".", "The", "3D", "simulation", "breaks", "the", "gradient", "chain", "and", "turns", "the", "problem", "into", "a", "black-box", "optimization", "problem", ".", "In", "short", ",", "the", "non-planar", "objects", "break", "-LSB-", "1,2", "-RSB-", "'s", "premise", "since", "the", "approaches", "therein", "rely", "on", "functions", "that", "are", "differentiable", "with", "respect", "to", "the", "camouflage", ".", "-LSB-", "1", "-RSB-", "Song", ",", "Dawn", ",", "Kevin", "Eykholt", ",", "Ivan", "Evtimov", ",", "Earlence", "Fernandes", ",", "Bo", "Li", ",", "Amir", "Rahmati", ",", "Florian", "Tramer", ",", "Atul", "Prakash", ",", "and", "Tadayoshi", "Kohno", ".", "TICKTICK", "Physical", "adversarial", "examples", "for", "object", "detectors", ".", "''", "In", "12th", "-LCB-", "USENIX", "-RCB-", "Workshop", "on", "Offensive", "Technologies", "-LRB-", "-LCB-", "WOOT", "-RCB-", "18", "-RRB-", ".", "2018", ".", "-LSB-", "2", "-RSB-", "Chen", ",", "Shang-Tse", ",", "Cory", "Cornelius", ",", "Jason", "Martin", ",", "and", "Duen", "Horng", "Chau", ".", "TICKTICK", "Robust", "Physical", "Adversarial", "Attack", "on", "Faster", "R-CNN", "Object", "Detector", ".", "''", "arXiv", "preprint", "arXiv", ":", "1804.05810", "-LRB-", "2018", "-RRB-", "."], "comment_id": "B1eQB3w2lV"}, {"rels": [[0, 3, 3, 14, "purpose"], [0, 14, 14, 1631, "elaboration"], [14, 22, 22, 47, "elaboration"], [22, 42, 42, 47, "same_unit"], [22, 23, 23, 31, "elaboration"], [22, 31, 31, 42, "purpose"], [31, 37, 37, 42, "elaboration"], [42, 47, 22, 42, "same_unit"], [14, 47, 47, 1631, "elaboration"], [54, 81, 47, 54, "concession"], [54, 70, 70, 81, "elaboration"], [70, 71, 71, 81, "elaboration"], [47, 81, 81, 1631, "elaboration"], [81, 86, 86, 104, "list"], [81, 84, 84, 86, "elaboration"], [86, 104, 81, 86, "list"], [86, 98, 98, 104, "same_unit"], [86, 97, 97, 98, "same_unit"], [86, 88, 88, 97, "elaboration"], [88, 89, 89, 93, "purpose"], [88, 93, 93, 97, "elaboration"], [97, 98, 86, 97, "same_unit"], [98, 104, 86, 98, "same_unit"], [81, 104, 104, 1631, "elaboration"], [104, 125, 125, 1631, "list"], [104, 119, 119, 125, "elaboration"], [125, 1631, 104, 125, "list"], [125, 127, 127, 1631, "list"], [127, 1631, 125, 127, "list"], [127, 145, 145, 1631, "elaboration"], [145, 158, 158, 1631, "list"], [145, 153, 153, 158, "elaboration"], [158, 1631, 145, 158, "list"], [158, 196, 196, 1631, "list"], [158, 160, 160, 196, "elaboration"], [160, 168, 168, 196, "elaboration"], [168, 175, 175, 196, "elaboration"], [175, 187, 187, 196, "same_unit"], [175, 176, 176, 187, "elaboration"], [187, 196, 175, 187, "same_unit"], [187, 188, 188, 195, "elaboration"], [187, 195, 195, 196, "elaboration"], [196, 1631, 158, 196, "list"], [196, 327, 327, 1631, "list"], [196, 202, 202, 218, "list"], [202, 218, 196, 202, "list"], [202, 212, 212, 218, "elaboration"], [196, 218, 218, 327, "condition"], [232, 327, 218, 232, "condition"], [226, 232, 218, 226, "condition"], [232, 244, 244, 327, "list"], [244, 327, 232, 244, "list"], [244, 249, 249, 272, "purpose"], [249, 257, 257, 272, "circumstance"], [257, 262, 262, 272, "purpose"], [244, 272, 272, 327, "elaboration"], [272, 276, 276, 292, "elaboration"], [272, 292, 292, 327, "example"], [292, 298, 298, 327, "purpose"], [298, 301, 301, 327, "elaboration"], [301, 316, 316, 327, "contrast"], [301, 312, 312, 316, "elaboration"], [316, 327, 301, 316, "contrast"], [316, 325, 325, 327, "elaboration"], [327, 1631, 196, 327, "list"], [327, 431, 431, 1631, "topic"], [327, 337, 337, 431, "elaboration"], [346, 357, 337, 346, "attribution"], [337, 357, 357, 431, "elaboration"], [357, 371, 371, 382, "list"], [371, 382, 357, 371, "list"], [357, 382, 382, 431, "elaboration"], [382, 384, 384, 431, "elaboration"], [384, 387, 387, 393, "elaboration"], [384, 393, 393, 431, "example"], [393, 407, 407, 431, "same_unit"], [393, 403, 403, 407, "elaboration"], [407, 431, 393, 407, "same_unit"], [407, 416, 416, 431, "contrast"], [416, 431, 407, 416, "contrast"], [431, 1631, 327, 431, "topic"], [431, 438, 438, 1631, "list"], [438, 1631, 431, 438, "list"], [438, 453, 453, 1631, "list"], [453, 1631, 438, 453, "list"], [453, 455, 455, 1631, "list"], [455, 1631, 453, 455, "list"], [455, 458, 458, 1631, "textualorganization"], [458, 1631, 455, 458, "textualorganization"], [458, 469, 469, 1631, "list"], [469, 1631, 458, 469, "list"], [469, 477, 477, 1631, "list"], [470, 477, 469, 470, "attribution"], [477, 1631, 469, 477, "list"], [477, 497, 497, 1631, "list"], [477, 479, 479, 497, "elaboration"], [479, 492, 492, 497, "elaboration"], [497, 1631, 477, 497, "list"], [497, 502, 502, 1631, "list"], [502, 1631, 497, 502, "list"], [502, 507, 507, 1631, "list"], [507, 1631, 502, 507, "list"], [507, 524, 524, 1631, "list"], [507, 510, 510, 524, "elaboration"], [510, 519, 519, 524, "means"], [524, 1631, 507, 524, "list"], [524, 591, 591, 1631, "topic"], [524, 530, 530, 591, "elaboration"], [530, 558, 558, 591, "same_unit"], [530, 546, 546, 558, "elaboration"], [558, 591, 530, 558, "same_unit"], [576, 591, 558, 576, "attribution"], [576, 585, 585, 591, "elaboration"], [591, 1631, 524, 591, "topic"], [591, 592, 592, 1631, "list"], [592, 1631, 591, 592, "list"], [592, 595, 595, 1631, "list"], [595, 1631, 592, 595, "list"], [595, 600, 600, 637, "elaboration"], [600, 623, 623, 636, "elaboration"], [600, 636, 636, 637, "elaboration"], [595, 637, 637, 1631, "elaboration"], [637, 648, 648, 658, "circumstance"], [637, 658, 658, 1631, "condition"], [658, 667, 667, 685, "elaboration"], [667, 677, 677, 685, "elaboration"], [658, 685, 685, 1631, "elaboration"], [685, 697, 697, 1631, "list"], [687, 697, 685, 687, "attribution"], [697, 1631, 685, 697, "list"], [697, 704, 704, 723, "elaboration"], [704, 713, 713, 723, "purpose"], [697, 723, 723, 1631, "elaboration"], [723, 725, 725, 1631, "list"], [725, 1631, 723, 725, "list"], [725, 727, 727, 733, "elaboration"], [727, 728, 728, 732, "purpose"], [727, 732, 732, 733, "restatement"], [725, 733, 733, 769, "elaboration"], [733, 747, 747, 752, "same_unit"], [733, 735, 735, 747, "elaboration"], [747, 752, 733, 747, "same_unit"], [733, 752, 752, 769, "elaboration"], [725, 769, 769, 1631, "elaboration"], [769, 791, 791, 822, "elaboration"], [797, 814, 791, 797, "attribution"], [797, 810, 810, 814, "elaboration"], [791, 814, 814, 822, "elaboration"], [814, 816, 816, 822, "elaboration"], [769, 822, 822, 1631, "elaboration"], [822, 1002, 1002, 1631, "list"], [822, 955, 955, 1002, "list"], [822, 844, 844, 866, "list"], [822, 825, 825, 844, "elaboration"], [844, 866, 822, 844, "list"], [844, 847, 847, 866, "reason"], [847, 852, 852, 866, "elaboration"], [822, 866, 866, 955, "elaboration"], [866, 868, 868, 955, "elaboration"], [868, 876, 876, 955, "elaboration"], [876, 882, 882, 891, "elaboration"], [876, 891, 891, 955, "elaboration"], [891, 896, 896, 904, "elaboration"], [896, 897, 897, 904, "elaboration"], [891, 904, 904, 955, "elaboration"], [904, 926, 926, 940, "same_unit"], [904, 909, 909, 926, "elaboration"], [909, 910, 910, 919, "elaboration"], [909, 919, 919, 926, "elaboration"], [926, 940, 904, 926, "same_unit"], [926, 930, 930, 940, "elaboration"], [904, 940, 940, 955, "elaboration"], [940, 946, 946, 955, "elaboration"], [955, 1002, 822, 955, "list"], [956, 980, 955, 956, "attribution"], [962, 980, 956, 962, "attribution"], [962, 972, 972, 973, "elaboration"], [962, 973, 973, 980, "elaboration"], [955, 980, 980, 1002, "elaboration"], [980, 988, 988, 1002, "elaboration"], [988, 992, 992, 1002, "same_unit"], [988, 989, 989, 992, "elaboration"], [992, 1002, 988, 992, "same_unit"], [1002, 1631, 822, 1002, "list"], [1002, 1135, 1135, 1631, "topic"], [1002, 1004, 1004, 1135, "elaboration"], [1004, 1007, 1007, 1041, "elaboration"], [1007, 1033, 1033, 1041, "elaboration"], [1004, 1041, 1041, 1135, "elaboration"], [1041, 1050, 1050, 1058, "same_unit"], [1041, 1044, 1044, 1050, "elaboration"], [1050, 1058, 1041, 1050, "same_unit"], [1041, 1058, 1058, 1135, "elaboration"], [1058, 1063, 1063, 1070, "elaboration"], [1058, 1070, 1070, 1135, "elaboration"], [1070, 1084, 1084, 1135, "same_unit"], [1070, 1075, 1075, 1084, "elaboration"], [1084, 1135, 1070, 1084, "same_unit"], [1084, 1092, 1092, 1135, "same_unit"], [1084, 1091, 1091, 1092, "elaboration"], [1092, 1135, 1084, 1092, "same_unit"], [1092, 1107, 1107, 1120, "elaboration"], [1111, 1120, 1107, 1111, "attribution"], [1092, 1120, 1120, 1135, "elaboration"], [1120, 1130, 1130, 1133, "elaboration"], [1120, 1133, 1133, 1135, "elaboration"], [1135, 1631, 1002, 1135, "topic"], [1135, 1161, 1161, 1631, "topic"], [1135, 1138, 1138, 1161, "elaboration"], [1141, 1161, 1138, 1141, "attribution"], [1141, 1145, 1145, 1161, "purpose"], [1145, 1156, 1156, 1161, "elaboration"], [1161, 1631, 1135, 1161, "topic"], [1161, 1163, 1163, 1631, "elaboration"], [1163, 1171, 1171, 1631, "textualorganization"], [1171, 1631, 1163, 1171, "textualorganization"], [1171, 1185, 1185, 1631, "list"], [1185, 1631, 1171, 1185, "list"], [1185, 1213, 1213, 1631, "topic"], [1185, 1201, 1201, 1213, "same_unit"], [1185, 1189, 1189, 1201, "elaboration"], [1189, 1196, 1196, 1201, "elaboration"], [1196, 1200, 1200, 1201, "elaboration"], [1201, 1213, 1185, 1201, "same_unit"], [1202, 1213, 1201, 1202, "attribution"], [1213, 1631, 1185, 1213, "topic"], [1213, 1239, 1239, 1631, "topic"], [1213, 1223, 1223, 1225, "elaboration"], [1213, 1225, 1225, 1239, "elaboration"], [1227, 1239, 1225, 1227, "attribution"], [1229, 1239, 1227, 1229, "attribution"], [1229, 1230, 1230, 1239, "elaboration"], [1239, 1631, 1213, 1239, "topic"], [1239, 1249, 1249, 1266, "list"], [1249, 1266, 1239, 1249, "list"], [1239, 1266, 1266, 1631, "elaboration"], [1266, 1334, 1334, 1631, "list"], [1266, 1277, 1277, 1334, "elaboration"], [1300, 1311, 1277, 1300, "attribution"], [1277, 1283, 1283, 1300, "elaboration"], [1277, 1311, 1311, 1334, "elaboration"], [1311, 1314, 1314, 1334, "elaboration"], [1327, 1334, 1314, 1327, "attribution"], [1327, 1332, 1332, 1334, "elaboration"], [1334, 1631, 1266, 1334, "list"], [1334, 1338, 1338, 1369, "elaboration"], [1338, 1341, 1341, 1369, "purpose"], [1341, 1363, 1363, 1369, "elaboration"], [1334, 1369, 1369, 1432, "elaboration"], [1369, 1390, 1390, 1432, "list"], [1369, 1375, 1375, 1390, "elaboration"], [1390, 1432, 1369, 1390, "list"], [1399, 1408, 1390, 1399, "attribution"], [1399, 1404, 1404, 1408, "elaboration"], [1390, 1408, 1408, 1432, "means"], [1408, 1418, 1418, 1432, "elaboration"], [1418, 1423, 1423, 1432, "elaboration"], [1334, 1432, 1432, 1596, "elaboration"], [1432, 1439, 1439, 1596, "question"], [1439, 1596, 1432, 1439, "question"], [1439, 1460, 1460, 1596, "contrast"], [1439, 1442, 1442, 1460, "purpose"], [1442, 1444, 1444, 1460, "purpose"], [1444, 1451, 1451, 1460, "elaboration"], [1460, 1596, 1439, 1460, "contrast"], [1460, 1464, 1464, 1474, "purpose"], [1460, 1474, 1474, 1596, "elaboration"], [1474, 1487, 1487, 1501, "elaboration"], [1474, 1501, 1501, 1518, "circumstance"], [1501, 1517, 1517, 1518, "same_unit"], [1501, 1509, 1509, 1517, "elaboration"], [1517, 1518, 1501, 1517, "same_unit"], [1474, 1518, 1518, 1596, "elaboration"], [1518, 1525, 1525, 1546, "concession"], [1525, 1531, 1531, 1546, "circumstance"], [1531, 1538, 1538, 1546, "elaboration"], [1538, 1543, 1543, 1546, "elaboration"], [1518, 1546, 1546, 1596, "elaboration"], [1546, 1549, 1549, 1565, "elaboration"], [1549, 1559, 1559, 1565, "elaboration"], [1546, 1565, 1565, 1596, "elaboration"], [1587, 1596, 1565, 1587, "attribution"], [1334, 1596, 1596, 1631, "elaboration"], [1596, 1622, 1622, 1631, "list"], [1596, 1600, 1600, 1605, "elaboration"], [1600, 1601, 1601, 1605, "elaboration"], [1596, 1605, 1605, 1622, "elaboration"], [1615, 1622, 1605, 1615, "attribution"], [1622, 1631, 1596, 1622, "list"], [1622, 1626, 1626, 1631, "elaboration"], [1626, 1627, 1627, 1631, "elaboration"]], "tokens": ["The", "paper", "proposes", "to", "use", "successor", "features", "for", "the", "purpose", "of", "option", "discovery", ".", "The", "idea", "is", "to", "start", "by", "constructing", "successor", "features", "based", "on", "a", "random", "policy", ",", "cluster", "them", "to", "discover", "subgoals", ",", "learn", "options", "that", "reach", "these", "subgoals", ",", "then", "iterate", "this", "process", ".", "This", "could", "be", "an", "interesting", "proposal", ",", "but", "there", "are", "several", "conceptual", "problems", "with", "the", "paper", ",", "and", "then", "many", "more", "minor", "issues", ",", "which", "put", "it", "below", "the", "threshold", "at", "the", "moment", ".", "Bigger", "comments", ":", "1", ".", "The", "reward", "used", "to", "train", "the", "options", "-LRB-", "eq", "5", "-RRB-", "could", "be", "either", "positive", "or", "negative", ".", "Hence", ",", "it", "is", "not", "clear", "how", "or", "why", "this", "is", "related", "to", "getting", "options", "that", "go", "to", "a", "goal", ".", "2", ".", "Computing", "SRs", "only", "for", "a", "random", "policy", "seems", "like", "it", "will", "waste", "potentially", "a", "lot", "of", "data", ".", "Why", "not", "do", "off-policy", "learning", "of", "the", "SR", "while", "performing", "the", "option", "?", "3", ".", "The", "candidate", "states", "formula", "seems", "very", "heuristic", ".", "It", "does", "not", "favour", "reaching", "many", "places", "necessarily", "-LRB-", "eg", "going", "to", "one", "next", "state", "would", "give", "a", "1", "/", "-LRB-", "1-gamma", "-RRB-", "SR", "value", "-RRB-", "4", ".", "Fig", "5", "is", "very", "confusing", ".", "There", "are", "large", "regions", "of", "all", "subgoals", "and", "then", "subgoals", "that", "are", "very", "spread", "out", ".", "If", "so", "many", "subgoals", "are", "close", "by", ",", "why", "would", "an", "agent", "explore", "?", "It", "could", "just", "jump", "randomly", "in", "that", "region", "for", "a", "while", ".", "It", "would", "have", "been", "useful", "to", "plot", "the", "trajectory", "distribution", "of", "the", "agent", "when", "using", "the", "learned", "options", "to", "see", "what", "exactly", "the", "agent", "is", "doing", "5", ".", "There", "are", "some", "hacks", "that", "detract", "from", "the", "clarity", "of", "the", "results", "and", "the", "merits", "of", "the", "proposed", "method", ".", "For", "example", ",", "options", "are", "supposed", "to", "be", "good", "for", "exploration", ",", "so", "sampling", "them", "less", "would", "defeat", "the", "purpose", "of", "constructing", "them", ",", "but", "that", "is", "exactly", "what", "the", "authors", "end", "up", "doing", ".", "This", "is", "very", "strange", "and", "seems", "like", "a", "hack", ".", "Similarly", ",", "the", "use", "of", "auxiliary", "tasks", "makes", "it", "unclear", "what", "is", "the", "relative", "merit", "of", "the", "proposed", "method", ".", "It", "would", "have", "been", "very", "useful", "to", "avoid", "using", "all", "these", "bells", "and", "whistles", "and", "stick", "as", "closely", "as", "possible", "to", "the", "stated", "idea", ".", "6", ".", "The", "experiments", "need", "to", "be", "described", "much", "better", ".", "For", "example", ",", "in", "the", "grid", "worlds", "are", "action", "effects", "deterministic", "or", "stochastic", "?", "Are", "start", "state", "and", "goal", "state", "drawn", "at", "random", "but", "maintained", "fixed", "across", "the", "learning", ",", "or", "each", "run", "has", "a", "different", "pair", "?", "Are", "parameters", "optimized", "for", "each", "algorithm", "?", "In", "the", "plots", "for", "the", "DM", "Lab", "experiments", ",", "what", "are", "we", "looking", "at", "?", "Policies", "?", "End", "states", "?", "How", "do", "options", "compare", "to", "Q-learning", "only", "in", "this", "case", "?", "Do", "you", "still", "do", "the", "non-unit", "exploration", "?", "The", "network", "used", "seems", "gigantic", ",", "was", "this", "optimized", "or", "was", "this", "the", "first", "choice", "that", "came", "to", "mind", "?", "Would", "this", "not", "overfit", "?", "What", "is", "the", "nonlinearity", "?", "Small", "comments", ":", "-", "This", "synergy", "enables", "the", "rapid", "learning", "Successor", "representations", "by", "improving", "sample", "efficiency", ".", "-", "Argmax", "a", "'", "before", "eq", "1", "-", "Inconsistent", "notation", "for", "the", "transition", "probability", "p", "-", "Eq", "3", "and", "4", "are", "incorrect", "-LRB-", "you", "seem", "to", "be", "one-off", "in", "the", "feature", "vectors", "used", "-RRB-", "-", "Figure", "2", "is", "unclear", ",", "it", "requires", "more", "explanation", "-", "Eq", "6", "does", "not", "correspond", "to", "eq", "5", "-", "In", "Fig", "6", "are", "the", "4", "panes", "corresponding", "top", "the", "4", "envs", ".", "?", "Please", "explain", ".", "Also", "this", "figure", "needs", "error", "bars", "-", "It", "would", "be", "useful", "to", "plot", "not", "just", "AUC", ",", "but", "actual", "learning", "curves", ",", "in", "order", "to", "see", "their", "shape", "-LRB-", "eg", "rising", "faster", "and", "asymptoting", "lower", "may", "give", "a", "better", "AUC", "-RRB-", ".", "-", "Does", "primitive", "Q-learning", "get", "the", "same", "number", "of", "time", "steps", "as", "*", "all", "*", "stages", "of", "the", "proposed", "algorithm", "?", "If", "not", ",", "it", "is", "not", "a", "fair", "comparison", "-", "It", "would", "be", "nice", "to", "also", "have", "quantitative", "results", "corresponding", "to", "the", "experiments", "in", "Fig", "7", ".", "Thank", "you", "for", "going", "through", "our", "work", "and", "providing", "valuable", "feedback", ".", "We", "hopefully", "address", "the", "concerns", "and", "questions", "raised", "in", "this", "response", "and", "we", "would", "be", "happy", "to", "expand", "on", "any", "point", "unclear", "in", "this", "response", ".", "1", ".", "The", "reward", "used", "to", "train", "the", "options", ":", "One", "way", "to", "understand", "the", "proposed", "reward", "function", "is", "to", "look", "at", "Figure", "22", "-LRB-", "Appendix", "O", "-RRB-", ".", "This", "reward", "function", "corresponds", "to", "one", "single", "option", "and", "dictates", "the", "intra-option", "policy", "for", "the", "same", ".", "The", "difference", "between", "the", "values", "printed", "on", "the", "individual", "states", "corresponds", "to", "the", "reward", "for", "a", "transition", "between", "the", "two", "states", ".", "Hence", "the", "designed", "reward", "function", "ensures", "that", "we", "reach", "a", "state", "with", "the", "largest", "value", "of", "$", "\\", "phi", "-LRB-", "s", "-RRB-", ".", "|", "Psi", "-LRB-", "Sub-goal", "-RRB-", "$", "2", ".", "Off-policy", "SR", ":", "Learning", "the", "SR", "in", "an", "off-policy", "manner", "is", "extremely", "hard", "and", "we", "are", "unaware", "of", "any", "such", "formulations", ".", "This", "is", "primarily", "because", "it", "is", "very", "difficult", "to", "relate", "the", "discounted", "visitation", "counts", "of", "one", "policy", "to", "that", "of", "another", ".", "3", ".", "The", "candidate", "states", "formula", "seems", "very", "heuristic", ".", "We", "have", "a", "very", "good", "reason", "for", "the", "choice", "of", "the", "candidate", "states", "formula", ".", "The", "candidate", "states", "are", "those", "states", "which", "have", "a", "moderately", "developed", "SR.", ".", "The", "formula", "uses", "the", "L1", "norm", "which", "encodes", "the", "visitation", "count", "of", "a", "particular", "state", "-LRB-", "See", "-LSB-", "1", "-RSB-", "-RRB-", ",", "hence", "encoding", "the", "degree", "to", "which", "the", "SR", "of", "a", "state", "is", "developed", ".", "The", "clustering", "from", "the", "SR-options", "ensures", "that", "the", "chosen", "sub-goals", "are", "sufficiently", "spread", "apart", ".", "Can", "you", "kindly", "clarify", "the", "comment", ":", "TICKTICK", "going", "to", "one", "next", "state", "would", "give", "a", "1", "/", "-LRB-", "1-gamma", "-RRB-", "SR", "value", "''", ".", "The", "maximum", "magnitude", "of", "the", "SR", "is", "1", "/", "-LRB-", "1-gamma", "-RRB-", "so", "the", "statement", "is", "n't", "too", "clear", "to", "us", ".", "4", ".", "Fig", "5", ":", "As", "stated", "in", "the", "image", "caption", ",", "the", "images", "on", "the", "left", "are", "for", "the", "Successor", "Options", "and", "the", "images", "on", "the", "right", "are", "for", "Eigen-options", "-LRB-", "the", "method", "we", "compare", "to", "-RRB-", ".", "The", "coloured", "states", "-LRB-", "yellow", "to", "light", "blue", "-RRB-", "are", "the", "termination", "states", "of", "all", "options", ".", "This", "clearly", "emphasizes", "the", "point", "that", "the", "Eigen-options", "have", "nearby", "sub-goals", ".", "With", "regards", "to", "the", "statement", "-LRB-", "If", "so", "many", "subgoals", "are", "close", "by", ",", "why", "would", "an", "agent", "explore", "?", "-RRB-", ",", "this", "is", "precisely", "the", "problem", "with", "the", "Eigen-options", "framework", ",", "and", "this", "is", "the", "basis", "on", "which", "we", "claim", "that", "Successor", "options", "will", "exhibit", "better", "empirical", "performance", ".", "With", "regards", "to", "the", "trajectory", "distribution", ",", "Appendix", "J", "addresses", "the", "same", ".", "5", ".", "Experimental", "Evaluation", ":", "The", "reviewer", "claims", "that", "we", "use", "tricks", "to", "detract", "from", "the", "clarity", "of", "the", "paper", ",", "an", "assessment", "we", "politely", "disagree", "with", ".", "5a", ".", "TICKTICK", "Auxiliary", "tasks", "make", "relative", "merit", "unclear", ":", "Can", "the", "reviewer", "kindly", "clarify", "which", "auxiliary", "tasks", "are", "being", "referred", "to", "here", "?", "The", "only", "auxiliary", "loss", "we", "use", "is", "the", "image", "reconstruction", "loss", "-LRB-", "auto-encoder", "loss", "-RRB-", "which", "ensures", "that", "the", "Successor", "Features", "do", "not", "learn", "the", "null", "vector", ".", "This", "is", "a", "very", "commonly", "used", "loss", "in", "Successor", "Representation", "based", "papers", "-LRB-", "See", "-LSB-", "2", "-RSB-", "which", "justify", "the", "usage", "of", "the", "same", "-RRB-", ".", "This", "loss", "is", "very", "much", "part", "of", "our", "described", "framework", "and", "does", "not", "in", "an", "any", "form", ",", "hide", "the", "merit", "of", "the", "reported", "results", "5b", ".", "Sampling", "options", "less", "would", "defeat", "the", "purpose", "of", "constructing", "them", ":", "We", "have", "demonstrated", "evaluations", "for", "Q-learning", "-LRB-", "only", "actions", "-RRB-", ",", "and", "SR-options", "with", "uniform", "and", "non-uniform", "exploration", "and", "hence", "we", "do", "not", "TICKTICK", "detract", "the", "clarity", "of", "the", "results", "''", "using", "hacks", ".", "We", "have", "attempted", "to", "be", "as", "transparent", "as", "possible", "in", "the", "reported", "results", "and", "we", "believe", "we", "stick", "to", "the", "method", "described", ".", "There", "are", "two", "points", "we", "would", "like", "to", "make", "1", "-RRB-", "The", "primary", "focus", "of", "this", "work", "is", "on", "Option-discovery", "and", "hence", "we", "do", "not", "delve", "deeply", "into", "areas", "related", "to", "learning", "with", "options", ".", "There", "are", "a", "plethora", "of", "possibilities", "worth", "exploring", "and", "this", "does", "not", "detract", "from", "the", "utility", "of", "the", "options", "themselves", ".", "2", "-RRB-", "Sampling", "the", "option", "less", "does", "not", "mean", "that", "there", "is", "no", "utility", "in", "constructing", "them", ".", "By", "that", "logic", ",", "one", "should", "expect", "a", "naive", "Q-learner", "to", "have", "the", "best", "performance", "-LRB-", "which", "is", "clearly", "not", "the", "case", "-RRB-", ".", "So", "why", "is", "this", "scheme", "useful", "?", "Options", "are", "used", "to", "navigate", "to", "key", "parts", "of", "the", "state", "space", "-LRB-", "that", "primitive", "actions", "are", "unable", "to", "-RRB-", ",", "while", "actions", "are", "used", "to", "explore", "the", "newly", "discovered", "region", "in", "state", "space", ".", "This", "is", "analogous", "to", "using", "an", "airplane", "to", "travel", "to", "a", "new", "city", "-LRB-", "using", "an", "option", "to", "land", "in", "new", "parts", "of", "state", "space", "-RRB-", ",", "following", "which", "one", "explores", "the", "city", "on", "foot", "-LRB-", "each", "step", "is", "a", "primitive", "action", "-RRB-", ".", "Hence", "the", "options", "are", "still", "essential", ",", "even", "if", "they", "are", "sampled", "infrequently", "since", "they", "perform", "a", "sequence", "of", "transition", "that", "has", "a", "negligible", "probability", "of", "happening", ".", "Sampling", "the", "options", "frequently", "would", "translate", "to", "jumping", "between", "regions", "in", "state", "space", "without", "exploring", "any", "one", "region", ".", "See", "Appendix", "J", "for", "more", "details", "-LSB-", "1", "-RSB-", "Machado", ",", "Marlos", "C.", ",", "Marc", "G.", "Bellemare", ",", "and", "Michael", "Bowling", ".", "TICKTICK", "Count-based", "exploration", "with", "the", "successor", "representation", ".", "''", "arXiv", "preprint", "arXiv", ":", "1807.11622", "-LRB-", "2018", "-RRB-", ".", "-LSB-", "2", "-RSB-", "Kulkarni", ",", "Tejas", "D.", ",", "et", "al.", "TICKTICK", "Deep", "successor", "reinforcement", "learning", ".", "''", "arXiv", "preprint", "arXiv", ":", "1606.02396", "-LRB-", "2016", "-RRB-", "."], "comment_id": "B1et7uIGyV"}, {"rels": [[0, 8, 8, 22, "elaboration"], [8, 17, 17, 22, "elaboration"], [0, 22, 22, 191, "elaboration"], [22, 30, 30, 41, "elaboration"], [32, 41, 30, 32, "attribution"], [22, 41, 41, 191, "elaboration"], [41, 48, 48, 68, "same_unit"], [41, 47, 47, 48, "elaboration"], [48, 68, 41, 48, "same_unit"], [48, 67, 67, 68, "same_unit"], [48, 61, 61, 67, "elaboration"], [67, 68, 48, 67, "same_unit"], [41, 68, 68, 191, "elaboration"], [68, 74, 74, 86, "purpose"], [68, 86, 86, 191, "elaboration"], [86, 112, 112, 191, "elaboration"], [112, 123, 123, 191, "elaboration"], [123, 132, 132, 148, "elaboration"], [132, 136, 136, 148, "elaboration"], [136, 137, 137, 148, "elaboration"], [123, 148, 148, 191, "elaboration"], [148, 151, 151, 177, "purpose"], [151, 155, 155, 177, "elaboration"], [155, 172, 172, 177, "elaboration"], [148, 177, 177, 191, "elaboration"], [177, 179, 179, 191, "list"], [179, 191, 177, 179, "list"], [184, 191, 179, 184, "attribution"]], "tokens": ["The", "paper", "proposes", "a", "simple", "but", "effective", "method", "for", "controlling", "the", "location", "of", "objects", "in", "image", "generation", "using", "generative", "adversarial", "networks", ".", "Experiments", "on", "MNIST", "and", "CLEVR", "are", "toy", "examples", "but", "illustrate", "that", "the", "model", "is", "indeed", "performing", "as", "expected", ".", "The", "experiments", "on", "COCO", "produce", "results", "that", "while", "containing", "obvious", "artefacts", "are", "producing", "output", "consistent", "with", "the", "input", "control", "signal", "-LRB-", "i.e.", ",", "bounding", "boxes", "-RRB-", ".", "It", "would", "however", "have", "been", "interesting", "to", "see", "more", "varied", "bounding", "box", "locations", "for", "the", "same", "caption", ".", "In", "short", ",", "the", "paper", "makes", "an", "interesting", "addition", "to", "image", "generation", "works", "and", "likely", "to", "be", "incorporated", "into", "future", "image", "generation", "and", "inpainting", "methods", ".", "Dear", "reviewer", ",", "thank", "you", "very", "much", "for", "your", "review", ".", "We", "will", "update", "our", "submission", "with", "examples", "of", "images", "based", "on", "MS-COCO", "captions", "in", "which", "we", "vary", "the", "location", "of", "the", "various", "bounding", "boxes", ".", "We", "will", "work", "to", "implement", "the", "feedback", "we", "got", "and", "will", "post", "an", "updated", "version", "of", "our", "submission", "by", "the", "end", "of", "next", "week", "-LRB-", "latest", "on", "16", ".", "November", "-RRB-", "and", "will", "let", "you", "know", "once", "the", "updated", "version", "is", "online", "."], "comment_id": "B1ejRvrkam"}, {"rels": [[0, 2, 2, 1382, "textualorganization"], [2, 1382, 0, 2, "textualorganization"], [2, 4, 4, 26, "elaboration"], [2, 26, 26, 1382, "elaboration"], [26, 35, 35, 46, "elaboration"], [26, 46, 46, 1382, "elaboration"], [46, 51, 51, 68, "list"], [51, 68, 46, 51, "list"], [51, 52, 52, 68, "manner"], [52, 59, 59, 68, "elaboration"], [59, 60, 60, 68, "elaboration"], [46, 68, 68, 1382, "elaboration"], [68, 77, 77, 86, "elaboration"], [68, 86, 86, 1382, "elaboration"], [86, 94, 94, 114, "same_unit"], [86, 90, 90, 94, "elaboration"], [94, 114, 86, 94, "same_unit"], [94, 98, 98, 114, "same_unit"], [98, 114, 94, 98, "same_unit"], [86, 114, 114, 1382, "elaboration"], [114, 126, 126, 134, "list"], [126, 134, 114, 126, "list"], [114, 134, 134, 1382, "elaboration"], [134, 144, 144, 158, "manner"], [144, 154, 154, 158, "same_unit"], [144, 146, 146, 154, "elaboration"], [154, 158, 144, 154, "same_unit"], [134, 158, 158, 1382, "elaboration"], [167, 175, 158, 167, "attribution"], [158, 175, 175, 1382, "elaboration"], [175, 190, 190, 1382, "question"], [175, 186, 186, 190, "comparison"], [190, 1382, 175, 190, "question"], [192, 200, 190, 192, "attribution"], [192, 197, 197, 200, "comparison"], [190, 200, 200, 1382, "elaboration"], [200, 227, 227, 1382, "list"], [227, 1382, 200, 227, "list"], [227, 242, 242, 1382, "list"], [230, 242, 227, 230, "attribution"], [242, 1382, 227, 242, "list"], [242, 254, 254, 1382, "elaboration"], [254, 269, 269, 1382, "list"], [269, 1382, 254, 269, "list"], [269, 271, 271, 281, "elaboration"], [273, 281, 271, 273, "attribution"], [269, 281, 281, 1382, "elaboration"], [281, 289, 289, 302, "elaboration"], [281, 302, 302, 1382, "elaboration"], [302, 314, 314, 1382, "elaboration"], [342, 1382, 314, 342, "antithesis"], [329, 342, 314, 329, "attribution"], [329, 334, 334, 342, "elaboration"], [348, 353, 342, 348, "attribution"], [342, 353, 353, 1382, "elaboration"], [353, 361, 361, 367, "elaboration"], [353, 367, 367, 1382, "elaboration"], [367, 391, 391, 1382, "list"], [367, 374, 374, 391, "elaboration"], [391, 1382, 367, 391, "list"], [391, 466, 466, 1382, "list"], [391, 394, 394, 466, "textualorganization"], [394, 466, 391, 394, "textualorganization"], [396, 410, 394, 396, "attribution"], [396, 402, 402, 410, "manner"], [402, 404, 404, 410, "purpose"], [394, 410, 410, 466, "elaboration"], [410, 419, 419, 423, "purpose"], [410, 423, 423, 466, "elaboration"], [425, 445, 423, 425, "attribution"], [425, 436, 436, 445, "purpose"], [423, 445, 445, 466, "elaboration"], [466, 1382, 391, 466, "list"], [466, 469, 469, 1382, "textualorganization"], [469, 1382, 466, 469, "textualorganization"], [469, 485, 485, 1382, "elaboration"], [485, 489, 489, 538, "elaboration"], [489, 504, 504, 538, "same_unit"], [489, 493, 493, 504, "elaboration"], [504, 538, 489, 504, "same_unit"], [504, 518, 518, 524, "elaboration"], [504, 524, 524, 529, "elaboration"], [504, 529, 529, 538, "elaboration"], [485, 538, 538, 1382, "elaboration"], [544, 556, 538, 544, "attribution"], [538, 556, 556, 1382, "elaboration"], [556, 564, 564, 583, "purpose"], [564, 569, 569, 583, "circumstance"], [556, 583, 583, 1382, "elaboration"], [594, 602, 583, 594, "attribution"], [594, 599, 599, 602, "manner"], [583, 602, 602, 1382, "example"], [606, 640, 602, 606, "attribution"], [617, 640, 606, 617, "attribution"], [617, 623, 623, 640, "elaboration"], [602, 640, 640, 1382, "elaboration"], [640, 652, 652, 1382, "list"], [640, 646, 646, 652, "same_unit"], [640, 642, 642, 646, "elaboration"], [646, 652, 640, 646, "same_unit"], [648, 652, 646, 648, "attribution"], [652, 1382, 640, 652, "list"], [652, 725, 725, 1382, "list"], [652, 654, 654, 725, "elaboration"], [654, 662, 662, 682, "same_unit"], [654, 658, 658, 662, "elaboration"], [662, 682, 654, 662, "same_unit"], [662, 666, 666, 682, "same_unit"], [666, 682, 662, 666, "same_unit"], [654, 682, 682, 725, "elaboration"], [682, 695, 695, 696, "same_unit"], [682, 688, 688, 695, "list"], [688, 695, 682, 688, "list"], [688, 692, 692, 695, "elaboration"], [695, 696, 682, 695, "same_unit"], [682, 696, 696, 699, "elaboration"], [682, 699, 699, 725, "elaboration"], [703, 725, 699, 703, "attribution"], [703, 711, 711, 725, "circumstance"], [711, 712, 712, 725, "elaboration"], [712, 716, 716, 725, "same_unit"], [712, 713, 713, 716, "elaboration"], [716, 725, 712, 716, "same_unit"], [725, 1382, 652, 725, "list"], [725, 727, 727, 1382, "list"], [727, 1382, 725, 727, "list"], [727, 747, 747, 1382, "list"], [747, 1382, 727, 747, "list"], [747, 757, 757, 1382, "list"], [757, 1382, 747, 757, "list"], [757, 760, 760, 790, "elaboration"], [760, 771, 771, 790, "elaboration"], [757, 790, 790, 802, "elaboration"], [793, 802, 790, 793, "attribution"], [793, 798, 798, 802, "same_unit"], [793, 794, 794, 798, "same_unit"], [794, 798, 793, 794, "same_unit"], [798, 802, 793, 798, "same_unit"], [757, 802, 802, 1382, "temporal"], [802, 813, 813, 1382, "textualorganization"], [802, 807, 807, 813, "same_unit"], [802, 803, 803, 807, "elaboration"], [807, 813, 802, 807, "same_unit"], [813, 1382, 802, 813, "textualorganization"], [820, 839, 813, 820, "attribution"], [813, 839, 839, 1382, "elaboration"], [839, 855, 855, 1382, "topic"], [841, 855, 839, 841, "attribution"], [845, 855, 841, 845, "attribution"], [855, 1382, 839, 855, "topic"], [855, 874, 874, 1382, "list"], [874, 1382, 855, 874, "list"], [874, 876, 876, 887, "elaboration"], [874, 887, 887, 1382, "elaboration"], [887, 891, 891, 902, "elaboration"], [887, 902, 902, 1382, "elaboration"], [902, 912, 912, 916, "elaboration"], [902, 916, 916, 1382, "elaboration"], [916, 931, 931, 937, "same_unit"], [916, 927, 927, 931, "elaboration"], [931, 937, 916, 931, "same_unit"], [931, 934, 934, 937, "manner"], [916, 937, 937, 1382, "elaboration"], [949, 957, 937, 949, "attribution"], [937, 946, 946, 949, "same_unit"], [937, 943, 943, 946, "elaboration"], [946, 949, 937, 946, "same_unit"], [937, 957, 957, 1382, "elaboration"], [957, 970, 970, 1103, "elaboration"], [970, 980, 980, 994, "purpose"], [970, 994, 994, 1103, "elaboration"], [994, 1001, 1001, 1044, "elaboration"], [1001, 1006, 1006, 1044, "same_unit"], [1001, 1005, 1005, 1006, "list"], [1005, 1006, 1001, 1005, "list"], [1006, 1044, 1001, 1006, "same_unit"], [1006, 1010, 1010, 1044, "elaboration"], [1010, 1029, 1029, 1044, "elaboration"], [1029, 1032, 1032, 1044, "reason"], [994, 1044, 1044, 1103, "elaboration"], [1048, 1069, 1044, 1048, "attribution"], [1048, 1054, 1054, 1069, "circumstance"], [1054, 1057, 1057, 1069, "purpose"], [1044, 1069, 1069, 1103, "example"], [1069, 1083, 1083, 1088, "same_unit"], [1069, 1076, 1076, 1083, "elaboration"], [1083, 1088, 1069, 1083, "same_unit"], [1069, 1088, 1088, 1103, "elaboration"], [1088, 1092, 1092, 1103, "elaboration"], [1092, 1099, 1099, 1103, "attribution"], [957, 1103, 1103, 1382, "elaboration"], [1103, 1111, 1111, 1382, "elaboration"], [1111, 1125, 1125, 1382, "elaboration"], [1125, 1129, 1129, 1142, "means"], [1125, 1142, 1142, 1382, "elaboration"], [1142, 1150, 1150, 1159, "elaboration"], [1150, 1154, 1154, 1159, "same_unit"], [1150, 1151, 1151, 1154, "elaboration"], [1154, 1159, 1150, 1154, "same_unit"], [1154, 1155, 1155, 1159, "elaboration"], [1142, 1159, 1159, 1382, "elaboration"], [1159, 1179, 1179, 1382, "elaboration"], [1179, 1198, 1198, 1382, "list"], [1198, 1382, 1179, 1198, "list"], [1202, 1236, 1198, 1202, "attribution"], [1202, 1218, 1218, 1236, "same_unit"], [1202, 1217, 1217, 1218, "purpose"], [1218, 1236, 1202, 1218, "same_unit"], [1218, 1228, 1228, 1236, "elaboration"], [1198, 1236, 1236, 1382, "elaboration"], [1236, 1242, 1242, 1265, "condition"], [1242, 1253, 1253, 1265, "elaboration"], [1236, 1265, 1265, 1382, "elaboration"], [1265, 1282, 1282, 1382, "list"], [1265, 1267, 1267, 1282, "elaboration"], [1267, 1271, 1271, 1282, "elaboration"], [1282, 1382, 1265, 1282, "list"], [1282, 1286, 1286, 1295, "elaboration"], [1282, 1295, 1295, 1382, "elaboration"], [1295, 1305, 1305, 1382, "list"], [1305, 1382, 1295, 1305, "list"], [1305, 1322, 1322, 1382, "list"], [1308, 1322, 1305, 1308, "attribution"], [1308, 1309, 1309, 1322, "elaboration"], [1316, 1322, 1309, 1316, "attribution"], [1321, 1322, 1316, 1321, "attribution"], [1322, 1382, 1305, 1322, "list"], [1322, 1340, 1340, 1382, "list"], [1324, 1340, 1322, 1324, "attribution"], [1324, 1333, 1333, 1340, "elaboration"], [1333, 1334, 1334, 1340, "attribution"], [1340, 1382, 1322, 1340, "list"], [1340, 1345, 1345, 1363, "purpose"], [1345, 1350, 1350, 1363, "elaboration"], [1350, 1354, 1354, 1363, "elaboration"], [1354, 1358, 1358, 1363, "elaboration"], [1340, 1363, 1363, 1382, "elaboration"], [1367, 1382, 1363, 1367, "attribution"], [1367, 1370, 1370, 1382, "list"], [1370, 1382, 1367, 1370, "list"]], "tokens": ["Comments", ":", "The", "author", "-LRB-", "s", "-RRB-", "provide", "stability", "and", "generalization", "bounds", "for", "SGD", "with", "momentum", "for", "strongly", "convex", ",", "smooth", ",", "and", "Lipschitz", "losses", ".", "This", "paper", "basically", "follows", "and", "extends", "the", "results", "from", "-LRB-", "Hardt", ",", "Recht", ",", "and", "Singer", ",", "2016", "-RRB-", ".", "Section", "2", "is", "quite", "identical", "but", "without", "mentioning", "the", "overlap", "from", "Section", "2", "in", "-LRB-", "Hardt", "et", "al", ",", "2016", "-RRB-", ".", "The", "analysis", "closely", "follows", "the", "approach", "from", "there", ".", "The", "proof", "of", "Theorem", "2", "has", "some", "issues", ".", "The", "set", "of", "assumptions", "-LRB-", "smooth", ",", "Lipschitz", "and", "strongly", "convex", "-RRB-", "is", "not", "valid", "on", "the", "whole", "set", "R", "^", "d", ",", "for", "example", "quadratic", "function", ".", "In", "this", "case", ",", "your", "Lipschitz", "constant", "L", "would", "be", "arbitrarily", "large", "and", "could", "be", "damaged", "your", "theoretical", "result", ".", "To", "consider", "projected", "step", "is", "true", ",", "but", "the", "proof", "without", "projection", "-LRB-", "and", "then", "explaining", "in", "the", "end", "-RRB-", "should", "have", "troubles", ".", "From", "the", "theoretical", "results", ",", "it", "is", "not", "clear", "that", "momentum", "parameter", "affects", "positively", "or", "negatively", ".", "In", "Theorem", "3", ",", "what", "is", "the", "advantage", "of", "this", "convergence", "compared", "to", "SGD", "?", "It", "seems", "that", "it", "is", "not", "better", "than", "SGD", ".", "Moreover", ",", "if", "\\", "mu", "=", "0", "and", "\\", "gamma", ">", "0", ",", "it", "seems", "not", "able", "to", "recover", "the", "linear", "convergence", "to", "neighborhood", "of", "SGD", ".", "Please", "also", "notice", "that", ",", "in", "this", "situation", ",", "L", "also", "could", "be", "large", ".", "The", "topic", "could", "be", "interesting", "but", "the", "contributions", "are", "very", "incremental", ".", "At", "the", "current", "state", ",", "I", "do", "not", "support", "the", "publications", "of", "this", "paper", ".", "R2C1", ":", "We", "believe", "that", "our", "results", "are", "substantial", "and", "important", ".", "Our", "analysis", "involves", "some", "subtle", "but", "important", "steps", "in", "dealing", "with", "the", "momentum", "term", "in", "the", "recursion", "in", "Section", "4", ".", "This", "method", "was", "not", "conceived", "in", "prior", "attempts", "on", "this", "problem", ".", "We", "reproduce", "the", "following", "statement", "from", "-LSB-", "Hardt", "et", "al.", ",", "Section", "7", "-RSB-", ":", "TICKTICK", "One", "very", "important", "technique", "that", "we", "did", "not", "discuss", "is", "momentum", ".", "However", ",", "it", "is", "not", "clear", "that", "momentum", "adds", "stability", ".", "It", "is", "possible", "that", "momentum", "speeds", "up", "training", "but", "adversely", "impacts", "generalization", ".", "''", "Our", "work", "is", "the", "first", "successful", "attempt", "that", "establishes", "that", "SGMM", "generalizes", ",", "for", "the", "practically", "important", "class", "of", "strongly", "convex", "loss", "functions", ".", "------------------------------------------------------------------------------------------------------------------------------------------------------------------------", "R2C2", ":", "Please", "note", "that", "we", "first", "discuss", "the", "proofs", "without", "projection", "to", "keep", "the", "notation", "uncluttered", ".", "We", "then", "explain", "how", "the", "proofs", "can", "be", "modified", "to", "accommodate", "projection", ".", "We", "believe", "this", "approach", "is", "technically", "sound", ",", "and", "it", "helps", "the", "readers", "to", "better", "understand", "the", "insights", "in", "our", "proofs", ".", "We", "respectfully", "request", "that", "the", "reviewer", "point", "out", "any", "specific", "issue", "in", "our", "proofs", "such", "that", "we", "can", "fix", "it", ".", "------------------------------------------------------------------------------------------------------------------------------------------------------------------------", "R2C3", ":", "To", "the", "best", "of", "our", "understanding", ",", "linear", "convergence", "happens", "under", "a", "very", "stringent", "condition", ":", "$", "\\", "Pr", "\\", "-LCB-", "\\", "nabla", "f_i", "-LRB-", "x", "^", "*", "-RRB-", "=", "0", "\\", "-RCB-", "=", "1", "$", ",", "\\", "ie", "$", "x", "^", "*", "$", "is", "a", "simultaneous", "minimizer", "of", "-LRB-", "almost", "-RRB-", "all", "$", "f_i", "-LRB-", "x", "^", "*", "-RRB-", "$", "-LSB-", "Needell", "et", "al.", ",", "2014", "-RSB-", ".", "Such", "a", "condition", "would", "artificially", "force", "that", "the", "loss", "function", "be", "simultaneously", "minimized", "on", "each", "training", "example", ".", "In", "absence", "of", "this", "condition", ",", "SGD", "appears", "to", "exhibit", "similar", "convergence", "rate", "as", "our", "paper", ",", "albeit", "under", "somewhat", "different", "assumptions", "on", "the", "loss", "function", ".", "Moreover", ",", "in", "terms", "of", "convergence", ",", "we", "can", "not", "claim", "that", "SGMM", "always", "outperforms", "SGM", "without", "momentum", ".", "For", "example", ",", "in", "-LSB-", "Kidambi", "et", "al.", ",", "2018", "-RSB-", ",", "the", "authors", "show", "that", "there", "exists", "linear", "regression", "problems", "for", "which", "SGM", "outperforms", "SGMM", "in", "terms", "of", "convergence", "for", "any", "learning", "rate", "and", "momentum", "parameter", ".", "Dear", "author", "-LRB-", "s", "-RRB-", ",", "Thank", "you", "for", "your", "response", "!", "1", ".", "The", "set", "of", "assumptions", "-LRB-", "smooth", ",", "Lipschitz", "and", "strongly", "convex", "-RRB-", "is", "not", "valid", "on", "the", "whole", "set", "R", "^", "d", ",", "for", "example", "quadratic", "function", ".", "Your", "L", "may", "be", "arbitrarily", "large", "and", "your", "bound", "in", "-LRB-", "14", "-RRB-", "could", "be", "damaged", ".", "I", "do", "not", "think", "you", "can", "properly", "apply", "the", "projection", "step", "here", "after", "deriving", "-LRB-", "14", "-RRB-", "in", "case", "of", "L", "-", ">", "\\", "infty", ".", "2", ".", "I", "was", "asking", "about", "the", "linear", "convergence", "to", "TICKTICK", "neighborhood", "''", ",", "not", "to", "the", "TICKTICK", "optimal", "solution", "''", ".", "Your", "theory", "seems", "not", "able", "to", "cover", "this", "case", ".", "Dear", "reviewer", ",", "-", "To", "clarify", "the", "correctness", "of", "our", "proof", ",", "please", "note", "that", "L", "in", "the", "theorem", "statement", "and", "the", "proof", "is", "bounded", "due", "to", "compactness", "of", "the", "parameter", "space", ".", "We", "have", "shown", "that", "-LRB-", "19", "-RRB-", "holds", "for", "projected", "SGMM", ".", "Before", "-LRB-", "19", "-RRB-", ",", "we", "have", "not", "used", "L-Lipschitz", ".", "-", "Regarding", "convergence", "analysis", ",", "please", "note", "that", "our", "goal", "is", "to", "find", "a", "*", "global", "*", "convergence", "bound", "not", "a", "TICKTICK", "local", "''", "one", ".", "We", "know", "that", "classical", "results", "show", "that", "heavy", "ball", "momentum", "achieves", "linear", "convergence", "rate", "locally", ".", "However", ",", "those", "results", "are", "for", "batch", "gradient", "descent", "not", "stochastic", "gradient", "descent", "for", "a", "general", "strongly-convex", "function", ".", "Dear", "author", "-LRB-", "s", "-RRB-", ",", "You", "are", "using", "a", "stochastic", "algorithm", ".", "There", "is", "nothing", "guarantee", "that", "all", "of", "your", "updated", "iterations", "are", "in", "compact", "set", ".", "It", "is", "true", "that", "you", "consider", "projected", "step", "as", "in", "-LRB-", "5", "-RRB-", ".", "However", ",", "your", "proof", "in", "Lemma", "1", "from", "the", "beginning", "to", "-LRB-", "14", "-RRB-", ",", "you", "are", "using", "without", "projection", ".", "It", "would", "damage", "your", "bound", "in", "-LRB-", "14", "-RRB-", "as", "I", "mentioned", "before", "that", "L", "could", "be", "arbitrarily", "large", ".", "Your", "explanation", "in", "the", "last", "paragraph", "of", "Lemma", "1", "is", "not", "convincing", ".", "In", "order", "to", "fix", "this", "issue", ",", "you", "may", "need", "to", "consider", "your", "derivation", "with", "projected", "step", "from", "the", "beginning", "of", "the", "proof", ".", "Dear", "reviewer", ",", "Please", "note", "that", "inequalities", "-LRB-", "A.", "2", "-RRB-", "and", "-LRB-", "A.", "3", "-RRB-", "-LRB-", "shown", "in", "the", "proof", "of", "Lemma", "1", "in", "the", "supplementary", "document", "-RRB-", "hold", "for", "the", "projected", "SGMM", "update", "-LRB-", "5", "-RRB-", "because", "Euclidean", "projection", "does", "not", "increase", "the", "distance", "between", "projected", "points", ".", "We", "are", "quite", "certain", "that", "our", "proof", "is", "correct", ",", "since", "our", "approach", "to", "handle", "projection", "is", "a", "commonly", "used", "technique", "in", "existing", "work", ".", "For", "example", ",", "it", "is", "used", "in", "-LRB-", "Hardt", "et", "al.", ",", "2016", "-RRB-", "-LSB-", "Section", "3.4", "-RSB-", ".", "I", "am", "not", "sure", "where", "I", "could", "find", "the", "supplementary", "document", "as", "you", "said", ".", "The", "pdf", "file", "only", "contains", "9", "pages", ".", "Dear", "reviewer", ",", "The", "supplementary", "document", "was", "submitted", "along", "with", "the", "original", "submission", ".", "It", "can", "be", "found", "by", "clicking", "the", "TICKTICK", "Show", "revisions", "''", "link", "below", "the", "paper", "title", ".", "Yes", ",", "it", "should", "hold", "for", "projection", "steps", "in", "-LRB-", "A2", "-RRB-", "and", "-LRB-", "A3", "-RRB-", ".", "But", "even", "so", ",", "your", "constant", "L", "must", "depend", "on", "the", "radius", "of", "the", "compact", "set", "of", "the", "parameters", ".", "How", "could", "you", "guarantee", "the", "optimal", "solution", "of", "the", "strongly", "convex", "problem", "is", "always", "in", "that", "compact", "set", "?", "In", "order", "to", "increase", "TICKTICK", "the", "chance", "''", "of", "the", "compact", "set", "containing", "the", "optimal", "solution", ",", "you", "need", "to", "TICKTICK", "increase", "''", "the", "size", "of", "the", "compact", "set", ",", "which", "implicitly", "pushes", "L", "be", "arbitrarily", "large", ".", "Therefore", ",", "it", "is", "only", "possible", "if", "you", "just", "find", "the", "solution", "from", "the", "small", "compact", "set", "-LRB-", "from", "which", "the", "optimal", "solution", "may", "be", "very", "far", "-RRB-", ".", "Our", "problem", "setting", "involves", "constrained", "optimization", "where", "we", "seek", "the", "optimal", "solution", "within", "a", "compact", "set", ".", "This", "constraint", "is", "assumed", "to", "be", "given", "apriori", "in", "the", "problem", "definition", ".", "Such", "setting", "have", "been", "widely", "considered", "in", "the", "literature", ".", "See", "for", "example", ":", "-LRB-", "Hardt", "et", "al.", ",", "2016", "-RRB-", "-LSB-", "Section", "3.4", "-RSB-", "-RRB-", ".", "Please", "note", "that", "we", "do", "not", "address", "the", "unconstrained", "optimization", "problem", "that", "you", "mention", "in", "your", "response", ".", "Thus", "we", "do", "not", "need", "to", "design", "the", "compact", "set", "that", "increases", "the", "chance", "of", "the", "compact", "set", "containing", "the", "optimal", "solution", ".", "We", "hope", "this", "clarifies", "our", "problem", "setup", "and", "you", "are", "convinced", "by", "the", "technical", "soundness", "of", "our", "work", "."], "comment_id": "B1e21iAhA7"}, {"rels": [[0, 33, 33, 45, "circumstance"], [0, 45, 45, 903, "elaboration"], [45, 105, 105, 903, "topic"], [45, 59, 59, 70, "elaboration"], [45, 70, 70, 105, "elaboration"], [105, 903, 45, 105, "topic"], [148, 903, 105, 148, "concession"], [148, 158, 158, 903, "elaboration"], [158, 166, 166, 178, "elaboration"], [166, 167, 167, 178, "elaboration"], [168, 178, 167, 168, "attribution"], [168, 175, 175, 178, "same_unit"], [168, 171, 171, 175, "elaboration"], [175, 178, 168, 175, "same_unit"], [158, 178, 178, 903, "example"], [178, 190, 190, 196, "elaboration"], [178, 196, 196, 903, "elaboration"], [196, 237, 237, 903, "elaboration"], [250, 269, 237, 250, "concession"], [237, 245, 245, 250, "elaboration"], [237, 269, 269, 903, "elaboration"], [269, 276, 276, 285, "purpose"], [269, 285, 285, 903, "example"], [285, 307, 307, 336, "elaboration"], [285, 336, 336, 903, "elaboration"], [336, 348, 348, 359, "elaboration"], [348, 350, 350, 359, "circumstance"], [336, 359, 359, 903, "elaboration"], [359, 372, 372, 379, "elaboration"], [372, 378, 378, 379, "elaboration"], [359, 379, 379, 391, "elaboration"], [379, 384, 384, 391, "elaboration"], [359, 391, 391, 903, "elaboration"], [391, 429, 429, 903, "contrast"], [391, 399, 399, 429, "purpose"], [399, 407, 407, 429, "same_unit"], [407, 429, 399, 407, "same_unit"], [408, 429, 407, 408, "attribution"], [408, 422, 422, 429, "list"], [422, 429, 408, 422, "list"], [429, 903, 391, 429, "contrast"], [429, 444, 444, 903, "elaboration"], [444, 473, 473, 903, "list"], [444, 450, 450, 473, "elaboration"], [450, 459, 459, 473, "elaboration"], [459, 465, 465, 473, "elaboration"], [473, 903, 444, 473, "list"], [473, 476, 476, 903, "textualorganization"], [476, 903, 473, 476, "textualorganization"], [476, 483, 483, 512, "elaboration"], [488, 512, 483, 488, "attribution"], [488, 498, 498, 512, "elaboration"], [476, 512, 512, 903, "elaboration"], [520, 545, 512, 520, "concession"], [520, 531, 531, 545, "same_unit"], [531, 545, 520, 531, "same_unit"], [531, 532, 532, 545, "circumstance"], [532, 538, 538, 545, "elaboration"], [512, 545, 545, 903, "condition"], [576, 903, 545, 576, "condition"], [560, 576, 545, 560, "condition"], [560, 561, 561, 576, "elaboration"], [576, 624, 624, 903, "textualorganization"], [576, 579, 579, 624, "elaboration"], [624, 903, 576, 624, "textualorganization"], [624, 630, 630, 665, "example"], [630, 632, 632, 665, "elaboration"], [632, 639, 639, 665, "elaboration"], [639, 645, 645, 665, "elaboration"], [646, 665, 645, 646, "attribution"], [646, 653, 653, 665, "same_unit"], [653, 665, 646, 653, "same_unit"], [655, 665, 653, 655, "attribution"], [624, 665, 665, 903, "elaboration"], [705, 903, 665, 705, "concession"], [665, 666, 666, 705, "elaboration"], [719, 744, 705, 719, "attribution"], [730, 744, 719, 730, "concession"], [730, 736, 736, 744, "elaboration"], [705, 744, 744, 903, "elaboration"], [749, 753, 744, 749, "attribution"], [744, 753, 753, 903, "elaboration"], [753, 759, 759, 781, "elaboration"], [759, 773, 773, 781, "elaboration"], [753, 781, 781, 801, "elaboration"], [753, 801, 801, 903, "elaboration"], [801, 816, 816, 903, "elaboration"], [822, 853, 816, 822, "attribution"], [822, 830, 830, 853, "elaboration"], [830, 841, 841, 853, "circumstance"], [816, 853, 853, 903, "elaboration"], [853, 887, 887, 903, "elaboration"]], "tokens": ["The", "primary", "technical", "contribution", "comes", "from", "Section", "2", ",", "where", "it", "is", "demonstrated", "that", "the", "normalized", "back-propagated", "gradients", "obtained", "from", "a", "BN", "layer", "can", "be", "viewed", "as", "the", "residuals", "of", "the", "gradients", "obtained", "without", "BN", "regressed", "via", "a", "simple", "two-parameter", "model", "of", "the", "activations", ".", "In", "some", "sense", "though", "this", "result", "is", "to", "be", "expected", ",", "since", "centering", "data", "-LRB-", "i.e.", ",", "removing", "the", "mean", "as", "in", "BN", "-RRB-", "can", "be", "generically", "viewed", "as", "computing", "the", "residuals", "after", "a", "least", "squares", "fit", "of", "a", "single", "constant", ",", "and", "similarly", "for", "de-trending", "with", "respect", "to", "a", "single", "independent", "variable", ",", "in", "this", "case", "the", "activations", ".", "So", "I", "'m", "not", "sure", "that", "Theorem", "1", "is", "really", "that", "much", "of", "an", "insightful", "breakthrough", ",", "even", "if", "it", "may", "be", "nice", "to", "work", "through", "the", "precise", "details", "in", "the", "specific", "case", "of", "a", "BN", "layer", "and", "the", "relationship", "to", "gradients", ".", "But", "beyond", "this", "a", "larger", "issue", "is", "as", "follows", ":", "This", "paper", "is", "framed", "as", "taking", "a", "step", "in", "explaining", "why", "batch", "normalization", "-LRB-", "BN", "-RRB-", "works", "so", "well", ".", "For", "example", ",", "even", "the", "abstract", "mentions", "this", "as", "an", "unsettled", "issue", "in", "motivating", "the", "proposed", "analysis", ".", "However", ",", "to", "me", "the", "interpretation", "of", "BN", "as", "introducing", "a", "form", "of", "least", "squares", "fit", "does", "not", "really", "extend", "our", "understanding", "of", "why", "it", "actually", "works", "better", "in", "practice", ",", "and", "this", "is", "the", "biggest", "disconnect", "of", "the", "paper", ".", "The", "new", "perspective", "presented", "might", "be", "another", "way", "to", "interpret", "BN", "layers", ",", "but", "it", "unfortunately", "remains", "mostly", "unanswered", "exactly", "why", "this", "new", "perspective", "is", "relevant", "in", "actually", "explaining", "BN", "behavior", ".", "The", "presented", "normalization", "theory", "is", "also", "used", "to", "motivate", "heuristic", "modifications", "to", "standard", "BN", "schemes", ".", "For", "example", ",", "the", "paper", "proposed", "concatenating", "BN", "with", "a", "layer", "normalization", "layer", ",", "demonstrating", "some", "modest", "improvement", "on", "CIFAR-10", "data", ".", "But", "again", ",", "I", "do", "n't", "see", "how", "viewing", "these", "normalization", "schemes", "as", "least-squares", "residuals", "motivates", "such", "concatenation", "any", "more", "than", "the", "merits", "of", "the", "original", "versions", "themselves", ".", "Moreover", ",", "it", "is", "not", "even", "clear", "that", "BN+LN", "is", "in", "fact", "generally", "better", "since", "only", "a", "single", "data", "set", "is", "considered", ".", "There", "are", "also", "no", "comparisons", "against", "competing", "BN", "modifications", "such", "as", "switch", "normalization", "-LRB-", "Luo", "et", "al.", "2018", "-RRB-", "which", "also", "involves", "a", "hybrid", "method", "combining", "aspects", "of", "LN", "and", "BN", ".", "Why", "not", "compare", "against", "approaches", "like", "this", "?", "To", "conclude", ",", "in", "Section", "6", "the", "paper", "asks", "TICKTICK", "Why", "do", "empirical", "improvements", "in", "neural", "networks", "with", "BN", "keep", "the", "gradient-least-squares", "residuals", "and", "drop", "the", "explained", "portion", "?", "''", "But", "this", "question", "is", "not", "at", "all", "answered", "but", "rather", "deferred", "to", "future", "work", ".", "For", "me", "this", "was", "a", "disappointment", "as", "this", "would", "seem", "to", "be", "an", "essential", "ingredient", "for", "actually", "developing", "a", "meaningful", "theory", "for", "why", "BN", "is", "helpful", "in", "practice", ".", "Other", "comments", ":", "*", "The", "analysis", "from", "Section", "2", ",", "including", "Theorem", "1", ",", "assume", "that", "the", "BN", "parameters", "c", "and", "b", "can", "be", "ignored", "-LRB-", "presumably", "this", "means", "fixing", "c", "=", "1", "and", "b", "=", "0", "-RRB-", ".", "I", "did", "not", "carefully", "check", "the", "details", ",", "but", "do", "all", "the", "same", "derivations", "and", "conclusions", "still", "seamlessly", "go", "through", "when", "these", "parameters", "have", "general", "values", "that", "deviate", "from", "this", "standard", "initialization", "?", "If", "not", ",", "then", "I", "do", "n't", "really", "see", "what", "is", "the", "practical", "relevance", ",", "since", "once", "learning", "begins", ",", "both", "b", "and", "c", "will", "typically", "shift", "to", "arbitrary", "values", ".", "Below", "eq", ".", "-LRB-", "1", "-RRB-", "it", "states", "that", "c", "and", "b", "are", "only", "ignored", "for", "clarity", ",", "but", "then", "later", "I", "did", "not", "see", "any", "subsequent", "discussion", "to", "handle", "the", "general", "case", ",", "which", "is", "what", "would", "be", "actually", "needed", "for", "explaining", "BN", "behavior", "in", "practice", ".", "*", "Please", "run", "a", "speck-checker", ".", "Example", ",", "TICKTICK", "On", "some", "leve", ",", "the", "matrix", "gradient", "...", "''", "*", "The", "paper", "cites", "-LRB-", "Lipton", "and", "Steinhardt", ",", "2018", "-RRB-", "in", "arguing", "that", "reasons", "for", "the", "effectiveness", "of", "BN", "are", "lacking", ".", "Indeed", "-LRB-", "Lipton", "and", "Steinhardt", ",", "2018", "-RRB-", "criticize", "the", "original", "BN", "paper", "for", "conflating", "speculation", "with", "explanation", ",", "or", "more", "precisely", ",", "framing", "speculation", "about", "why", "BN", "should", "be", "helpful", "as", "an", "actual", "true", "explanation", "without", "clear", "evidence", ".", "But", "to", "me", "this", "submission", "is", "hovering", "somewhere", "in", "the", "same", "category", ",", "speculating", "that", "regressing", "away", "certain", "portions", "of", "the", "gradient", "could", "be", "useful", "but", "never", "really", "providing", "concrete", "evidence", "for", "why", "this", "should", "offer", "an", "improvement", ".", "Dear", "Paper923", "AnonReviewer2", "Thank", "you", "for", "your", "criticisms", ".", "We", "have", "dialed", "back", "our", "language", "in", "the", "abstract", ",", "the", "TLDR", ",", "and", "the", "main", "body", "of", "the", "text", "to", "reflect", "your", "perspective", "on", "our", "work", ".", "We", "apologize", "for", "the", "typos", "in", "the", "earlier", "version", ",", "and", "we", "have", "been", "more", "diligent", "in", "this", "update", ".", "Also", ",", "we", "have", "clarified", "some", "of", "the", "language", "around", "the", "downstream", "affine", "transformation", ".", "Ignoring", "the", "affine", "transform", "is", "done", "without", "loss", "of", "generality", ",", "in", "the", "sense", "that", "they", "can", "be", "absorbed", "into", "the", "rest", "of", "the", "network", "without", "impacting", "our", "view", "of", "the", "gradients", "of", "the", "gaussian", "normalization", ".", "Our", "experiments", "were", "meant", "to", "be", "toy-examples", "of", "how", "one", "might", "better", "understand", "what", "happens", "to", "the", "gradient", "regression", "under", "adjustments", "to", "BN", ";", "ideally", ",", "we", "would", "like", "to", "design", "a", "new", "normalization", "that", "outperforms", "switch", "normalization", ",", "but", "we", "have", "not", "been", "able", "to", "do", "that", "here", "."], "comment_id": "B1eSC5-K0X"}, {"rels": [[0, 10, 10, 15, "elaboration"], [0, 15, 15, 27, "elaboration"], [15, 19, 19, 27, "purpose"], [0, 27, 27, 983, "elaboration"], [27, 32, 32, 61, "elaboration"], [32, 41, 41, 61, "elaboration"], [41, 57, 57, 61, "elaboration"], [27, 61, 61, 983, "elaboration"], [61, 67, 67, 81, "elaboration"], [67, 72, 72, 81, "elaboration"], [61, 81, 81, 983, "elaboration"], [88, 117, 81, 88, "attribution"], [100, 117, 88, 100, "attribution"], [100, 112, 112, 117, "elaboration"], [81, 117, 117, 983, "elaboration"], [120, 135, 117, 120, "attribution"], [117, 135, 135, 983, "elaboration"], [135, 141, 141, 147, "elaboration"], [135, 147, 147, 983, "elaboration"], [147, 165, 165, 191, "elaboration"], [165, 169, 169, 191, "elaboration"], [147, 191, 191, 213, "elaboration"], [191, 192, 192, 213, "elaboration"], [192, 203, 203, 213, "elaboration"], [203, 204, 204, 213, "elaboration"], [147, 213, 213, 983, "elaboration"], [213, 231, 231, 254, "elaboration"], [231, 238, 238, 254, "elaboration"], [238, 246, 246, 254, "list"], [246, 254, 238, 246, "list"], [213, 254, 254, 983, "elaboration"], [254, 266, 266, 286, "same_unit"], [254, 260, 260, 266, "elaboration"], [266, 286, 254, 266, "same_unit"], [266, 281, 281, 286, "purpose"], [254, 286, 286, 983, "elaboration"], [286, 287, 287, 290, "elaboration"], [286, 290, 290, 303, "elaboration"], [286, 303, 303, 315, "elaboration"], [303, 311, 311, 315, "elaboration"], [286, 315, 315, 983, "elaboration"], [315, 329, 329, 347, "same_unit"], [315, 325, 325, 329, "elaboration"], [329, 347, 315, 329, "same_unit"], [329, 330, 330, 347, "elaboration"], [330, 341, 341, 347, "elaboration"], [315, 347, 347, 983, "elaboration"], [347, 353, 353, 386, "condition"], [362, 386, 353, 362, "condition"], [362, 385, 385, 386, "same_unit"], [362, 373, 373, 385, "elaboration"], [385, 386, 362, 385, "same_unit"], [347, 386, 386, 983, "elaboration"], [391, 399, 386, 391, "attribution"], [386, 399, 399, 983, "elaboration"], [399, 408, 408, 426, "purpose"], [408, 416, 416, 426, "elaboration"], [416, 425, 425, 426, "purpose"], [399, 426, 426, 434, "elaboration"], [427, 434, 426, 427, "attribution"], [399, 434, 434, 983, "elaboration"], [434, 442, 442, 983, "reason"], [442, 451, 451, 462, "elaboration"], [442, 462, 462, 983, "elaboration"], [462, 467, 467, 477, "purpose"], [467, 470, 470, 477, "elaboration"], [462, 477, 477, 983, "elaboration"], [480, 495, 477, 480, "attribution"], [480, 489, 489, 495, "list"], [489, 495, 480, 489, "list"], [477, 495, 495, 983, "elaboration"], [495, 499, 499, 507, "elaboration"], [495, 507, 507, 983, "elaboration"], [507, 514, 514, 557, "elaboration"], [514, 520, 520, 557, "elaboration"], [507, 557, 557, 983, "elaboration"], [557, 578, 578, 983, "list"], [557, 562, 562, 578, "purpose"], [562, 567, 567, 578, "list"], [567, 578, 562, 567, "list"], [569, 578, 567, 569, "attribution"], [578, 983, 557, 578, "list"], [578, 585, 585, 983, "list"], [579, 585, 578, 579, "attribution"], [585, 983, 578, 585, "list"], [585, 590, 590, 983, "list"], [590, 983, 585, 590, "list"], [590, 592, 592, 617, "elaboration"], [592, 599, 599, 617, "purpose"], [599, 604, 604, 617, "elaboration"], [604, 606, 606, 617, "elaboration"], [590, 617, 617, 983, "elaboration"], [617, 629, 629, 669, "list"], [617, 625, 625, 629, "elaboration"], [629, 669, 617, 629, "list"], [629, 640, 640, 669, "list"], [640, 669, 629, 640, "list"], [640, 641, 641, 669, "elaboration"], [617, 669, 669, 983, "elaboration"], [669, 702, 702, 983, "elaboration"], [702, 807, 807, 983, "list"], [702, 704, 704, 729, "elaboration"], [721, 729, 704, 721, "attribution"], [704, 709, 709, 721, "elaboration"], [721, 725, 725, 729, "circumstance"], [702, 729, 729, 807, "elaboration"], [729, 731, 731, 742, "elaboration"], [729, 742, 742, 807, "elaboration"], [742, 764, 764, 770, "elaboration"], [742, 770, 770, 807, "elaboration"], [770, 779, 779, 807, "elaboration"], [779, 785, 785, 807, "elaboration"], [807, 983, 702, 807, "list"], [807, 816, 816, 983, "list"], [807, 809, 809, 816, "elaboration"], [816, 983, 807, 816, "list"], [816, 838, 838, 983, "list"], [816, 818, 818, 838, "elaboration"], [838, 983, 816, 838, "list"], [838, 862, 862, 983, "list"], [862, 983, 838, 862, "list"], [862, 863, 863, 864, "elaboration"], [862, 864, 864, 872, "elaboration"], [862, 872, 872, 983, "elaboration"], [872, 876, 876, 983, "textualorganization"], [876, 983, 872, 876, "textualorganization"], [876, 896, 896, 983, "list"], [876, 886, 886, 896, "elaboration"], [896, 983, 876, 896, "list"], [896, 897, 897, 902, "elaboration"], [896, 902, 902, 983, "elaboration"], [902, 906, 906, 922, "purpose"], [906, 912, 912, 922, "elaboration"], [902, 922, 922, 983, "elaboration"], [922, 924, 924, 955, "elaboration"], [924, 941, 941, 955, "same_unit"], [924, 934, 934, 941, "elaboration"], [941, 955, 924, 941, "same_unit"], [941, 946, 946, 955, "elaboration"], [922, 955, 955, 983, "elaboration"], [955, 957, 957, 965, "purpose"], [957, 961, 961, 965, "elaboration"], [955, 965, 965, 983, "elaboration"], [965, 969, 969, 983, "elaboration"], [969, 974, 974, 983, "same_unit"], [971, 974, 969, 971, "attribution"], [974, 983, 969, 974, "same_unit"]], "tokens": ["#", "Summary", "This", "paper", "proposes", "a", "simple", "regularizer", "for", "RL", "which", "encourages", "the", "state", "representations", "learned", "by", "neural", "networks", "to", "be", "more", "discriminative", "across", "different", "observations", ".", "The", "main", "idea", "is", "to", "-LRB-", "implicitly", "-RRB-", "measure", "the", "rank", "of", "the", "matrix", "which", "is", "constructed", "from", "a", "sequence", "of", "observations", "and", "state", "feature", "vectors", "and", "encourage", "the", "rank", "to", "be", "high", ".", "This", "paper", "introduces", "three", "different", "objectives", "to", "implement", "the", "same", "idea", "-LRB-", "increasing", "the", "rank", "of", "the", "matrix", "-RRB-", ".", "The", "experimental", "results", "on", "Atari", "games", "show", "that", "this", "regularizer", "improves", "A3C", "on", "most", "of", "the", "games", "and", "show", "that", "the", "learned", "representations", "with", "the", "proposed", "regularizer", "has", "a", "high", "rank", "compared", "to", "the", "baseline", ".", "-LSB-", "Pros", "-RSB-", "-", "Makes", "an", "interesting", "point", "about", "the", "correlation", "between", "RL", "performance", "and", "state", "representations", ".", "-", "Proposes", "a", "simple", "objective", "function", "that", "gives", "strong", "empirical", "results", ".", "-LSB-", "Cons", "-RSB-", "-", "Needs", "more", "empirical", "evidences", "to", "better", "support", "the", "main", "hypothesis", "of", "the", "paper", ".", "#", "Novelty", "and", "Significance", "-", "This", "paper", "makes", "an", "interesting", "observation", "about", "the", "correlation", "between", "the", "RL", "performance", "and", "the", "how", "discriminative", "the", "learned", "features", ".", "-", "To", "verify", "it", ",", "this", "paper", "proposes", "a", "new", "and", "simple", "regularizer", "which", "improves", "the", "performance", "across", "many", "Atari", "games", ".", "#", "Quality", "and", "Experiment", "-", "The", "main", "hypothesis", "of", "this", "paper", "is", "that", "the", "expressiveness", "of", "the", "features", "-LRB-", "specifically", "the", "rank", "of", "the", "matrix", "that", "consists", "of", "a", "sequence", "of", "features", "-RRB-", "and", "its", "RL", "performance", "is", "highly", "correlated", ".", "Although", "this", "paper", "showed", "some", "plots", "-LRB-", "Figure", "2", ",", "6", "-RRB-", "to", "verify", "this", ",", "a", "more", "extensive", "statistical", "test", "or", "experiments", "would", "be", "more", "convincing", "to", "show", "the", "hypothesis", ".", "Examples", "would", "be", ":", "1", "-RRB-", "Measuring", "the", "correlation", "between", "the", "two", "across", "all", "Atari", "games", ".", "2", "-RRB-", "An", "ablation", "study", "on", "the", "hyperparameter", "-LRB-", "alpha", "-RRB-", ".", "3", "-RRB-", "Learning", "state", "representations", "just", "from", "the", "reconstruction", "task", "-LRB-", "without", "RL", "-RRB-", "with/without", "the", "proposed", "regularizer", "and", "separately", "learning", "policies", "on", "top", "of", "that", "-LRB-", "with", "fixed", "representations", "-RRB-", ".", "It", "would", "be", "much", "more", "convincing", "if", "the", "regularizer", "helps", "even", "in", "this", "setup", ",", "because", "this", "would", "show", "the", "general", "effect", "of", "the", "expressiveness", "term", "-LRB-", "by", "removing", "the", "effect", "of", "RL", "algorithm", "on", "the", "representation", "-RRB-", ".", "-", "This", "paper", "only", "reports", "TICKTICK", "relative", "''", "performances", "to", "the", "baseline", ".", "Though", "it", "looks", "strong", ",", "it", "is", "also", "important", "to", "report", "the", "absolute", "performances", "in", "Atari", "games", "-LRB-", "e.g.", ",", "median", "human-normalized", "score", ",", "etc", "-RRB-", "to", "show", "how", "significant", "the", "performance", "gap", "is", ".", "-", "The", "results", "with", "DQN", "are", "not", "convincing", "because", "the", "agents", "are", "trained", "only", "for", "20M", "frames", "-LRB-", "compared", "to", "200M", "frames", "in", "many", "other", "papers", "-RRB-", ".", "It", "is", "not", "much", "meaningful", "to", "compare", "performances", "on", "such", "a", "short", "training", "regime", ".", "I", "would", "suggest", "running", "longer", "or", "removing", "this", "result", "from", "the", "paper", "and", "focusing", "on", "more", "analysis", ".", "#", "Clarity", "and", "Presentation", "-", "Figure", "1a", "is", "not", "much", "insightful", ".", "It", "is", "not", "surprising", "that", "the", "representations", "that", "led", "to", "a", "poor", "policy", "-LRB-", "which", "achieves", "0", "reward", "-RRB-", "are", "much", "less", "discriminative", "given", "five", "situations", "with", "five", "distinct", "optimal", "actions", ",", "because", "the", "the", "policy", "has", "no", "idea", "which", "action", "is", "better", "than", "the", "other", "in", "such", "situations", ".", "It", "would", "be", "more", "informative", "to", "pick", "N", "consecutive", "frames", "and", "show", "how", "scattered", "they", "are", "in", "the", "embedding", "space", ".", "Thank", "you", "for", "the", "helpful", "comments", ".", "Here", "are", "our", "responses", ".", "Q1", ":", "A", "more", "extensive", "statistical", "test", "or", "experiments", "to", "convince", "the", "hypothesis", ":", "a", "-RRB-", "Measuring", "the", "correlation", "between", "the", "two", "across", "all", "Atari", "games", ".", "b", "-RRB-", "An", "ablation", "study", "on", "the", "hyperparameter", "-LRB-", "alpha", "-RRB-", ".", "c", "-RRB-", "Learning", "state", "representations", "separately", "...", "A1", ":", "a", "-RRB-", "Curves", "tracking", "testing", "rewards", "and", "the", "expressiveness", "in", "Fig.", "2", "and", "Fig.", "6", "have", "demonstrated", "their", "correlation", "over", "multiple", "Atari", "games", ",", "which", "have", "shown", "some", "statistical", "significance", ".", "In", "order", "to", "make", "the", "results", "more", "convincing", ",", "we", "have", "added", "the", "study", "about", "relationship", "between", "model", "performance", "and", "representations", "across", "all", "Atari", "games", "in", "Section", "2.2.1", "in", "our", "updated", "version", ".", "b", "-RRB-", "The", "ablation", "study", "on", "hyperparameter", "-LRB-", "alpha", "-RRB-", "is", "shown", "in", "Appendix", "B", "now", ",", "which", "shows", "that", "improvements", "are", "stable", "with", "different", "alpha", ".", "c", "-RRB-", "Our", "proposed", "method", "is", "designed", "and", "applied", "to", "RL", "algorithms", ".", "Although", "one", "RL", "agent", "model", "can", "be", "viewed", "as", "the", "state", "extractor", "and", "the", "policy", "learning", "part", ",", "they", "are", "trained", "end-to-end", "within", "the", "RL", "algorithm", "loop", ".", "These", "two", "parts", "influence", "each", "other", "during", "training", ".", "Besides", ",", "we", "do", "not", "emphasis", "which", "part", "works", "in", "our", "proposed", "method", "indeed", ",", "we", "just", "make", "a", "correlation", "between", "performances", "and", "the", "expressiveness", "of", "representations", ".", "Q2", ":", "Detailed", "questions", "for", "the", "experimental", "results", ".", "A2", ":", "1", "-RRB-", "We", "also", "provide", "the", "absolute", "performances", "of", "all", "Atari", "games", "in", "Appendix", "C", "in", "the", "updated", "version", ".", "2", "-RRB-", "For", "DQN", ",", "we", "finished", "the", "experiments", "for", "200M", "frames", "and", "updated", "the", "results", "in", "Section", "4.4", "in", "the", "new", "version", ".", "Q3", ":", "TICKTICK", "Figure", "1a", "is", "not", "much", "insightful", ".", "...", "''", "A3", ":", "Fig.", "1a", "has", "been", "refined", "in", "the", "following", "way", ":", "selected", "frames", "and", "their", "corresponding", "embedding", "points", "are", "removed", ".", "Thanks", "for", "addressing", "my", "questions", ".", "The", "revised", "paper", "seems", "to", "provide", "a", "bit", "more", "evidence", "about", "the", "relationship", "between", "expressiveness", "and", "performance", "in", "RL", ".", "One", "thing", "that", "I", "realized", "is", "that", "the", "authors", "used", "different", "hyperparameters", "-LRB-", "rank", "regularization", "term", ",", "alpha", "-RRB-", "for", "each", "Atari", "game", ",", "which", "makes", "the", "proposed", "algorithm", "look", "less", "practical", ".", "I", "decided", "to", "keep", "my", "score", "-LRB-", "6", "-RRB-", ".", "One", "minor", "comment", ":", "Please", "compute", "TICKTICK", "human", "''", "-", "normalized", "score", "in", "Table", "5", "and", "6", "."], "comment_id": "B1ekBnl3yV"}, {"rels": [[0, 1077, 1077, 1227, "topic"], [0, 8, 8, 18, "means"], [0, 18, 18, 1077, "elaboration"], [18, 29, 29, 38, "elaboration"], [18, 38, 38, 1077, "elaboration"], [38, 42, 42, 53, "circumstance"], [42, 47, 47, 53, "elaboration"], [38, 53, 53, 1077, "elaboration"], [56, 69, 53, 56, "attribution"], [53, 69, 69, 1077, "elaboration"], [69, 88, 88, 105, "elaboration"], [88, 92, 92, 105, "purpose"], [92, 97, 97, 105, "condition"], [69, 105, 105, 1077, "elaboration"], [106, 119, 105, 106, "attribution"], [106, 110, 110, 119, "same_unit"], [106, 107, 107, 110, "elaboration"], [110, 119, 106, 110, "same_unit"], [105, 119, 119, 1077, "elaboration"], [125, 139, 119, 125, "attribution"], [125, 132, 132, 139, "purpose"], [119, 139, 139, 1077, "elaboration"], [139, 141, 141, 1077, "elaboration"], [141, 168, 168, 183, "elaboration"], [141, 183, 183, 209, "elaboration"], [141, 209, 209, 1077, "elaboration"], [209, 217, 217, 1077, "elaboration"], [217, 220, 220, 251, "elaboration"], [220, 242, 242, 251, "elaboration"], [217, 251, 251, 1077, "elaboration"], [251, 260, 260, 270, "purpose"], [251, 270, 270, 1077, "elaboration"], [271, 284, 270, 271, "attribution"], [271, 276, 276, 284, "condition"], [270, 284, 284, 1077, "elaboration"], [284, 301, 301, 1077, "elaboration"], [301, 308, 308, 1077, "elaboration"], [308, 312, 312, 327, "purpose"], [308, 327, 327, 1077, "elaboration"], [332, 342, 327, 332, "attribution"], [332, 337, 337, 342, "circumstance"], [327, 342, 342, 426, "elaboration"], [342, 365, 365, 426, "elaboration"], [365, 385, 385, 397, "same_unit"], [365, 369, 369, 385, "elaboration"], [385, 397, 365, 385, "same_unit"], [365, 397, 397, 426, "elaboration"], [400, 426, 397, 400, "attribution"], [400, 419, 419, 426, "elaboration"], [327, 426, 426, 1077, "elaboration"], [426, 436, 436, 1077, "elaboration"], [436, 448, 448, 1077, "elaboration"], [448, 459, 459, 469, "elaboration"], [448, 469, 469, 1077, "elaboration"], [469, 482, 482, 1077, "elaboration"], [482, 484, 484, 497, "elaboration"], [482, 497, 497, 1077, "elaboration"], [497, 508, 508, 549, "elaboration"], [508, 519, 519, 549, "elaboration"], [519, 521, 521, 549, "elaboration"], [521, 529, 529, 549, "elaboration"], [497, 549, 549, 1077, "elaboration"], [549, 556, 556, 570, "elaboration"], [556, 558, 558, 570, "elaboration"], [558, 559, 559, 570, "elaboration"], [559, 565, 565, 570, "elaboration"], [549, 570, 570, 1077, "elaboration"], [570, 581, 581, 1077, "elaboration"], [581, 591, 591, 618, "elaboration"], [591, 614, 614, 618, "elaboration"], [581, 618, 618, 1077, "elaboration"], [618, 627, 627, 645, "elaboration"], [627, 633, 633, 645, "attribution"], [633, 636, 636, 645, "purpose"], [618, 645, 645, 1077, "elaboration"], [647, 651, 645, 647, "attribution"], [645, 651, 651, 1077, "elaboration"], [651, 652, 652, 653, "elaboration"], [651, 653, 653, 667, "elaboration"], [653, 659, 659, 667, "same_unit"], [659, 667, 653, 659, "same_unit"], [651, 667, 667, 682, "elaboration"], [651, 682, 682, 1077, "elaboration"], [682, 683, 683, 684, "elaboration"], [682, 684, 684, 708, "elaboration"], [682, 708, 708, 1077, "elaboration"], [708, 716, 716, 741, "elaboration"], [716, 729, 729, 741, "elaboration"], [729, 734, 734, 741, "elaboration"], [708, 741, 741, 1077, "elaboration"], [741, 760, 760, 763, "elaboration"], [741, 763, 763, 828, "elaboration"], [763, 784, 784, 796, "same_unit"], [763, 778, 778, 784, "elaboration"], [784, 796, 763, 784, "same_unit"], [763, 796, 796, 828, "elaboration"], [796, 805, 805, 828, "list"], [796, 800, 800, 805, "elaboration"], [805, 828, 796, 805, "list"], [805, 822, 822, 828, "attribution"], [741, 828, 828, 1077, "elaboration"], [828, 851, 851, 870, "list"], [828, 837, 837, 851, "elaboration"], [851, 870, 828, 851, "list"], [851, 861, 861, 870, "elaboration"], [828, 870, 870, 1077, "elaboration"], [870, 872, 872, 1077, "elaboration"], [872, 881, 881, 888, "elaboration"], [872, 888, 888, 1077, "elaboration"], [890, 894, 888, 890, "attribution"], [888, 894, 894, 1077, "elaboration"], [894, 896, 896, 1077, "elaboration"], [906, 918, 896, 906, "attribution"], [896, 918, 918, 1077, "elaboration"], [918, 919, 919, 923, "elaboration"], [918, 923, 923, 1077, "elaboration"], [924, 930, 923, 924, "attribution"], [923, 930, 930, 1077, "elaboration"], [930, 951, 951, 1077, "elaboration"], [955, 972, 951, 955, "attribution"], [951, 972, 972, 1077, "elaboration"], [979, 988, 972, 979, "attribution"], [972, 988, 988, 1077, "elaboration"], [988, 990, 990, 991, "elaboration"], [988, 991, 991, 1005, "elaboration"], [991, 997, 997, 1005, "same_unit"], [997, 1005, 991, 997, "same_unit"], [988, 1005, 1005, 1020, "elaboration"], [988, 1020, 1020, 1077, "elaboration"], [1020, 1022, 1022, 1047, "elaboration"], [1020, 1047, 1047, 1077, "elaboration"], [1047, 1062, 1062, 1067, "circumstance"], [1047, 1067, 1067, 1077, "elaboration"], [1077, 1227, 0, 1077, "topic"], [1077, 1081, 1081, 1088, "same_unit"], [1078, 1081, 1077, 1078, "attribution"], [1081, 1088, 1077, 1081, "same_unit"], [1077, 1088, 1088, 1227, "circumstance"], [1088, 1108, 1108, 1227, "elaboration"], [1108, 1114, 1114, 1227, "list"], [1108, 1112, 1112, 1114, "elaboration"], [1114, 1227, 1108, 1114, "list"], [1115, 1227, 1114, 1115, "attribution"], [1115, 1116, 1116, 1227, "condition"], [1116, 1132, 1132, 1227, "elaboration"], [1132, 1139, 1139, 1227, "textualorganization"], [1139, 1227, 1132, 1139, "textualorganization"], [1139, 1163, 1163, 1178, "list"], [1139, 1150, 1150, 1163, "elaboration"], [1163, 1178, 1139, 1163, "list"], [1139, 1178, 1178, 1227, "elaboration"], [1178, 1193, 1193, 1209, "elaboration"], [1193, 1197, 1197, 1209, "elaboration"], [1197, 1203, 1203, 1209, "elaboration"], [1178, 1209, 1209, 1227, "elaboration"], [1216, 1227, 1209, 1216, "attribution"]], "tokens": ["The", "authors", "propose", "a", "new", "on-policy", "exploration", "strategy", "by", "using", "a", "policy", "with", "a", "hierarchy", "of", "stochasticity", ".", "The", "authors", "use", "a", "two-level", "hierarchical", "distribution", "as", "a", "policy", ",", "where", "the", "global", "variable", "is", "used", "for", "dropout", ".", "This", "work", "is", "interesting", "since", "the", "authors", "use", "dropout", "for", "policy", "learning", "and", "exploration", ".", "The", "authors", "show", "that", "parameter", "noise", "exploration", "is", "a", "particular", "case", "of", "the", "proposed", "policy", ".", "The", "main", "concern", "is", "the", "gap", "between", "the", "problem", "formulation", "and", "the", "actual", "optimization", "problem", "in", "Eq", "12", ".", "I", "am", "very", "happy", "to", "give", "a", "higher", "rating", "if", "the", "authors", "address", "the", "following", "points", ".", "Detailed", "Comments", "-LRB-", "1", "-RRB-", "The", "authors", "give", "the", "derivation", "for", "Eq", "10", ".", "However", ",", "it", "is", "not", "obvious", "that", "how", "to", "move", "from", "line", "3", "to", "line", "4", "at", "Eq", "15", ".", "Minor", ":", "Since", "the", "action", "is", "denoted", "by", "TICKTICK", "a", "''", ",", "it", "will", "be", "more", "clear", "if", "the", "authors", "use", "another", "symbol", "to", "denote", "the", "parameter", "of", "q", "-LRB-", "z", "-RRB-", "instead", "of", "''", "\\", "alpha", "''", "at", "Eq", "10", "and", "15", ".", "-LRB-", "2", "-RRB-", "Due", "to", "the", "use", "of", "the", "likelihood", "ratio", "trick", ",", "the", "authors", "use", "the", "mean", "policy", "as", "an", "approximation", "at", "Eq", "12", ".", "Does", "such", "approximation", "guarantee", "the", "policy", "improvement", "?", "Any", "justification", "?", "-LRB-", "3", "-RRB-", "Instead", "of", "using", "the", "mean", "policy", "approximation", "in", "Eq", "12", ",", "the", "authors", "should", "consider", "existing", "Monte", "Carlo", "techniques", "to", "reduce", "the", "variance", "of", "the", "gradient", "estimation", ".", "For", "example", ",", "-LSB-", "1", "-RSB-", "could", "be", "used", "to", "reduce", "the", "variance", "of", "gradient", "w.r.t.", "\\", "phi", ".", "Note", "that", "the", "gradient", "is", "biased", "if", "the", "mean", "policy", "approximation", "is", "used", ".", "-LRB-", "4", "-RRB-", "Are", "\\", "theta", "and", "\\", "phi", "jointly", "and", "simultaneously", "optimized", "at", "Eq", "12", "?", "The", "authors", "should", "clarify", "this", "point", ".", "-LRB-", "5", "-RRB-", "Due", "to", "the", "mean", "policy", "approximation", ",", "does", "the", "mean", "policy", "depend", "on", "\\", "phi", "?", "The", "authors", "should", "clearly", "explain", "how", "to", "update", "\\", "phi", "when", "optimizing", "Eq", "12", ".", "-LRB-", "6", "-RRB-", "If", "the", "authors", "jointly", "and", "simultaneously", "optimize", "\\", "theta", "and", "\\", "phi", ",", "why", "a", "regularization", "term", "about", "q", "_", "-LCB-", "\\", "phi", "-RCB-", "-LRB-", "z", "-RRB-", "is", "missing", "in", "Eq", "12", "while", "a", "regularization", "term", "about", "\\", "pi", "_", "-LCB-", "\\", "theta", "|", "z", "-RCB-", "does", "appear", "in", "Eq", "12", "?", "-LRB-", "7", "-RRB-", "The", "authors", "give", "the", "derivations", "about", "\\", "theta", "such", "as", "the", "gradient", "and", "the", "regularization", "term", "about", "\\", "theta", "-LRB-", "see", ",", "Eq", "18-19", "-RRB-", ".", "However", ",", "the", "derivations", "about", "\\", "phi", "are", "missing", ".", "For", "example", ",", "how", "to", "compute", "the", "gradient", "w.r.t.", "\\", "phi", "?", "Since", "the", "mean", "policy", "is", "used", ",", "it", "is", "not", "apparent", "that", "how", "to", "compute", "the", "gradient", "w.r.t.", "\\", "phi", ".", "Minor", ",", "1/2", "is", "missing", "in", "the", "last", "line", "of", "Eq", "19", ".", "Reference", ":", "-LSB-", "1", "-RSB-", "AUEB", ",", "Michalis", "Titsias", "RC", ",", "and", "Miguel", "Lzaro-Gredilla", ".", "TICKTICK", "Local", "expectation", "gradients", "for", "black", "box", "variational", "inference", ".", "''", "In", "Advances", "in", "neural", "information", "processing", "systems", ",", "pp.", "2638-2646", ".", "2015", ".", "Thank", "your", "very", "much", "for", "your", "review", ".", "We", "have", "updated", "the", "manuscript", "with", "more", "details", "in", "the", "derivation", "of", "the", "first", "order", "approximation", "of", "KL", "divergence", ".", "1", "-RRB-", "Elaborated", "derivation", "of", "Eq", ".", "10", "Q1", ":", "We", "have", "added", "one", "more", "line", "to", "explain", "the", "derivation", ".", "Basically", "a", "baseline", "is", "subtracted", ",", "and", "GAE", "is", "introduced", ".", "2", "-RRB-", "Gradient", "update", "on", "\\", "phi", "from", "KL", "divergence", "The", "gradients", "w.r.t.", "\\", "phi", "from", "the", "KL", "divergence", "is", "stopped", "for", "variance", "reduction", "with", "acceptable", "bias", ",", "which", "we", "prove", "with", "MuProp", "-LSB-", "1", "-RSB-", ".", "Details", "could", "be", "found", "in", "Appendix", "C.", "Q3", ":", "Rather", "than", "-LSB-", "2", "-RSB-", ",", "we", "employ", "MuProp", "to", "reduce", "variance", "in", "our", "development", "of", "NADPEx", ".", "Thank", "your", "for", "your", "suggestion", ".", "Q4", ":", "Yes", "\\", "theta", "and", "\\", "phi", "are", "jointly", "and", "simultaneously", "optimized", "at", "Eq", ".", "12", ",", "though", "the", "gradients", "w.r.t.", "\\", "phi", "from", "the", "KL", "divergence", "is", "stopped", ".", "Q7", ":", "Due", "to", "the", "stop-gradient", "manipulation", "in", "the", "KL", "divergence", ",", "gradients", "w.r.t.", "\\", "phi", "remains", "the", "same", "as", "in", "stated", "in", "last", "subsection", ".", "3", "-RRB-", "Mean", "policy", "in", "the", "KL", "divergence", "What", "motivates", "the", "mean", "policy", "is", "not", "variance", "reduction", ",", "but", "the", "idea", "that", "dropout", "policy", "had", "better", "to", "be", "close", "to", "each", "other", ".", "As", "intuitively", "\\", "phi", "is", "controlling", "the", "distance", "between", "dropout", "policies", ",", "it", "would", "further", "remedy", "the", "little", "bias", "mentioned", "above", ".", "However", ",", "the", "computation", "complexity", "for", "TICKTICK", "close", "to", "each", "other", "''", "would", "be", "O", "-LRB-", "N", "^", "2", "-RRB-", ",", "with", "N", "being", "the", "number", "of", "dropout", "policies", "in", "this", "batch", ".", "We", "employ", "mean", "policy", "to", "make", "it", "linear", ".", "And", "it", "could", "be", "regarded", "as", "an", "integration", "on", "a", "Gaussian", "approximation", "of", "the", "Monte", "Carlo", "estimate", "according", "to", "-LSB-", "3", "-RSB-", ".", "Details", "could", "be", "found", "in", "Appendix", "C.", "Q2", ":", "No", "the", "mean", "policy", "is", "not", "used", "due", "to", "the", "likelihood", "ratio", "trick", ".", "And", "the", "approximation", "of", "using", "mean", "policy", "is", "discussed", "in", "-LSB-", "3", "-RSB-", ",", "with", "a", "sound", "deduction", ".", "Q3", ":", "Mean", "policy", "is", "not", "motivated", "by", "variance", "reduction", ",", "which", "is", "addressed", "as", "introduced", "above", ".", "Thank", "you", "for", "your", "suggestion", ".", "Q5", ":", "In", "the", "updated", "version", ",", "we", "have", "explicitly", "pointed", "out", "that", "the", "gradients", "w.r.t.", "\\", "phi", "from", "KL", "divergence", "is", "stopped", ".", "Thanks", "for", "this", "suggestion", ".", "Hope", "our", "response", "addresses", "your", "concerns", "!", "-LSB-", "1", "-RSB-", "Gu", "et", "al.", ",", "TICKTICK", "MuProp", ":", "Unbiased", "Backpropagation", "for", "Stochastic", "Neural", "Networks", "''", ",", "ICLR", "2016", ".", "-LSB-", "2", "-RSB-", "Titsias", "et", "al.", ",", "TICKTICK", "Local", "Expectation", "Gradients", "for", "Black", "Box", "Variational", "Inference", "''", ",", "NIPS", "2015", ".", "-LSB-", "3", "-RSB-", "Wang", "et", "al.", ",", "TICKTICK", "Fast", "dropout", "training", "''", ",", "ICML", "2013", ".", "TICKTICK", "Q4", ":", "Yes", "\\", "theta", "and", "\\", "phi", "are", "jointly", "and", "simultaneously", "optimized", "at", "Eq", ".", "12", ",", "though", "the", "gradients", "w.r.t.", "\\", "phi", "from", "the", "KL", "divergence", "is", "stopped", ".", "Q7", ":", "Due", "to", "the", "stop-gradient", "manipulation", "in", "the", "KL", "divergence", ",", "gradients", "w.r.t.", "\\", "phi", "remains", "the", "same", "as", "in", "stated", "in", "last", "subsection", ".", "''", "My", "guess", "is", "that", "due", "to", "the", "stop-gradient", "manipulation", ",", "\\", "phi", "remains", "the", "same", "when", "optimizing", "Eq", "12", ".", "In", "other", "words", ",", "\\", "phi", "is", "not", "updated", ".", "Is", "it", "correct", "?", "Can", "the", "authors", "comment", "on", "this", "?", "As", "explained", "in", "our", "last", "response", ",", "\\", "phi", "is", "still", "updated", "with", "gradients", "from", "surrogate", "loss", "i.e.", "Eq", ".", "10", "and", "Eq", ".", "11", ".", "Note", "that", "if", "there", "was", "stop", "gradient", "operation", ",", "there", "would", "be", "two", "streams", "of", "gradients", "in", "NADPEx", "when", "a", "KL", "regularizer", "is", "added", ":", "one", "from", "surrogate", "loss", ",", "another", "one", "from", "KL", "divergence", ".", "We", "only", "stop", "gradients", "w.r.t.", "\\", "phi", "from", "the", "KL", "divergence", ".", "''", "\\", "phi", "is", "not", "updated", "''", "means", "gradients", "from", "surrogate", "loss", "are", "also", "stopped", ".", "Actually", "in", "our", "paper", ",", "it", "is", "referred", "to", "as", "bootstrap", ",", "named", "with", "BootstrapDQN", "-LSB-", "1", "-RSB-", ",", "for", "which", "we", "provided", "a", "comparison", "with", "NADPEx", "in", "Section", "4.3", ".", "-LSB-", "1", "-RSB-", "Osband", "et", "al.", ",", "TICKTICK", "Deep", "exploration", "via", "bootstrapped", "dqn", "''", ",", "NIPS", "2016", "."], "comment_id": "B1e3qRw3p7"}, {"rels": [[0, 38, 38, 44, "elaboration"], [0, 44, 44, 58, "elaboration"], [0, 58, 58, 1934, "elaboration"], [58, 65, 65, 1934, "elaboration"], [65, 79, 79, 1934, "elaboration"], [79, 90, 90, 142, "elaboration"], [90, 106, 106, 142, "elaboration"], [106, 109, 109, 142, "elaboration"], [109, 138, 138, 142, "elaboration"], [79, 142, 142, 1934, "elaboration"], [142, 149, 149, 154, "elaboration"], [142, 154, 154, 161, "elaboration"], [142, 161, 161, 175, "elaboration"], [142, 175, 175, 194, "elaboration"], [142, 194, 194, 355, "elaboration"], [194, 196, 196, 229, "elaboration"], [196, 222, 222, 229, "same_unit"], [196, 208, 208, 222, "elaboration"], [222, 229, 196, 222, "same_unit"], [222, 223, 223, 229, "elaboration"], [194, 229, 229, 355, "elaboration"], [229, 236, 236, 241, "elaboration"], [229, 241, 241, 277, "elaboration"], [241, 261, 261, 277, "contrast"], [241, 248, 248, 261, "circumstance"], [261, 277, 241, 261, "contrast"], [265, 277, 261, 265, "attribution"], [229, 277, 277, 355, "elaboration"], [281, 311, 277, 281, "attribution"], [281, 296, 296, 311, "elaboration"], [277, 311, 311, 355, "elaboration"], [311, 325, 325, 355, "same_unit"], [311, 313, 313, 325, "elaboration"], [325, 355, 311, 325, "same_unit"], [325, 334, 334, 355, "elaboration"], [334, 341, 341, 355, "elaboration"], [341, 347, 347, 355, "elaboration"], [142, 355, 355, 1934, "elaboration"], [355, 398, 398, 1934, "contrast"], [355, 380, 380, 398, "elaboration"], [398, 1934, 355, 398, "contrast"], [398, 426, 426, 434, "elaboration"], [398, 434, 434, 1934, "elaboration"], [434, 442, 442, 453, "elaboration"], [434, 453, 453, 1934, "example"], [453, 473, 473, 484, "same_unit"], [453, 467, 467, 473, "elaboration"], [473, 484, 453, 473, "same_unit"], [473, 479, 479, 484, "elaboration"], [453, 484, 484, 1934, "elaboration"], [489, 524, 484, 489, "attribution"], [489, 499, 499, 524, "purpose"], [484, 524, 524, 545, "elaboration"], [484, 545, 545, 1934, "elaboration"], [545, 555, 555, 1934, "elaboration"], [555, 557, 557, 568, "elaboration"], [557, 559, 559, 568, "elaboration"], [555, 568, 568, 1934, "elaboration"], [568, 584, 584, 1934, "topic"], [568, 579, 579, 584, "elaboration"], [584, 1934, 568, 584, "topic"], [590, 616, 584, 590, "attribution"], [584, 616, 616, 1934, "explanation"], [623, 640, 616, 623, "attribution"], [623, 630, 630, 640, "elaboration"], [630, 634, 634, 640, "elaboration"], [616, 640, 640, 707, "elaboration"], [642, 664, 640, 642, "attribution"], [642, 656, 656, 664, "list"], [656, 664, 642, 656, "list"], [640, 664, 664, 707, "explanation"], [664, 672, 672, 680, "concession"], [664, 680, 680, 707, "elaboration"], [680, 692, 692, 707, "elaboration"], [692, 693, 693, 707, "elaboration"], [693, 696, 696, 707, "elaboration"], [616, 707, 707, 851, "elaboration"], [707, 717, 717, 851, "elaboration"], [717, 729, 729, 745, "same_unit"], [717, 725, 725, 729, "elaboration"], [725, 726, 726, 729, "elaboration"], [729, 745, 717, 729, "same_unit"], [717, 745, 745, 851, "elaboration"], [745, 759, 759, 763, "same_unit"], [745, 755, 755, 759, "elaboration"], [755, 756, 756, 759, "elaboration"], [759, 763, 745, 759, "same_unit"], [745, 763, 763, 851, "elaboration"], [763, 788, 788, 796, "same_unit"], [763, 784, 784, 788, "elaboration"], [788, 796, 763, 788, "same_unit"], [763, 796, 796, 851, "elaboration"], [796, 800, 800, 804, "elaboration"], [796, 804, 804, 851, "elaboration"], [807, 851, 804, 807, "attribution"], [807, 814, 814, 829, "list"], [814, 829, 807, 814, "list"], [807, 829, 829, 851, "elaboration"], [829, 841, 841, 851, "elaboration"], [844, 851, 841, 844, "attribution"], [616, 851, 851, 1934, "elaboration"], [878, 893, 851, 878, "attribution"], [851, 893, 893, 904, "elaboration"], [851, 904, 904, 1934, "elaboration"], [908, 928, 904, 908, "attribution"], [908, 914, 914, 928, "purpose"], [914, 920, 920, 928, "purpose"], [904, 928, 928, 1934, "elaboration"], [928, 940, 940, 969, "same_unit"], [928, 932, 932, 940, "elaboration"], [940, 969, 928, 940, "same_unit"], [940, 959, 959, 969, "elaboration"], [928, 969, 969, 1934, "elaboration"], [972, 999, 969, 972, "attribution"], [983, 999, 972, 983, "condition"], [969, 999, 999, 1022, "elaboration"], [969, 1022, 1022, 1934, "elaboration"], [1022, 1039, 1039, 1934, "elaboration"], [1039, 1041, 1041, 1934, "textualorganization"], [1041, 1934, 1039, 1041, "textualorganization"], [1041, 1052, 1052, 1056, "elaboration"], [1041, 1056, 1056, 1934, "elaboration"], [1056, 1074, 1074, 1934, "elaboration"], [1076, 1105, 1074, 1076, "attribution"], [1077, 1105, 1076, 1077, "attribution"], [1077, 1099, 1099, 1105, "elaboration"], [1074, 1105, 1105, 1934, "elaboration"], [1105, 1123, 1123, 1934, "list"], [1105, 1118, 1118, 1123, "list"], [1118, 1123, 1105, 1118, "list"], [1123, 1934, 1105, 1123, "list"], [1123, 1125, 1125, 1934, "list"], [1125, 1934, 1123, 1125, "list"], [1125, 1141, 1141, 1934, "list"], [1125, 1127, 1127, 1141, "means"], [1141, 1934, 1125, 1141, "list"], [1143, 1934, 1141, 1143, "attribution"], [1143, 1151, 1151, 1934, "elaboration"], [1151, 1180, 1180, 1934, "elaboration"], [1180, 1214, 1214, 1934, "list"], [1180, 1190, 1190, 1214, "elaboration"], [1214, 1934, 1180, 1214, "list"], [1214, 1226, 1226, 1934, "topic"], [1214, 1216, 1216, 1226, "list"], [1216, 1226, 1214, 1216, "list"], [1216, 1217, 1217, 1218, "elaboration"], [1216, 1218, 1218, 1226, "elaboration"], [1218, 1221, 1221, 1226, "elaboration"], [1226, 1934, 1214, 1226, "topic"], [1226, 1236, 1236, 1934, "elaboration"], [1236, 1249, 1249, 1934, "elaboration"], [1249, 1265, 1265, 1288, "elaboration"], [1249, 1288, 1288, 1934, "elaboration"], [1288, 1303, 1303, 1312, "elaboration"], [1288, 1312, 1312, 1400, "elaboration"], [1312, 1323, 1323, 1400, "elaboration"], [1323, 1337, 1337, 1343, "elaboration"], [1323, 1343, 1343, 1400, "elaboration"], [1343, 1348, 1348, 1400, "elaboration"], [1348, 1357, 1357, 1400, "elaboration"], [1357, 1375, 1375, 1400, "elaboration"], [1375, 1380, 1380, 1400, "elaboration"], [1288, 1400, 1400, 1934, "elaboration"], [1400, 1429, 1429, 1439, "same_unit"], [1400, 1406, 1406, 1429, "elaboration"], [1429, 1439, 1400, 1429, "same_unit"], [1400, 1439, 1439, 1934, "elaboration"], [1469, 1488, 1439, 1469, "attribution"], [1469, 1483, 1483, 1488, "same_unit"], [1469, 1476, 1476, 1483, "elaboration"], [1483, 1488, 1469, 1483, "same_unit"], [1439, 1488, 1488, 1934, "elaboration"], [1488, 1509, 1509, 1934, "elaboration"], [1509, 1524, 1524, 1934, "list"], [1516, 1524, 1509, 1516, "attribution"], [1516, 1518, 1518, 1524, "purpose"], [1524, 1934, 1509, 1524, "list"], [1524, 1547, 1547, 1934, "topic"], [1524, 1534, 1534, 1547, "elaboration"], [1534, 1536, 1536, 1547, "elaboration"], [1536, 1541, 1541, 1547, "elaboration"], [1547, 1934, 1524, 1547, "topic"], [1547, 1566, 1566, 1934, "question"], [1547, 1565, 1565, 1566, "same_unit"], [1547, 1559, 1559, 1565, "elaboration"], [1565, 1566, 1547, 1565, "same_unit"], [1566, 1934, 1547, 1566, "question"], [1566, 1584, 1584, 1934, "list"], [1566, 1575, 1575, 1584, "same_unit"], [1566, 1571, 1571, 1575, "elaboration"], [1575, 1584, 1566, 1575, "same_unit"], [1575, 1578, 1578, 1584, "list"], [1578, 1584, 1575, 1578, "list"], [1584, 1934, 1566, 1584, "list"], [1584, 1597, 1597, 1934, "list"], [1584, 1592, 1592, 1597, "attribution"], [1597, 1934, 1584, 1597, "list"], [1597, 1603, 1603, 1608, "list"], [1603, 1608, 1597, 1603, "list"], [1597, 1608, 1608, 1637, "elaboration"], [1608, 1615, 1615, 1620, "elaboration"], [1608, 1620, 1620, 1637, "elaboration"], [1621, 1637, 1620, 1621, "attribution"], [1621, 1632, 1632, 1637, "elaboration"], [1597, 1637, 1637, 1722, "elaboration"], [1637, 1643, 1643, 1670, "elaboration"], [1643, 1644, 1644, 1670, "circumstance"], [1644, 1650, 1650, 1670, "elaboration"], [1650, 1654, 1654, 1670, "elaboration"], [1654, 1655, 1655, 1670, "elaboration"], [1637, 1670, 1670, 1722, "elaboration"], [1686, 1722, 1670, 1686, "concession"], [1670, 1680, 1680, 1686, "elaboration"], [1688, 1722, 1686, 1688, "attribution"], [1688, 1700, 1700, 1722, "elaboration"], [1597, 1722, 1722, 1934, "elaboration"], [1724, 1752, 1722, 1724, "attribution"], [1726, 1752, 1724, 1726, "attribution"], [1726, 1741, 1741, 1752, "elaboration"], [1722, 1752, 1752, 1934, "elaboration"], [1752, 1809, 1809, 1934, "topic"], [1752, 1758, 1758, 1809, "elaboration"], [1758, 1767, 1767, 1790, "elaboration"], [1758, 1790, 1790, 1809, "elaboration"], [1790, 1797, 1797, 1809, "elaboration"], [1809, 1934, 1752, 1809, "topic"], [1809, 1835, 1835, 1843, "elaboration"], [1835, 1842, 1842, 1843, "purpose"], [1809, 1843, 1843, 1852, "elaboration"], [1809, 1852, 1852, 1934, "elaboration"], [1852, 1856, 1856, 1880, "elaboration"], [1856, 1859, 1859, 1880, "elaboration"], [1852, 1880, 1880, 1934, "elaboration"], [1880, 1891, 1891, 1912, "purpose"], [1893, 1912, 1891, 1893, "attribution"], [1893, 1904, 1904, 1912, "same_unit"], [1893, 1898, 1898, 1904, "elaboration"], [1904, 1912, 1893, 1904, "same_unit"], [1880, 1912, 1912, 1934, "elaboration"], [1912, 1922, 1922, 1934, "elaboration"]], "tokens": ["This", "paper", "presents", "a", "very", "interesting", "investigation", "of", "the", "expressive", "capabilities", "of", "graph", "neural", "networks", ",", "in", "particular", "focusing", "on", "the", "discriminative", "power", "of", "such", "GNN", "models", ",", "i.e.", "the", "ability", "to", "tell", "that", "two", "inputs", "are", "different", "when", "they", "are", "actually", "different", ".", "The", "analysis", "is", "based", "on", "the", "study", "of", "injective", "representation", "functions", "on", "multisets", ".", "This", "perspective", "in", "particular", "allows", "the", "authors", "to", "distinguish", "different", "aggregation", "methods", ",", "sum", ",", "mean", "and", "max", ",", "as", "well", "as", "to", "distinguish", "one", "layer", "linear", "transformations", "from", "multi-layer", "MLPs", ".", "Based", "on", "the", "analysis", "the", "authors", "proposed", "a", "variant", "of", "the", "GNN", "called", "Graph", "Isomorphism", "Networks", "-LRB-", "GINs", "-RRB-", "that", "use", "MLPs", "instead", "of", "linear", "transformations", "on", "each", "layer", ",", "and", "sum", "instead", "of", "mean", "or", "max", "as", "the", "aggregation", "method", ",", "which", "has", "the", "most", "discriminative", "power", "following", "the", "analysis", ".", "Experiments", "were", "done", "on", "node", "classification", "benchmarks", "to", "support", "the", "claims", ".", "Overall", "I", "quite", "liked", "this", "paper", ".", "The", "study", "of", "the", "expressive", "capabilities", "of", "GNNs", "is", "a", "very", "important", "problem", ".", "Given", "the", "popularity", "of", "this", "class", "of", "models", "recently", ",", "theoretical", "analysis", "for", "these", "models", "is", "largely", "missing", ".", "Previous", "attempts", "at", "studying", "the", "capability", "of", "GNNs", "focus", "on", "the", "function", "approximation", "perspective", "-LRB-", "e.g.", "Mapping", "Images", "to", "Scene", "Graphs", "with", "Permutation-Invariant", "Structured", "Prediction", "by", "Hertiz", "et", "al.", "which", "is", "worth", "discussing", "-RRB-", ".", "This", "paper", "presents", "a", "very", "different", "angle", "focusing", "on", "discriminative", "capabilities", ".", "Being", "able", "to", "tell", "two", "inputs", "apart", "when", "they", "are", "different", "is", "obviously", "just", "one", "aspect", "of", "representation", "power", ",", "but", "this", "paper", "showed", "that", "studying", "this", "aspect", "can", "already", "give", "us", "some", "interesting", "insights", ".", "I", "do", "feel", "however", "that", "the", "authors", "should", "make", "it", "clear", "that", "discriminative", "power", "is", "not", "the", "only", "thing", "we", "care", ",", "and", "in", "most", "applications", "we", "are", "not", "doing", "graph", "isomorphism", "tests", ".", "The", "ability", "to", "tell", ",", "for", "example", ",", "how", "far", "two", "inputs", "are", ",", "when", "they", "are", "not", "the", "same", "is", "also", "very", "-LRB-", "and", "maybe", "more", "-RRB-", "important", ",", "which", "such", "isomorphism", "/", "injective", "map", "based", "analysis", "does", "not", "capture", "at", "all", ".", "In", "fact", "the", "assumption", "that", "each", "feature", "vector", "can", "be", "mapped", "to", "a", "unique", "label", "in", "-LCB-", "a", ",", "b", ",", "c", ",", "...", "-RCB-", "-LRB-", "Section", "3", "first", "paragraph", "-RRB-", "is", "overly", "simplistic", "and", "only", "makes", "sense", "for", "analyzing", "injective", "maps", ".", "If", "we", "want", "to", "reason", "anything", "about", "the", "continuity", "of", "the", "features", "and", "representations", ",", "this", "assumption", "does", "not", "apply", ",", "and", "the", "real", "set", "is", "not", "countable", "so", "such", "a", "mapping", "can", "not", "exist", ".", "In", "equation", "4.1", "describes", "the", "GIN", "update", ",", "which", "is", "proposed", "as", "TICKTICK", "the", "most", "powerful", "GNN", "''", ".", "However", ",", "such", "architecture", "is", "not", "really", "new", ",", "for", "example", "the", "Interaction", "Networks", "-LRB-", "Battaglia", "et", "al.", "2016", "-RRB-", "already", "uses", "sum", "aggregation", "and", "MLP", "as", "the", "building", "blocks", ".", "Also", ",", "it", "is", "said", "that", "in", "the", "first", "iteration", "a", "simple", "sum", "is", "enough", "to", "implement", "injective", "map", ",", "this", "is", "true", "for", "sum", ",", "but", "replacing", "that", "with", "mean", "and", "max", "can", "lose", "information", "very", "early", "on", ".", "Another", "MLP", "on", "the", "input", "features", "at", "least", "for", "mean", "or", "max", "aggregation", "for", "the", "first", "iteration", "is", "therefore", "necessary", ".", "This", "is", "n't", "made", "very", "clear", "in", "the", "paper", ".", "The", "training", "set", "results", "presented", "in", "section", "6.1", "is", "not", "very", "clear", ".", "The", "plots", "show", "only", "one", "run", "for", "each", "model", "variant", ",", "which", "run", "was", "it", "?", "As", "the", "purpose", "is", "to", "show", "that", "some", "variants", "fit", "well", ",", "and", "some", "others", "overfit", ",", "these", "runs", "should", "be", "chosen", "to", "optimize", "training", "set", "performance", ",", "rather", "than", "generalization", ".", "Also", "the", "restrictions", "should", "be", "made", "clear", "that", "all", "models", "are", "given", "the", "same", "-LRB-", "small", "-RRB-", "amount", "of", "hidden", "units", "per", "node", ".", "I", "imagine", "if", "the", "amount", "of", "hidden", "units", "are", "allowed", "to", "be", "much", "bigger", ",", "mean", "and", "max", "aggregators", "should", "also", "catch", "up", ".", "As", "mentioned", "earlier", "I", "quite", "liked", "the", "paper", "despite", "some", "restrictions", "anc", "things", "to", "clarify", ".", "I", "would", "vote", "for", "accepting", "this", "paper", "for", "publication", "at", "ICLR", ".", "--------", "Considering", "the", "counter-example", "given", "above", ",", "I", "'m", "lowering", "my", "scores", "a", "bit", ".", "The", "proof", "of", "theorem", "3", "is", "less", "than", "clear", ".", "The", "proof", "for", "the", "first", "half", "of", "theorem", "3", "-LRB-", "a", "-RRB-", "is", "quite", "obvious", ",", "but", "the", "proof", "for", "the", "second", "half", "is", "a", "bit", "hand-wavy", ".", "In", "the", "worst", "case", ",", "the", "second", "half", "of", "theorem", "3", "-LRB-", "a", "-RRB-", "will", "be", "invalid", ".", "The", "most", "general", "GNN", "will", "then", "have", "to", "use", "an", "update", "function", "in", "the", "form", "of", "the", "first", "half", "of", "3", "-LRB-", "a", "-RRB-", ",", "and", "all", "the", "other", "analysis", "still", "holds", ".", "The", "experiments", "will", "need", "to", "be", "rerun", ".", "--------", "Update", ":", "the", "new", "revision", "resolved", "the", "counter-example", "issue", "and", "I", "'m", "mostly", "happy", "with", "it", ",", "so", "my", "rating", "was", "adjusted", "again", ".", "We", "thank", "the", "reviewer", "for", "the", "positive", "review", "and", "constructive", "feedback", "!", "We", "are", "glad", "that", "the", "reviewer", "likes", "our", "paper", ".", "First", ",", "we", "completely", "agree", "that", "the", "ability", "of", "GNNs", "to", "capture", "structural", "similarity", "of", "graphs", "is", "very", "important", "besides", "their", "discriminative", "power", ",", "and", "we", "believe", "this", "is", "one", "of", "the", "most", "important", "benefits", "of", "using", "GNNs", "over", "WL", "kernel", ".", "We", "have", "now", "made", "this", "point", "clearer", "in", "Section", "4", ".", "Furthermore", ",", "we", "emphasized", "that", "we", "do", "consider", "node", "features", "to", "lie", "in", "R", "^", "d", "so", "that", "they", "can", "capture", "the", "similarity", ".", "The", "subtlety", "is", "that", "-LRB-", "as", "R1", "nicely", "pointed", "out", "-RRB-", ",", "we", "need", "a", "common", "assumption", "that", "node", "features", "at", "each", "layer", "are", "from", "countable", "set", "in", "R", "^", "d", "-LRB-", "not", "from", "the", "entire", "R", "^", "d", "-RRB-", ".", "This", "is", "satisfied", "if", "the", "input", "node", "features", "are", "from", "a", "countable", "set", ",", "because", "for", "a", "graph", "neural", "network", ",", "countability", "propagates", "across", "all", "layers", "in", "a", "GNN", ".", "We", "leave", "uncountable", "node", "input", "features", "for", "future", "work", "and", "add", "a", "more", "detailed", "discussion", "in", "Section", "4", "of", "the", "revised", "paper", ".", "In", "the", "following", ",", "we", "respond", "to", "R3", "'s", "other", "helpful", "comments", "and", "suggestions", ":", "1", ".", "RE", ":", "Architecture", "is", "similar", "to", ",", "e.g.", ",", "Interaction", "Networks", "Thank", "you", "for", "the", "pointers", ".", "Some", "of", "our", "GIN", "'s", "building", "blocks", ",", "e.g.", "sum", "and", "MLP", "indeed", "appeared", "in", "other", "architectures", ".", "We", "emphasize", "that", "while", "previous", "work", "tend", "to", "be", "somewhat", "ad-hoc", "in", "designing", "GNN", "architectures", ",", "our", "main", "emphasis", "is", "on", "deriving", "our", "GIN", "architecture", "based", "on", "the", "theoretical", "motivation", ".", "In", "Section", "6", "of", "the", "revised", "version", ",", "we", "mention", "related", "GNN", "architectures", "and", "discuss", "the", "differences", ".", "2", ".", "RE", ":", "Using", "MLP", "for", "mean", "or", "max", "in", "the", "initial", "step", "is", "more", "fair", "?", "We", "think", "there", "might", "be", "a", "slight", "misunderstanding", "here", ":", "as", "we", "discussed", "with", "concrete", "examples", "in", "Section", "5.2", ",", "mean", "or", "max", "pooling", "are", "inherently", "incapable", "of", "capturing", "the", "multiset", "information", "regardless", "of", "the", "use", "of", "MLP", ".", "Especially", ",", "in", "our", "experiments", ",", "we", "use", "one-hot", "encodings", "as", "input", "node", "features", ",", "so", "the", "use", "of", "MLP", "on", "top", "of", "them", "does", "not", "increase", "the", "discriminative", "power", "of", "mean/max", "pooling", ".", "3", ".", "RE", ":", "Training", "set", "results", "optimized", "for", "test", "performance", "?", "The", "results", "were", "not", "actually", "optimized", "for", "test", "performance", ".", "Instead", ",", "we", "used", "exactly", "the", "same", "configurations", "for", "all", "the", "datasets", ":", "For", "all", "the", "GNNs", ",", "the", "same", "configurations", "were", "used", "across", "datasets", ":", "5", "GNN", "layers", "-LRB-", "including", "the", "input", "layer", "-RRB-", ",", "hidden", "units", "of", "size", "64", ",", "minibatch", "of", "size", "128", ",", "and", "0.5", "dropout", "ratio", ".", "For", "the", "WL", "subtree", "kernel", ",", "we", "set", "the", "number", "of", "iterations", "to", "4", ",", "which", "is", "comparable", "to", "the", "5", "GNN", "layers", ".", "We", "clarified", "this", "in", "Figure", "6", "of", "the", "revised", "paper", ".", "I", "thank", "the", "authors", "for", "the", "revision", "of", "the", "paper", "and", "the", "response", ".", "I", "have", "readjusted", "my", "rating", ".", "The", "solution", "to", "the", "question", "raised", "by", "the", "counter", "example", "in", "the", "new", "equation", "-LRB-", "4.1", "-RRB-", "is", "a", "technical", "one", ",", "I", "would", "rather", "prefer", "not", "to", "simplify", "the", "function", "g", "-LRB-", "c", ",", "X", "-RRB-", "which", "uses", "two", "functions", "phi", "and", "f", "in", "this", "form", ",", "as", "it", "really", "does", "n't", "buy", "us", "much", ".", "W.r.t.", "related", "work", ",", "the", "statement", "TICKTICK", "Not", "surprisingly", ",", "some", "building", "blocks", "of", "GIN", ",", "e.g.", "sum", "aggregation", "and", "MLP", "encoding", ",", "also", "appeared", "in", "other", "models", "''", "-LRB-", "section", "6", "-RRB-", "is", "not", "fair", "and", "misleading", ".", "As", "it", "is", "not", "the", "case", "that", "TICKTICK", "some", "building", "blocks", "''", "also", "appear", "in", "other", "models", ",", "but", "rather", "some", "other", "models", ",", "like", "interaction", "networks", ",", "already", "contains", "TICKTICK", "all", "''", "the", "essential", "building", "blocks", "-LRB-", "sum", ",", "MLP", ",", "etc.", "-RRB-", "presented", "in", "this", "paper", ".", "This", "does", "n't", "undermine", "the", "theoretical", "contribution", "of", "this", "paper", ",", "but", "the", "authors", "should", "be", "fair", "to", "previous", "work", ".", "Thank", "you", "for", "the", "encouraging", "review", "!", "We", "respond", "to", "your", "further", "comments", "below", ".", "1", "-RRB-", "We", "probably", "do", "not", "fully", "understand", "your", "comment", "regarding", "Eqn", "-LRB-", "4.1", "-RRB-", "and", "g", "-LRB-", "c", ",", "X", "-RRB-", ".", "Especially", ",", "could", "you", "please", "clarify", "your", "meaning", "of", "TICKTICK", "simplify", "g", "-LRB-", "c", ",", "X", "-RRB-", "''", "?", "In", "our", "GIN", "in", "Eqn", "-LRB-", "4.1", "-RRB-", ",", "we", "compose", "phi", "and", "f", "in", "Corollary", "6", ".", "2", "-RRB-", "We", "will", "further", "edit", "related", "work", "according", "to", "your", "suggestions", ".", "Interaction", "Networks", "is", "a", "great", "work", "and", "we", "like", "it", ".", "What", "I", "meant", "was", ",", "in", "g", "-LRB-", "c", ",", "X", "-RRB-", "you", "have", "two", "functions", "phi", "and", "f", ",", "which", "is", "the", "form", "required", "by", "Theorem", "3", ".", "The", "problem", "of", "the", "counter-example", "comes", "in", "when", "you", "used", "a", "single", "function", "instead", "of", "2", "functions", ",", "which", "ignores", "the", "difference", "between", "the", "node", "at", "the", "center", "and", "all", "its", "neighbors", ".", "Introducing", "an", "epsilon", "is", "a", "technical", "solution", "to", "this", "problem", "-LRB-", "in", "my", "opinion", "-RRB-", ",", "I", "think", "you", "actually", "do", "n't", "need", "this", "because", "the", "original", "form", "of", "g", "-LRB-", "c", ",", "X", "-RRB-", "is", "enough", ",", "and", "using", "a", "single", "function", "rather", "than", "2", "does", "not", "save", "you", "much", ".", "Note", ":", "I", "think", "of", "phi", "and", "f", "as", "MLPs", ",", "''", ",", "''", "as", "concat", ",", "and", "''", "-LCB-", "-RCB-", "''", "as", "some", "aggregation", "operator", ",", "like", "sum", ".", "Thank", "you", "for", "the", "clarification", ".", "We", "would", "like", "to", "first", "clarify", "that", "the", "letters", "-LRB-", "phi", ",", "f", "-RRB-", "in", "Corollary", "6", "and", "Theorem", "3", "do", "not", "have", "direct", "correspondence", ";", "but", "we", "can", "easily", "rearrange", "Eqn", "-LRB-", "4.1", "-RRB-", "to", "obtain", "the", "corresponding", "-LRB-", "phi", ",", "f", "-RRB-", "in", "the", "form", "of", "Theorem", "3", ".", "Intuitively", ",", "what", "Theorem", "3", "asks", "for", "is", "to", "injectively", "represent", "a", "pair", "of", "a", "node", "and", "its", "neighbors", ",", "so", "the", "injective", "function", ",", "g", "-LRB-", "c", ",", "X", "-RRB-", ",", "corresponds", "to", "-LRB-", "phi", ",", "f", "-RRB-", "in", "Theorem", "3", ".", "Furthermore", ",", "our", "motivation", "for", "designing", "Eqn", "-LRB-", "4.1", "-RRB-", ",", "i.e.", "GIN-0", "and", "GIN-eps", ",", "rather", "than", "simply", "applying", "concatenation", ",", "is", "for", "better", "empirical", "performance", ".", "In", "our", "preliminary", "experiments", ",", "we", "found", "such", "concatenation", "was", "harder", "to", "train", "compared", "to", "our", "simple", "GINs", "-LRB-", "both", "GIN-0", "and", "GIN-eps", "-RRB-", "and", "achieved", "lower", "test", "accuracy", "than", "GINs", ".", "The", "simplicity", "of", "GINs", "brings", "better", "performance", "in", "practice", ".", "We", "leave", "the", "extensive", "investigation", "and", "comparison", "to", "our", "future", "work", "."], "comment_id": "B1et5yXJ14"}, {"rels": [[0, 17, 17, 29, "condition"], [0, 29, 29, 264, "elaboration"], [29, 34, 34, 200, "elaboration"], [34, 39, 39, 200, "elaboration"], [39, 47, 47, 75, "elaboration"], [47, 52, 52, 75, "same_unit"], [52, 75, 47, 52, "same_unit"], [52, 65, 65, 75, "elaboration"], [65, 70, 70, 75, "list"], [70, 75, 65, 70, "list"], [39, 75, 75, 200, "elaboration"], [75, 91, 91, 200, "elaboration"], [91, 111, 111, 200, "elaboration"], [111, 144, 144, 200, "list"], [111, 125, 125, 144, "contrast"], [125, 144, 111, 125, "contrast"], [125, 126, 126, 144, "manner"], [144, 200, 111, 144, "list"], [144, 150, 150, 175, "elaboration"], [157, 175, 150, 157, "purpose"], [157, 164, 164, 175, "elaboration"], [144, 175, 175, 200, "elaboration"], [175, 180, 180, 200, "purpose"], [180, 193, 193, 200, "elaboration"], [29, 200, 200, 264, "elaboration"], [200, 209, 209, 231, "list"], [200, 206, 206, 209, "elaboration"], [209, 231, 200, 209, "list"], [211, 231, 209, 211, "attribution"], [211, 215, 215, 231, "elaboration"], [200, 231, 231, 264, "elaboration"], [231, 235, 235, 264, "elaboration"], [235, 241, 241, 264, "elaboration"], [241, 247, 247, 264, "list"], [247, 264, 241, 247, "list"], [247, 258, 258, 264, "elaboration"], [0, 264, 264, 456, "elaboration"], [264, 305, 305, 320, "elaboration"], [264, 320, 320, 456, "elaboration"], [320, 360, 360, 456, "list"], [320, 325, 325, 360, "reason"], [325, 351, 351, 360, "list"], [325, 339, 339, 351, "elaboration"], [351, 360, 325, 351, "list"], [360, 456, 320, 360, "list"], [360, 366, 366, 369, "elaboration"], [360, 369, 369, 456, "elaboration"], [369, 380, 380, 456, "elaboration"], [380, 389, 389, 456, "elaboration"], [389, 394, 394, 456, "list"], [394, 456, 389, 394, "list"], [394, 405, 405, 456, "same_unit"], [394, 399, 399, 405, "elaboration"], [405, 456, 394, 405, "same_unit"], [408, 456, 405, 408, "attribution"], [408, 409, 409, 433, "elaboration"], [409, 422, 422, 433, "elaboration"], [408, 433, 433, 456, "elaboration"]], "tokens": ["This", "paper", "presents", "and", "empirical", "and", "theoretical", "study", "of", "the", "convergence", "of", "asynchronous", "stochastic", "gradient", "descent", "training", "if", "there", "are", "delays", "due", "to", "the", "asynchronous", "part", "of", "it", ".", "The", "paper", "can", "be", "neatly", "split", "in", "two", "parts", ":", "a", "simulation", "study", "and", "a", "theoretical", "analysis", ".", "The", "simulation", "study", "compares", ",", "under", "fixed", "hyperparameters", ",", "the", "behavior", "of", "distributed", "training", "under", "different", "simulated", "levels", "of", "delay", "on", "different", "problems", "and", "different", "model", "architectures", ".", "Overall", "the", "results", "are", "very", "interesting", ",", "but", "the", "simulation", "could", "have", "been", "more", "thorough", ".", "Specifically", ",", "the", "same", "hyperparameter", "values", "were", "used", "across", "batch", "sizes", "and", "across", "different", "values", "of", "the", "distributed", "delay", ".", "Some", "algorithms", "failed", "to", "converge", "under", "some", "settings", "and", "others", "experienced", "dramatic", "slowdowns", ",", "but", "without", "careful", "study", "of", "hyperparameters", "it", "'s", "hard", "to", "tell", "whether", "these", "behaviors", "are", "normal", "or", "outliers", ".", "Also", "it", "would", "have", "been", "interesting", "to", "see", "a", "recurrent", "architecture", "there", ",", "as", "I", "'ve", "heard", "much", "anecdotal", "evidence", "about", "the", "robustness", "of", "RNNs", "and", "LSTMs", "to", "asynchronous", "training", ".", "I", "strongly", "advise", "the", "authors", "to", "redo", "the", "experiments", "with", "some", "hyperparameter", "tuning", "for", "different", "levels", "of", "staleness", "to", "make", "these", "results", "more", "believable", ".", "The", "theoretical", "analysis", "identifies", "a", "quantity", "called", "gradient", "coherence", "and", "proves", "that", "a", "learning", "rate", "based", "on", "the", "coherence", "can", "lead", "to", "an", "optimal", "convergence", "rate", "even", "under", "asynchronous", "training", ".", "The", "proof", "is", "correct", "-LRB-", "I", "checked", "the", "major", "steps", "but", "not", "all", "details", "-RRB-", ",", "and", "it", "'s", "sufficiently", "different", "from", "the", "analysis", "of", "hogwild", "algorithms", "to", "be", "of", "independent", "interest", ".", "The", "paper", "also", "shows", "the", "empirical", "behavior", "of", "the", "gradient", "coherence", "statistic", "during", "model", "training", ";", "interestingly", "this", "seems", "to", "also", "explain", "the", "heuristic", "commonly", "believed", "that", "to", "make", "asynchronous", "training", "work", "one", "needs", "to", "slowly", "anneal", "the", "number", "of", "workers", "-LRB-", "coherence", "is", "much", "worse", "in", "the", "earlier", "than", "later", "phases", "of", "training", "-RRB-", ".", "This", "quantity", "is", "interesting", "also", "because", "it", "'s", "somewhat", "independent", "of", "the", "variance", "of", "the", "stochastic", "gradient", "across", "minibatches", "-LRB-", "it", "'s", "the", "time", "variance", ",", "in", "a", "way", "-RRB-", ",", "and", "further", "analysis", "might", "also", "show", "interesting", "results", ".", "LSTM", "is", "indeed", "an", "interesting", "piece", "to", "add", ".", "We", "have", "added", "new", "results", "on", "LSTMs", "in", "Appendix", "A.", "8", "--", "we", "vary", "the", "number", "of", "layers", "of", "LSTMs", "-LRB-", "see", "Figure", "13", "-RRB-", "and", "types", "of", "SGD", "algorithms", "-LRB-", "see", "Figure", "14", "-RRB-", ",", "and", "have", "observed", "that", "-LRB-", "1", "-RRB-", "staleness", "impacts", "deeper", "network", "variants", "more", "than", "shallower", "counterparts", ",", "which", "is", "consistent", "with", "our", "observation", "in", "CNNs", "and", "DNNs", ";", "-LRB-", "2", "-RRB-", "different", "algorithms", "respond", "to", "staleness", "differently", ",", "with", "SGD", "and", "Adam", "more", "robust", "to", "staleness", "than", "Momentum", "and", "RMSProp", "."], "comment_id": "B1e7cN_6RX"}, {"rels": [[0, 18, 18, 863, "topic"], [0, 7, 7, 8, "elaboration"], [0, 8, 8, 18, "elaboration"], [18, 863, 0, 18, "topic"], [18, 143, 143, 863, "topic"], [18, 39, 39, 50, "same_unit"], [18, 29, 29, 39, "elaboration"], [39, 50, 18, 39, "same_unit"], [40, 50, 39, 40, "attribution"], [49, 50, 40, 49, "attribution"], [18, 50, 50, 58, "elaboration"], [18, 58, 58, 143, "elaboration"], [58, 70, 70, 71, "elaboration"], [58, 71, 71, 78, "elaboration"], [58, 78, 78, 143, "elaboration"], [80, 97, 78, 80, "attribution"], [78, 97, 97, 143, "elaboration"], [108, 113, 97, 108, "attribution"], [97, 113, 113, 143, "elaboration"], [113, 115, 115, 121, "elaboration"], [115, 116, 116, 120, "elaboration"], [115, 120, 120, 121, "elaboration"], [113, 121, 121, 143, "elaboration"], [121, 129, 129, 143, "elaboration"], [129, 132, 132, 143, "elaboration"], [132, 137, 137, 143, "purpose"], [143, 863, 18, 143, "topic"], [143, 181, 181, 863, "list"], [143, 146, 146, 152, "elaboration"], [143, 152, 152, 181, "elaboration"], [152, 167, 167, 181, "same_unit"], [152, 159, 159, 167, "sequence"], [159, 167, 152, 159, "sequence"], [167, 181, 152, 167, "same_unit"], [167, 180, 180, 181, "same_unit"], [167, 171, 171, 180, "elaboration"], [171, 175, 175, 180, "elaboration"], [180, 181, 167, 180, "same_unit"], [181, 863, 143, 181, "list"], [181, 189, 189, 863, "textualorganization"], [189, 863, 181, 189, "textualorganization"], [189, 209, 209, 863, "same_unit"], [201, 209, 189, 201, "condition"], [209, 863, 189, 209, "same_unit"], [209, 219, 219, 863, "list"], [219, 863, 209, 219, "list"], [219, 240, 240, 863, "textualorganization"], [219, 224, 224, 230, "elaboration"], [219, 230, 230, 231, "elaboration"], [219, 231, 231, 240, "temporal"], [240, 863, 219, 240, "textualorganization"], [240, 243, 243, 863, "textualorganization"], [243, 863, 240, 243, "textualorganization"], [243, 255, 255, 863, "textualorganization"], [255, 863, 243, 255, "textualorganization"], [255, 268, 268, 863, "textualorganization"], [268, 863, 255, 268, "textualorganization"], [268, 316, 316, 863, "list"], [268, 284, 284, 316, "elaboration"], [284, 299, 299, 316, "purpose"], [299, 304, 304, 316, "attribution"], [316, 863, 268, 316, "list"], [316, 368, 368, 863, "list"], [322, 368, 316, 322, "attribution"], [322, 328, 328, 368, "elaboration"], [328, 338, 338, 368, "elaboration"], [338, 348, 348, 368, "contrast"], [348, 368, 338, 348, "contrast"], [348, 367, 367, 368, "same_unit"], [348, 361, 361, 367, "elaboration"], [367, 368, 348, 367, "same_unit"], [368, 863, 316, 368, "list"], [368, 373, 373, 390, "elaboration"], [373, 384, 384, 390, "list"], [384, 390, 373, 384, "list"], [368, 390, 390, 464, "elaboration"], [390, 404, 404, 417, "elaboration"], [390, 417, 417, 464, "elaboration"], [417, 422, 422, 428, "purpose"], [417, 428, 428, 464, "explanation"], [428, 435, 435, 454, "purpose"], [435, 438, 438, 454, "purpose"], [428, 454, 454, 464, "elaboration"], [454, 459, 459, 464, "elaboration"], [368, 464, 464, 863, "elaboration"], [470, 487, 464, 470, "antithesis"], [473, 487, 470, 473, "attribution"], [473, 486, 486, 487, "same_unit"], [473, 480, 480, 486, "elaboration"], [486, 487, 473, 486, "same_unit"], [464, 487, 487, 863, "elaboration"], [487, 521, 521, 863, "topic"], [487, 494, 494, 521, "purpose"], [494, 496, 496, 521, "means"], [496, 509, 509, 521, "elaboration"], [509, 510, 510, 521, "elaboration"], [521, 863, 487, 521, "topic"], [521, 528, 528, 557, "elaboration"], [528, 542, 542, 550, "elaboration"], [528, 550, 550, 557, "elaboration"], [521, 557, 557, 863, "elaboration"], [557, 565, 565, 580, "elaboration"], [565, 567, 567, 571, "purpose"], [565, 571, 571, 580, "concession"], [557, 580, 580, 863, "result"], [580, 594, 594, 863, "list"], [594, 863, 580, 594, "list"], [594, 604, 604, 605, "elaboration"], [594, 605, 605, 863, "elaboration"], [605, 606, 606, 863, "textualorganization"], [606, 863, 605, 606, "textualorganization"], [606, 822, 822, 863, "list"], [606, 626, 626, 822, "list"], [626, 822, 606, 626, "list"], [626, 630, 630, 643, "elaboration"], [630, 635, 635, 643, "elaboration"], [626, 643, 643, 822, "elaboration"], [643, 654, 654, 822, "list"], [643, 648, 648, 654, "purpose"], [648, 653, 653, 654, "elaboration"], [654, 822, 643, 654, "list"], [654, 656, 656, 662, "elaboration"], [656, 659, 659, 662, "elaboration"], [654, 662, 662, 822, "elaboration"], [662, 684, 684, 822, "list"], [662, 668, 668, 684, "purpose"], [684, 822, 662, 684, "list"], [684, 704, 704, 822, "list"], [704, 822, 684, 704, "list"], [704, 717, 717, 822, "list"], [717, 822, 704, 717, "list"], [717, 719, 719, 822, "list"], [719, 822, 717, 719, "list"], [719, 748, 748, 822, "list"], [719, 729, 729, 748, "list"], [729, 748, 719, 729, "list"], [729, 741, 741, 748, "elaboration"], [748, 822, 719, 748, "list"], [748, 750, 750, 822, "list"], [750, 822, 748, 750, "list"], [750, 769, 769, 822, "list"], [769, 822, 750, 769, "list"], [769, 771, 771, 822, "list"], [771, 822, 769, 771, "list"], [771, 792, 792, 801, "elaboration"], [771, 801, 801, 822, "elaboration"], [801, 812, 812, 822, "elaboration"], [822, 863, 606, 822, "list"], [822, 832, 832, 863, "list"], [832, 863, 822, 832, "list"], [832, 859, 859, 863, "list"], [844, 859, 832, 844, "attribution"], [844, 848, 848, 859, "elaboration"], [848, 854, 854, 859, "elaboration"], [859, 863, 832, 859, "list"]], "tokens": ["Overall", "I", "am", "positive", "about", "this", "manuscript", ":", "-", "I", "find", "the", "motivation", "is", "clear", "and", "valid", ".", "As", "far", "as", "I", "know", ",", "this", "is", "a", "novel", "contribution", "-LRB-", "my", "confidence", "is", "not", "very", "high", "on", "that", "one", "though", "-", "I", "might", "be", "unaware", "of", "related", "work", "-RRB-", ".", "-", "The", "paper", "is", "well-written", "and", "organized", ".", "-", "Experiments", "are", "conducted", "systematically", ",", "although", "certain", "parts", "could", "be", "better", "explained", "-LRB-", "see", "my", "questions", "below", "-RRB-", ".", "I", "think", "this", "paper", "adds", "an", "original", "and", "valuable", "angle", "to", "the", "existing", "literature", "on", "data", "poisoning", "attacks", ".", "I", "do", "n't", "see", "any", "major", "flaws", ",", "therefore", "I", "think", "it", "should", "be", "accepted", ".", "A", "few", "points", "which", "might", "need", "clarification", ":", "-", "How", "exactly", "is", "TICKTICK", "attack", "success", "''", "being", "measured", "?", "-", "Which", "model", "is", "used", "to", "generate", "the", "adversarial", "samples", "?", "Is", "this", "an", "-LRB-", "adversarially", "-RRB-", "pretrained", "model", "?", "-LRB-", "If", "that", "'s", "the", "case", ",", "then", "what", "is", "the", "model", "architecture", "?", "-RRB-", "Or", "are", "adversarial", "samples", "generated", "on", "the", "fly", "using", "the", "currently", "trained/poisoned", "model", "?", "-", "At", "the", "end", "of", "Section", "4.4", ":", "if", "the", "images", "with", "larger", "noise", "rely", "more", "on", "the", "backdoor", ",", "why", "does", "this", "have", "an", "adverse", "effect", "?", "Should", "n't", "it", "increase", "the", "effectiveness", "of", "the", "attack", "?", "-", "Was", "the", "data", "augmentation", "-LRB-", "flips", ",", "crops", "etc", "-RRB-", "performed", "before", "or", "after", "the", "poisoning", "pattern", "was", "applied", "?", "Minor", "comments", ":", "-", "definition", "of", "the", "encoding", "at", "the", "bottom", "of", "page", "4", ":", "this", "should", "be", "argmax", "instead", "of", "max", "-", "typo", "in", "Sec.", "5.1", ":", "TICKTICK", "to", "evaluate", "the", "uat", "a", "wide", "variety", "''", "-", "repetitive", "sentence", "in", "Sec.", "5.2", ":", "TICKTICK", "we", "find", "that", "images", "generated", "with", "$", "\\", "tau", "\\", "leq", "0.2", "$", "remain", "-LSB-", "fairly", "-RSB-", "plausible", "''", "We", "thank", "the", "reviewer", "for", "the", "kind", "comments", "and", "helpful", "suggestions", ".", "We", "will", "address", "points", "raised", "below", ":", "-", "The", "attack", "success", "rate", "-LRB-", "ASR", "-RRB-", "is", "computed", "as", "the", "fraction", "of", "inputs", "that", "are", "_", "not", "_", "labeled", "with", "the", "target", "class", "but", "are", "classified", "as", "the", "target", "class", "after", "the", "backdoor", "pattern", "is", "applied", "-LRB-", "Beginning", "of", "Section", "5", "-RRB-", ".", "We", "have", "edited", "the", "manuscript", "to", "make", "this", "definition", "appear", "more", "prominently", "earlier", "in", "the", "paper", "and", "edited", "the", "relevant", "captions", ".", "-", "We", "use", "adversarially", "trained", "models", "trained", "with", "the", "publicly", "available", "code", "from", "https://github.com/MadryLab/cifar10_challenge", "-LRB-", "we", "train", "the", "non-wide", "variant", "both", "with", "L2", "and", "Linf", "-RRB-", ".", "The", "adversarial", "examples", "are", "generated", "once", "using", "this", "pre-trained", "network", ".", "Since", "our", "threat", "model", "only", "allows", "us", "to", "add", "examples", "to", "the", "training", "set", ",", "we", "can", "not", "compute", "these", "adversarial", "perturbations", "on", "the", "fly", ".", "We", "have", "edited", "the", "manuscript", "to", "incorporate", "this", "discussion", ".", "-", "We", "were", "also", "surprised", "initially", "but", "we", "believe", "that", "there", "is", "a", "fairly", "simple", "explanation", "-LRB-", "outlined", "in", "Section", "4.4", "-RRB-", ".", "On", "noisy", "images", ",", "the", "classifier", "learns", "to", "predict", "by", "relying", "on", "the", "backdoor", "*", "in", "the", "absence", "of", "strong", "image", "signal", "*", "-LRB-", "since", "the", "salient", "image", "features", "are", "fairly", "corrupted", "-RRB-", ".", "However", ",", "when", "evaluated", "on", "the", "test", "set", "with", "a", "backdoor", "applied", ",", "the", "image", "itself", "will", "have", "a", "strong", "signal", "-LRB-", "since", "it", "will", "not", "be", "noisy", "-RRB-", "that", "can", "overcome", "the", "backdoor", "pattern", ".", "Therefore", ",", "it", "is", "necessary", "for", "the", "classifier", "to", "learn", "to", "predict", "the", "backdoor", "even", "when", "the", "salient", "image", "characteristics", "are", "present", ".", "As", "a", "result", ",", "random", "noise", "is", "not", "very", "effective", "at", "injecting", "backdoors", ".", "We", "have", "updated", "Section", "4.4", "to", "better", "reflect", "this", "argument", ".", "-", "Since", "we", "do", "not", "have", "access", "to", "the", "training", "procedure", ",", "the", "pattern", "is", "applied", "before", "any", "data", "augmentation", ".", "This", "is", "the", "reason", "why", "this", "setting", "is", "challenging", "--", "data", "augmentation", "might", "obscure", "the", "pattern", ".", "We", "have", "updated", "the", "manuscript", "to", "incorporate", "the", "other", "comments", ".", "Those", "answer", "all", "the", "questions", "I", "had", ".", "Dear", "AnonReviewer2", ",", "I", "am", "writing", "to", "bring", "your", "attention", "to", "my", "comments", "below", ",", "per", "the", "Area", "Chair", "'s", "request", ".", "In", "my", "opinion", ",", "this", "paper", "'s", "overarching", "idea", "is", "very", "interesting", "and", "yet", "the", "implementation", "could", "be", "improved", ".", "In", "particular", ",", "I", "had", "three", "major", "concerns", "in", "my", "initial", "review", ".", "1", ".", "This", "paper", "does", "not", "propose", "any", "new", "attack", "algorithms", ".", "Instead", ",", "it", "investigates", "an", "existing", "adversarial", "attack", "method", "and", "the", "GAN", "based", "interpolation", "for", "the", "backdoor", "attack", ".", "2", ".", "As", "experiments", "are", "conducted", "on", "small-scale", "datasets", ",", "it", "is", "unclear", "how", "effective", "the", "improved", "backdoor", "attack", "is", ".", "3", ".", "Moreover", ",", "one", "of", "the", "main", "disadvantages", "of", "the", "proposed", "attack", "method", "is", "that", "simple", "data", "augmentation", "techniques", ",", "especially", "random", "cropping", ",", "can", "successfully", "defend", "against", "the", "attack", ".", "The", "first", "two", "concerns", "were", "reinforced", "by", "the", "authors", "'", "responses", "-LRB-", "at", "least", "from", "my", "point", "of", "view", "-RRB-", ".", "The", "answer", "to", "the", "third", "concern", "is", "not", "convincing", ".", "My", "background", "is", "largely", "from", "computer", "vision", ",", "and", "I", "can", "think", "of", "many", "data", "augmentations", "to", "overcome", "the", "four-corner", "backdoor", "patterns", "studied", "in", "this", "paper", ".", "Best", "regards", ",", "AnonReviewer1"], "comment_id": "B1eHKRmEe4"}, {"rels": [[0, 6, 6, 23, "elaboration"], [0, 23, 23, 44, "elaboration"], [23, 31, 31, 44, "elaboration"], [0, 44, 44, 718, "elaboration"], [96, 718, 44, 96, "antithesis"], [44, 59, 59, 96, "elaboration"], [59, 78, 78, 96, "same_unit"], [59, 65, 65, 78, "elaboration"], [78, 96, 59, 78, "same_unit"], [78, 87, 87, 96, "elaboration"], [96, 108, 108, 125, "list"], [96, 104, 104, 108, "elaboration"], [108, 125, 96, 108, "list"], [96, 125, 125, 718, "elaboration"], [125, 131, 131, 718, "elaboration"], [160, 718, 131, 160, "antithesis"], [140, 160, 131, 140, "attribution"], [140, 155, 155, 160, "elaboration"], [160, 187, 187, 718, "list"], [160, 165, 165, 187, "same_unit"], [165, 187, 160, 165, "same_unit"], [165, 178, 178, 187, "circumstance"], [187, 718, 160, 187, "list"], [187, 202, 202, 228, "contrast"], [187, 197, 197, 202, "elaboration"], [202, 228, 187, 202, "contrast"], [202, 223, 223, 228, "elaboration"], [187, 228, 228, 718, "elaboration"], [228, 238, 238, 718, "list"], [228, 231, 231, 235, "elaboration"], [228, 235, 235, 238, "elaboration"], [238, 718, 228, 238, "list"], [238, 241, 241, 245, "elaboration"], [238, 245, 245, 251, "elaboration"], [238, 251, 251, 718, "elaboration"], [251, 252, 252, 257, "restatement"], [252, 253, 253, 257, "restatement"], [251, 257, 257, 260, "elaboration"], [251, 260, 260, 718, "elaboration"], [267, 312, 260, 267, "attribution"], [260, 263, 263, 267, "elaboration"], [268, 312, 267, 268, "attribution"], [268, 295, 295, 312, "elaboration"], [295, 307, 307, 312, "same_unit"], [295, 296, 296, 307, "restatement"], [307, 312, 295, 307, "same_unit"], [260, 312, 312, 718, "elaboration"], [312, 330, 330, 718, "list"], [330, 718, 312, 330, "list"], [330, 340, 340, 718, "list"], [340, 718, 330, 340, "list"], [340, 346, 346, 718, "list"], [346, 718, 340, 346, "list"], [346, 355, 355, 718, "list"], [355, 718, 346, 355, "list"], [355, 365, 365, 718, "condition"], [365, 383, 383, 718, "list"], [365, 372, 372, 375, "elaboration"], [365, 375, 375, 383, "purpose"], [383, 718, 365, 383, "list"], [383, 385, 385, 718, "list"], [385, 718, 383, 385, "list"], [385, 394, 394, 718, "elaboration"], [394, 405, 405, 409, "comparison"], [394, 409, 409, 718, "elaboration"], [409, 436, 436, 718, "list"], [409, 424, 424, 425, "same_unit"], [409, 414, 414, 424, "elaboration"], [414, 421, 421, 424, "elaboration"], [424, 425, 409, 424, "same_unit"], [409, 425, 425, 436, "purpose"], [436, 718, 409, 436, "list"], [436, 522, 522, 718, "topic"], [436, 438, 438, 522, "elaboration"], [438, 450, 450, 522, "elaboration"], [450, 456, 456, 470, "elaboration"], [450, 470, 470, 522, "elaboration"], [470, 482, 482, 522, "elaboration"], [482, 484, 484, 501, "elaboration"], [482, 501, 501, 522, "elaboration"], [501, 503, 503, 520, "elaboration"], [503, 511, 511, 520, "same_unit"], [503, 505, 505, 511, "elaboration"], [511, 520, 503, 511, "same_unit"], [511, 515, 515, 520, "list"], [515, 520, 511, 515, "list"], [501, 520, 520, 522, "elaboration"], [522, 718, 436, 522, "topic"], [522, 531, 531, 718, "textualorganization"], [531, 718, 522, 531, "textualorganization"], [531, 539, 539, 718, "condition"], [539, 547, 547, 718, "list"], [547, 718, 539, 547, "list"], [547, 549, 549, 565, "elaboration"], [549, 555, 555, 565, "reason"], [555, 560, 560, 561, "elaboration"], [555, 561, 561, 565, "means"], [547, 565, 565, 718, "elaboration"], [565, 579, 579, 593, "same_unit"], [565, 574, 574, 579, "elaboration"], [579, 593, 565, 579, "same_unit"], [579, 580, 580, 593, "elaboration"], [565, 593, 593, 718, "elaboration"], [593, 595, 595, 718, "elaboration"], [595, 629, 629, 718, "list"], [595, 606, 606, 629, "elaboration"], [606, 618, 618, 629, "elaboration"], [618, 625, 625, 629, "elaboration"], [629, 718, 595, 629, "list"], [629, 631, 631, 718, "explanation"], [631, 670, 670, 676, "elaboration"], [631, 676, 676, 718, "elaboration"], [676, 678, 678, 718, "elaboration"], [678, 691, 691, 718, "list"], [691, 718, 678, 691, "list"], [691, 693, 693, 718, "elaboration"], [695, 718, 693, 695, "attribution"]], "tokens": ["This", "paper", "proposed", "a", "mixed", "strategy", "to", "obtain", "better", "precision", "on", "robustness", "verifications", "of", "feed-forward", "neural", "networks", "with", "piecewise", "linear", "activation", "functions", ".", "The", "topic", "of", "robustness", "verification", "is", "important", ".", "The", "paper", "is", "well-written", "and", "the", "overview", "example", "is", "nice", "and", "helpful", ".", "The", "central", "idea", "of", "this", "paper", "is", "simple", "and", "the", "results", "can", "be", "expected", ":", "the", "authors", "combine", "several", "verification", "methods", "-LRB-", "the", "complete", "verifier", "MILP", ",", "the", "incomplete", "verifier", "LP", "and", "AI2", "-RRB-", "and", "thus", "achieve", "better", "precision", "compared", "with", "imcomplete", "verifiers", "while", "being", "more", "scalable", "than", "the", "complete", "verifiers", ".", "However", ",", "the", "verified", "networks", "are", "fairly", "small", "-LRB-", "1800", "neurons", "-RRB-", "and", "it", "is", "not", "clear", "how", "good", "the", "performance", "is", "compared", "to", "other", "state-of-the-art", "complete/incomplete", "verifiers", ".", "About", "experiments", "questions", ":", "1", ".", "The", "experiments", "compare", "verified", "robustness", "with", "AI2", "and", "show", "that", "RefineAI", "can", "verify", "more", "than", "AI2", "at", "the", "expense", "of", "much", "more", "computation", "time", "-LRB-", "Figure", "3", "-RRB-", ".", "However", ",", "the", "problem", "here", "is", "how", "is", "RefineAI", "or", "AI2", "compare", "with", "other", "complete", "and", "incomplete", "verifiers", "as", "described", "in", "the", "second", "paragraph", "of", "introduction", "?", "The", "AI2", "does", "not", "seem", "to", "have", "public", "available", "codes", "that", "readers", "can", "try", "out", "but", "for", "some", "complete", "and", "incomplete", "verifiers", "papers", "mentioned", "in", "the", "introductions", ",", "I", "do", "find", "some", "public", "codes", "available", ":", "*", "complete", "verifiers", "1", ".", "Tjeng", "&", "Tedrake", "-LRB-", "2017", "-RRB-", ":", "github.com/vtjeng/MIPVerify.jl", "2", ".", "SMT", "Katz", "etal", "-LRB-", "2017", "-RRB-", ":", "https://github.com/guykatzz/ReluplexCav2017", "*", "incomplete", "verifiers", "3", ".", "Weng", "etal", "-LRB-", "2018", "-RRB-", ":", "https://github.com/huanzhang12/CertifiedReLURobustness", "4", ".", "Wong", "&", "Kolter", "-LRB-", "2018", "-RRB-", ":", "http://github.com/locuslab/convex_adversarial", "How", "does", "Refine", "AI", "proposed", "in", "this", "paper", "compare", "with", "the", "above", "four", "papers", "in", "terms", "of", "the", "verified", "robustness", "percentage", "on", "test", "set", ",", "the", "robustness", "bound", "-LRB-", "the", "epsilon", "in", "the", "paragraph", "Abstract", "Interpretation", "p.", "4", "-RRB-", "and", "the", "run", "time", "?", "The", "verified", "robustness", "percentage", "of", "Tjeng", "&", "Tedrake", "is", "reported", "but", "the", "robustness", "bound", "is", "not", "reported", ".", "Also", ",", "can", "Refine", "AI", "scale", "to", "other", "datasets", "?", "About", "other", "questions", ":", "1", ".", "Can", "RefineAI", "handle", "only", "piece-wise", "linear", "activation", "functions", "?", "How", "about", "other", "activation", "functions", ",", "such", "as", "sigmoid", "?", "If", "so", ",", "what", "are", "the", "modifications", "to", "be", "made", "to", "handle", "other", "non-piece-wise", "linear", "activation", "functions", "?", "2", ".", "In", "Sec", "4", ",", "the", "Robustness", "properties", "paragraph", ".", "TICKTICK", "The", "adversarial", "attack", "considered", "here", "is", "untargeted", "and", "therefore", "stronger", "than", "...", "''", ".", "The", "approaches", "in", "Weng", "etal", "-LRB-", "2018", "-RRB-", "and", "Tjeng", "&", "Tedrake", "-LRB-", "2017", "-RRB-", "seem", "to", "be", "able", "to", "handle", "the", "untargeted", "robustness", "as", "well", "?", "3", ".", "In", "Sec", "4", ",", "the", "Effect", "of", "neural", "selection", "heuristic", "paragraph", ".", "TICKTICK", "Although", "the", "number", "of", "images", "verified", "change", "by", "only", "3", "%", "...", "produces", "tighter", "output", "bounds", "...", "''", ".", "How", "tight", "the", "output", "bounds", "improved", "by", "the", "neuron", "selection", "heuristics", "?", "Q1", ".", "The", "verified", "robustness", "percentage", "of", "Tjeng", "&", "Tedrake", "is", "reported", "but", "the", "robustness", "bound", "is", "not", ".", "R1", ".", "The", "epsilon", "considered", "for", "this", "experiment", "is", "reported", "-LRB-", "page", "7", "-RRB-", "and", "it", "is", "0.03", ".", "Q2", ".", "Can", "RefineAI", "handle", "only", "piecewise", "linear", "activation", "functions", "?", "How", "about", "other", "activations", "such", "as", "sigmoid", "?", "If", "so", ",", "what", "modifications", "are", "needed", "?", "R2", ".", "RefineAI", "provides", "better", "approximations", "for", "ReLU", "because", "it", "uses", "tighter", "bounds", "returned", "by", "MILP/LP", "solvers", ".", "Similarly", ",", "we", "can", "refine", "DeepZ", "approximations", "for", "sigmoid", "-LRB-", "which", "already", "exist", "-RRB-", "by", "using", "better", "bounds", "from", "a", "tighter", "approximation", ",", "e.g.", ",", "quadratic", "approximation", ".", "Q3", ".", "How", "is", "the", "verification", "problem", "affected", "by", "considering", "the", "untargeted", "attack", "as", "in", "this", "paper", "vs.", "the", "targeted", "attack", "in", "Weng", "et", "al", "-LRB-", "2018", "-RRB-", "and", "Tjeng", "&", "Tedrake", "-LRB-", "2017", "-RRB-", "?", "R3", ".", "Since", "the", "targeted", "attack", "is", "weaker", ",", "the", "complete", "verifier", "from", "Tjeng", "and", "Tedrake", "runs", "faster", "and", "the", "incomplete", "verifier", "from", "Weng", "et", "al.", "proves", "more", "properties", "in", "their", "respective", "evaluation", "than", "it", "would", "if", "they", "considered", "untargeted", "attacks", "as", "considered", "in", "this", "paper", ".", "Q4", ".", "How", "tight", "are", "the", "output", "bounds", "improved", "by", "the", "neuron", "selection", "heuristics", "?", "R4", ".", "We", "observed", "that", "the", "width", "of", "the", "interval", "for", "the", "correctly", "classified", "label", "is", "up", "to", "37", "%", "smaller", "with", "our", "neuron", "selection", "heuristic", "."], "comment_id": "B1eV9q7URm"}, {"rels": [[0, 217, 217, 1715, "topic"], [0, 6, 6, 26, "elaboration"], [6, 8, 8, 26, "purpose"], [8, 15, 15, 26, "means"], [0, 26, 26, 217, "elaboration"], [26, 49, 49, 217, "elaboration"], [49, 65, 65, 78, "elaboration"], [49, 78, 78, 217, "elaboration"], [78, 82, 82, 118, "elaboration"], [82, 102, 102, 118, "elaboration"], [102, 108, 108, 118, "purpose"], [78, 118, 118, 217, "elaboration"], [118, 138, 138, 156, "elaboration"], [138, 144, 144, 156, "same_unit"], [138, 139, 139, 144, "elaboration"], [144, 156, 138, 144, "same_unit"], [118, 156, 156, 217, "elaboration"], [156, 171, 171, 182, "elaboration"], [171, 173, 173, 182, "same_unit"], [171, 172, 172, 173, "elaboration"], [173, 182, 171, 173, "same_unit"], [156, 182, 182, 217, "elaboration"], [182, 187, 187, 217, "elaboration"], [189, 217, 187, 189, "attribution"], [189, 195, 195, 217, "list"], [195, 217, 189, 195, "list"], [195, 208, 208, 217, "elaboration"], [217, 1715, 0, 217, "topic"], [217, 244, 244, 1715, "list"], [217, 219, 219, 244, "example"], [219, 227, 227, 244, "elaboration"], [227, 241, 241, 244, "same_unit"], [227, 237, 237, 241, "elaboration"], [241, 244, 227, 241, "same_unit"], [244, 1715, 217, 244, "list"], [244, 254, 254, 273, "elaboration"], [254, 256, 256, 273, "elaboration"], [256, 263, 263, 273, "same_unit"], [256, 259, 259, 263, "attribution"], [263, 273, 256, 263, "same_unit"], [244, 273, 273, 1715, "elaboration"], [273, 301, 301, 1715, "elaboration"], [301, 320, 320, 1715, "textualorganization"], [301, 316, 316, 320, "same_unit"], [301, 302, 302, 303, "elaboration"], [301, 303, 303, 316, "elaboration"], [316, 320, 301, 316, "same_unit"], [320, 1715, 301, 320, "textualorganization"], [320, 330, 330, 1715, "list"], [320, 327, 327, 330, "elaboration"], [330, 1715, 320, 330, "list"], [330, 341, 341, 1715, "question"], [341, 1715, 330, 341, "question"], [342, 356, 341, 342, "attribution"], [342, 352, 352, 356, "temporal"], [341, 356, 356, 1715, "elaboration"], [357, 391, 356, 357, "attribution"], [364, 391, 357, 364, "attribution"], [368, 391, 364, 368, "attribution"], [377, 391, 368, 377, "attribution"], [356, 391, 391, 1715, "elaboration"], [391, 418, 418, 1715, "elaboration"], [419, 460, 418, 419, "attribution"], [418, 460, 460, 1715, "elaboration"], [460, 639, 639, 1715, "textualorganization"], [460, 485, 485, 639, "list"], [460, 464, 464, 485, "purpose"], [485, 639, 460, 485, "list"], [485, 510, 510, 639, "list"], [485, 495, 495, 510, "purpose"], [510, 639, 485, 510, "list"], [510, 514, 514, 530, "purpose"], [514, 517, 517, 530, "purpose"], [517, 525, 525, 530, "elaboration"], [510, 530, 530, 639, "elaboration"], [533, 557, 530, 533, "attribution"], [533, 539, 539, 557, "elaboration"], [539, 552, 552, 557, "elaboration"], [530, 557, 557, 639, "elaboration"], [561, 592, 557, 561, "attribution"], [562, 592, 561, 562, "attribution"], [566, 592, 562, 566, "attribution"], [569, 592, 566, 569, "attribution"], [569, 582, 582, 592, "purpose"], [557, 592, 592, 639, "elaboration"], [592, 598, 598, 605, "purpose"], [598, 601, 601, 605, "elaboration"], [592, 605, 605, 639, "elaboration"], [605, 611, 611, 639, "elaboration"], [611, 622, 622, 639, "list"], [622, 639, 611, 622, "list"], [622, 628, 628, 639, "elaboration"], [639, 1715, 460, 639, "textualorganization"], [639, 658, 658, 1715, "list"], [658, 1715, 639, 658, "list"], [658, 710, 710, 1715, "topic"], [659, 710, 658, 659, "attribution"], [659, 662, 662, 672, "elaboration"], [659, 672, 672, 710, "elaboration"], [673, 710, 672, 673, "attribution"], [673, 703, 703, 709, "elaboration"], [673, 709, 709, 710, "elaboration"], [710, 1715, 658, 710, "topic"], [710, 723, 723, 1715, "elaboration"], [723, 741, 741, 1715, "list"], [723, 737, 737, 741, "same_unit"], [723, 731, 731, 737, "elaboration"], [737, 741, 723, 737, "same_unit"], [741, 1715, 723, 741, "list"], [741, 747, 747, 755, "elaboration"], [741, 755, 755, 1715, "example"], [770, 796, 755, 770, "attribution"], [770, 792, 792, 796, "elaboration"], [755, 796, 796, 833, "elaboration"], [796, 832, 832, 833, "same_unit"], [796, 797, 797, 832, "condition"], [797, 812, 812, 832, "same_unit"], [797, 809, 809, 812, "elaboration"], [812, 832, 797, 812, "same_unit"], [812, 821, 821, 832, "elaboration"], [821, 826, 826, 832, "elaboration"], [832, 833, 796, 832, "same_unit"], [755, 833, 833, 1715, "elaboration"], [833, 837, 837, 1715, "textualorganization"], [837, 1715, 833, 837, "textualorganization"], [837, 881, 881, 1715, "textualorganization"], [838, 881, 837, 838, "attribution"], [881, 1715, 837, 881, "textualorganization"], [881, 1165, 1165, 1715, "textualorganization"], [881, 885, 885, 1165, "elaboration"], [885, 895, 895, 1165, "elaboration"], [895, 904, 904, 939, "list"], [904, 939, 895, 904, "list"], [905, 939, 904, 905, "attribution"], [911, 939, 905, 911, "attribution"], [914, 939, 911, 914, "attribution"], [914, 915, 915, 939, "means"], [915, 934, 934, 939, "purpose"], [895, 939, 939, 1165, "elaboration"], [939, 954, 954, 968, "contrast"], [941, 954, 939, 941, "attribution"], [941, 948, 948, 954, "same_unit"], [941, 943, 943, 948, "elaboration"], [948, 954, 941, 948, "same_unit"], [954, 968, 939, 954, "contrast"], [939, 968, 968, 1165, "elaboration"], [968, 1002, 1002, 1165, "list"], [968, 972, 972, 1002, "example"], [972, 982, 982, 1002, "same_unit"], [972, 977, 977, 982, "elaboration"], [982, 1002, 972, 982, "same_unit"], [982, 987, 987, 1002, "purpose"], [987, 994, 994, 1002, "circumstance"], [1002, 1165, 968, 1002, "list"], [1002, 1020, 1020, 1062, "textualorganization"], [1020, 1062, 1002, 1020, "textualorganization"], [1020, 1029, 1029, 1039, "elaboration"], [1020, 1039, 1039, 1062, "elaboration"], [1002, 1062, 1062, 1165, "elaboration"], [1062, 1086, 1086, 1165, "list"], [1062, 1066, 1066, 1086, "elaboration"], [1066, 1070, 1070, 1086, "elaboration"], [1070, 1079, 1079, 1083, "elaboration"], [1070, 1083, 1083, 1086, "elaboration"], [1086, 1165, 1062, 1086, "list"], [1086, 1100, 1100, 1165, "elaboration"], [1107, 1122, 1100, 1107, "attribution"], [1107, 1112, 1112, 1122, "elaboration"], [1100, 1122, 1122, 1165, "elaboration"], [1122, 1131, 1131, 1165, "elaboration"], [1131, 1147, 1147, 1165, "same_unit"], [1143, 1147, 1131, 1143, "attribution"], [1147, 1165, 1131, 1147, "same_unit"], [1147, 1161, 1161, 1165, "elaboration"], [1161, 1162, 1162, 1165, "elaboration"], [1162, 1164, 1164, 1165, "elaboration"], [1165, 1715, 881, 1165, "textualorganization"], [1165, 1188, 1188, 1715, "list"], [1181, 1188, 1165, 1181, "attribution"], [1188, 1715, 1165, 1188, "list"], [1188, 1210, 1210, 1715, "topic"], [1189, 1210, 1188, 1189, "attribution"], [1189, 1196, 1196, 1210, "same_unit"], [1196, 1210, 1189, 1196, "same_unit"], [1196, 1200, 1200, 1210, "list"], [1200, 1210, 1196, 1200, "list"], [1210, 1715, 1188, 1210, "topic"], [1210, 1217, 1217, 1226, "comparison"], [1210, 1226, 1226, 1232, "elaboration"], [1210, 1232, 1232, 1256, "elaboration"], [1236, 1256, 1232, 1236, "attribution"], [1237, 1256, 1236, 1237, "attribution"], [1210, 1256, 1256, 1286, "elaboration"], [1260, 1286, 1256, 1260, "attribution"], [1260, 1269, 1269, 1286, "same_unit"], [1260, 1264, 1264, 1269, "elaboration"], [1269, 1286, 1260, 1269, "same_unit"], [1210, 1286, 1286, 1487, "elaboration"], [1286, 1291, 1291, 1317, "elaboration"], [1291, 1307, 1307, 1317, "purpose"], [1286, 1317, 1317, 1341, "elaboration"], [1321, 1341, 1317, 1321, "attribution"], [1322, 1341, 1321, 1322, "attribution"], [1286, 1341, 1341, 1487, "elaboration"], [1345, 1371, 1341, 1345, "attribution"], [1345, 1354, 1354, 1371, "same_unit"], [1345, 1349, 1349, 1354, "elaboration"], [1354, 1371, 1345, 1354, "same_unit"], [1341, 1371, 1371, 1487, "example"], [1371, 1376, 1376, 1402, "elaboration"], [1376, 1392, 1392, 1402, "purpose"], [1371, 1402, 1402, 1487, "elaboration"], [1402, 1404, 1404, 1418, "same_unit"], [1402, 1403, 1403, 1404, "elaboration"], [1404, 1418, 1402, 1404, "same_unit"], [1408, 1418, 1404, 1408, "attribution"], [1402, 1418, 1418, 1487, "elaboration"], [1428, 1443, 1418, 1428, "attribution"], [1418, 1443, 1443, 1487, "elaboration"], [1443, 1458, 1458, 1470, "elaboration"], [1458, 1462, 1462, 1470, "elaboration"], [1443, 1470, 1470, 1487, "elaboration"], [1475, 1487, 1470, 1475, "attribution"], [1210, 1487, 1487, 1715, "elaboration"], [1487, 1497, 1497, 1519, "elaboration"], [1497, 1499, 1499, 1519, "elaboration"], [1506, 1519, 1499, 1506, "attribution"], [1506, 1509, 1509, 1519, "purpose"], [1487, 1519, 1519, 1715, "example"], [1519, 1539, 1539, 1561, "elaboration"], [1519, 1561, 1561, 1715, "elaboration"], [1561, 1575, 1575, 1715, "elaboration"], [1575, 1590, 1590, 1715, "elaboration"], [1590, 1618, 1618, 1715, "list"], [1590, 1593, 1593, 1618, "elaboration"], [1618, 1715, 1590, 1618, "list"], [1618, 1630, 1630, 1715, "list"], [1618, 1620, 1620, 1630, "elaboration"], [1630, 1715, 1618, 1630, "list"], [1630, 1640, 1640, 1715, "list"], [1630, 1634, 1634, 1640, "elaboration"], [1640, 1715, 1630, 1640, "list"], [1640, 1655, 1655, 1715, "list"], [1655, 1715, 1640, 1655, "list"], [1655, 1675, 1675, 1715, "list"], [1655, 1665, 1665, 1675, "elaboration"], [1665, 1670, 1670, 1675, "elaboration"], [1675, 1715, 1655, 1675, "list"], [1675, 1683, 1683, 1715, "list"], [1675, 1679, 1679, 1683, "elaboration"], [1683, 1715, 1675, 1683, "list"], [1683, 1692, 1692, 1715, "list"], [1692, 1715, 1683, 1692, "list"], [1692, 1699, 1699, 1715, "elaboration"]], "tokens": ["This", "is", "a", "well", "written", "paper", "which", "proposes", "to", "learn", "heteroscedastic", "noise", "models", "from", "data", "by", "optimizing", "the", "prediction", "likelihood", "end-to-end", "through", "differentiable", "Bayesian", "Filters", ".", "In", "addition", "to", "existing", "Bayesian", "filters", ",", "the", "paper", "also", "proposes", "two", "different", "versions", "of", "the", "-LSB-", "differentiable", "-RSB-", "Unscented", "Kalman", "Filter", ".", "Performance", "of", "the", "different", "filters", "and", "noise", "models", "is", "evaluated", "on", "two", "real-world", "robotic", "problems", ":", "Visual", "Odometry", "and", "visual", "tracking", "of", "an", "object", "pushed", "by", "the", "robot", ".", "While", "the", "general", "idea", "of", "learning", "the", "noise", "variances", "through", "backpropagation", "are", "straightforward", "extensions", "of", "existing", "work", "on", "differential", "Bayesian", "filters", ",", "the", "questions", "that", "the", "paper", "explores", "are", "important", "to", "make", "end-to-end", "learning", "of", "Bayesian", "filter", "more", "common", ".", "The", "results", "will", "help", "future", "research", "select", "the", "correct", "differential", "filter", "for", "their", "use", "case", ",", "and", "insight", "in", "potential", "benefits", "-LRB-", "or", "lack", "thereof", "-RRB-", "by", "learning", "heteroscedastic", "or", "homoscedastic", "process", "noise", ",", "and/or", "observation", "noise", ".", "A", "downside", "is", "that", "the", "paper", "does", "not", "further", "explore", "how", "to", "weigh", "different", "loss", "terms", "which", "are", "apparently", "important", "to", "successfully", "train", "such", "models", ".", "Also", "unfortunate", "is", "the", "footnote", "which", "states", "that", "the", "current", "results", "are", "incomplete", "and", "will", "be", "updated", ",", "hence", "as", "a", "reviewer", "I", "am", "not", "sure", "which", "results", "and", "conclusions", "are", "valid", "right", "now", ".", "Pros", ":", "+", "clearly", "written", "+", "useful", "experiments", "for", "those", "seeking", "to", "select", "a", "differential", "Bayesian", "filter", ",", "and", "learning", "-LRB-", "heteroscedastic", "-RRB-", "noise", "from", "data", ".", "+", "experiments", "on", "real-world", "use", "cases", "rather", "than", "toy", "problems", "Cons", ":", "-", "Incomplete", "experiments", "according", "to", "footnote", ",", "thus", "results", "and", "conclusions", "might", "change", "after", "this", "review", ".", "-", "Unclear", "what", "the", "effect", "of", "the", "selected", "process", "/", "observation", "model", "is", "on", "the", "learned", "noise", "Below", "are", "more", "detailed", "comments", "and", "questions", ":", "*", "p6", ".", "Footnote", ":", "TICKTICK", "due", "to", "time", "constraints", ",", "...", ",", "results", "will", "be", "updated", "''", "Is", "this", "acceptable", "?", "I", "have", "never", "seen", "such", "a", "notice", "when", "reviewing", ".", "So", ",", "are", "the", "current", "results", "on", "a", "single", "fold", "?", "Will", "the", "numbers", "in", "the", "tables", ",", "or", "the", "conclusions", "change", "after", "this", "review", "?", "*", "If", "I", "understand", "correctly", ",", "the", "paper", "TICK", "only", "'", "focuses", "on", "learning", "the", "heteroscedastic", "noise", "variance", ",", "but", "assumes", "that", "the", "deterministic", "non-linear", "parts", "of", "the", "process", "and", "observation", "models", "are", "fixed", ".", "I", "did", "not", "find", "this", "very", "clearly", "stated", "in", "the", "paper", ",", "though", "at", "least", "the", "Appendix", "explicitly", "states", "the", "used", "functions", "for", "the", "process", "models", ".", "*", "I", "would", "have", "liked", "to", "see", "in", "the", "paper", "more", "explanation", "on", "how", "the", "process", "and", "observations", "models", "were", "selected", "and", "validated", "in", "the", "experiments", ",", "since", "I", "expect", "that", "the", "validity", "of", "these", "functions", "affects", "the", "learned", "noise", "variances", ".", "Since", "the", "noise", "needs", "to", "account", "for", "the", "inaccuracies", "in", "the", "deterministic", "models", ",", "would", "the", "choice", "for", "these", "functions", "not", "impact", "your", "conclusions", "?", "And", ",", "would", "it", "or", "would", "it", "not", "be", "possible", "to", "learn", "both", "these", "deterministic", "models", "and", "the", "noise", "jointly", "from", "the", "training", "data", "?", "*", "Is", "it", "possible", "to", "add", "priors", "on", "Q", "and", "R", "parameters", "for", "Bayesian", "treatment", "of", "learning", "model", "parameters", "?", "I", "can", "imagine", "that", "priors", "can", "guide", "the", "optimization", "to", "either", "adjust", "more", "of", "the", "Q", "or", "more", "of", "the", "R", "variance", "to", "improve", "the", "likelihood", ".", "*", "Section", "1", ":", "*", "TICKTICK", "Our", "experiments", "show", "that", "...", "''", "This", "may", "be", "a", "matter", "of", "taste", ",", "but", "I", "did", "not", "expect", "to", "see", "the", "main", "conclusions", "already", "in", "the", "introduction", ".", "They", "should", "appear", "in", "the", "abstract", "to", "help", "out", "the", "quick", "reader", ".", "In", "the", "introduction", ",", "it", "appears", "as", "if", "you", "are", "talking", "about", "some", "separate", "preliminary", "experiments", ",", "and", "which", "you", "base", "some", "conclusions", "that", "will", "be", "used", "in", "the", "remainder", "of", "this", "paper", ".", "*", "Section", "3", ":", "*", "So", ",", "mostly", "empirical", "study", ",", "since", "heteroscedastic", "noise", "models", "were", "already", "used", "?", "*", "TICKTICK", "Previous", "work", "evaluated", "...", "''", "please", "add", "citations", "*", "Section", "4.1", ":", "*", "TICKTICK", "train", "a", "discriminative", "neural", "network", "o", "with", "parameters", "wo", "to", "preprocess", "the", "raw", "sensory", "data", "D", "and", "thus", "create", "a", "more", "compact", "representation", "of", "the", "observations", "z", "=", "o", "-LRB-", "D", ";", "wo", "-RRB-", ".", "''", "At", "this", "point", "in", "the", "paper", ",", "I", "do", "n't", "understand", "this", ".", "How", "is", "z", "learned", ",", "via", "supervised", "learning", "-LRB-", "what", "is", "the", "target", "value", "for", "z", "-RRB-", "?", "Or", "is", "z", "some", "latent", "representation", "that", "is", "jointly", "optimized", "with", "the", "filters", "?", "This", "only", "became", "somewhat", "clearer", "in", "Sec.", "5.2", "on", "p.", "8", "where", "it", "states", "that", "TICKTICK", "We", "...", "train", "a", "neural", "network", "to", "extract", "the", "position", "of", "the", "object", ",", "the", "contact", "point", "and", "normal", "as", "well", "as", "...", "''", ".", "So", "if", "I", "understand", "correctly", ",", "the", "function", "o", "for", "z", "=", "o", "-LRB-", "D", "-RRB-", "is", "thus", "learned", "offline", "w.r.t.", "some", "designed", "observation", "variables", "for", "which", "GT", "is", "available", "-LRB-", "from", "manual", "annotations", "?", "-RRB-", ".", "*", "Section", "4.2", ":", "*", "TICKTICK", "we", "predict", "a", "separate", "Qi", "for", "every", "sigma", "point", "and", "then", "compute", "Q", "as", "the", "weighted", "mean", "''", "CD", "So", ",", "separate", "parameters", "w_g", "for", "each", "sigma", "point", "i", ",", "or", "is", "a", "single", "learned", "non-linear", "function", "applied", "to", "all", "points", "?", "*", "Section", "4.3", ":", "*", "Equation", "14", ":", "inconsistent", "use", "of", "boldface", "script", ":", "should", "use", "bold", "sigma_t", ",", "and", "bold", "l_t", "?", "*", "TICKTICK", "In", "practice", ",", "we", "found", "that", "during", "learning", "...", "by", "only", "increasing", "the", "predicted", "variance", "''", "CD", "This", "is", "an", "interesting", "observation", ",", "which", "I", "would", "have", "liked", "to", "see", "explored", "more", ".", "I", "understand", "that", "term", "-LRB-", "ii", "-RRB-", "is", "needed", "to", "guide", "the", "learning", "processes", ",", "but", "in", "the", "end", "would", "n't", "we", "want", "to", "optimize", "the", "actual", "likelihood", "?", "So", ",", "could", "you", "-LRB-", "after", "the", "loss", "with", "-LRB-", "ii", "-RRB-", "converged", "-RRB-", "reduce", "\\", "lambda_2", "to", "zero", "to", "properly", "optimize", "only", "the", "log", "likelihood", "without", "guidance", "from", "a", "good", "initial", "state", "?", "Or", "is", "it", "not", "possible", "to", "reliably", "optimize", "the", "likelihood", "via", "back-propagation", "at", "all", "from", "some", "reason", "?", "*", "Section", "5.1.1", "*", "''", "...", "of", "varying", "length", "-LRB-", "from", "270", "to", "over", "4500", "steps", "-RRB-", "...", "''", "it", "would", "be", "good", "to", "mention", "the", "fps", ",", "to", "get", "understand", "to", "what", "real-world", "time", "horizons", "50", "/", "100", "frames", "correspond", ".", "*", "Section", "5.1.2", ":", "*", "Table", "1", ":", "How", "are", "the", "parameters", "of", "the", "filters", "in", "the", "TICKTICK", "no", "learning", "''", "column", "obtained", "?", "Are", "these", "tuned", "in", "some", "other", "way", ",", "or", "taken", "form", "existing", "implementations", "?", "Also", ",", "can", "you", "clarify", "if", "the", "TICK", "no", "learning", "'", "parameters", "served", "as", "the", "initial", "condition", "for", "the", "learning", "approaches", "?", "*", "Table", "1", ",", "first", "row", "column", "Q+R", ":", "TICKTICK", "0.2", "''", "CD", "Is", "there", "a", "missing", "zero", "here", ",", "i.e.", "TICKTICK", "0.20", "''", "?", "Otherwise", ",", "the", "precision", "of", "reported", "results", "in", "this", "table", "is", "not", "consistent", ".", "Hard", "to", "say", ":", "is", "the", "mean", "of", "R+Q", "0.2", ",", "and", "slightly", "lower", "than", "R+Q", "h", ",", "or", "could", "it", "be", "as", "high", "as", "0.24", "?", "*", "TICKTICK", "learning", "a", "heteroscedastic", "process", "noise", "model", "leads", "to", "big", "improvements", "and", "makes", "the", "filters", "competitive", "with", "the", "EKF", "''", ".", "Results", "for", "EKF", "still", "appear", "significantly", "better", "than", "the", "novel", "UKF", ",", "and", "even", "the", "PF", "-LRB-", "especially", "rotational", "error", "-RRB-", ".", "*", "Section", "6", ":", "*", "TICKTICK", "Large", "outliers", "in", "the", "prediction", "of", "the", "preprocessing", "networks", "were", "not", "associated", "with", "higher", "observation", "noise", ".", "''", "I", "do", "n't", "see", "on", "what", "presented", "results", "these", "conclusions", "were", "drawn", ",", "as", "this", "is", "the", "first", "time", "the", "word", "TICKTICK", "outlier", "''", "is", "mentioned", "in", "the", "paper", ".", "Outliers", "seem", "indeed", "important", ",", "as", "they", "contradict", "the", "typical", "assumptions", "e.g.", "of", "Gaussian", "noise", ",", "so", "it", "would", "be", "useful", "to", "clarify", "how", "the", "proposed", "techniques", "handle", "such", "outliers", ".", "*", "Section", "6", ":", "*", "TICKTICK", "Large", "outliers", "in", "the", "prediction", "of", "the", "preprocessing", "networks", "were", "not", "associated", "with", "higher", "observation", "noise", ".", "''", "I", "do", "n't", "see", "on", "what", "presented", "results", "these", "conclusions", "were", "drawn", ",", "as", "this", "is", "the", "first", "time", "the", "word", "TICKTICK", "outlier", "''", "is", "mentioned", "in", "the", "paper", ".", "Outliers", "seem", "indeed", "important", ",", "as", "they", "contradict", "the", "typical", "assumptions", "e.g.", "of", "Gaussian", "noise", ",", "so", "it", "would", "be", "useful", "to", "clarify", "how", "the", "proposed", "techniques", "handle", "such", "outliers", ".", "Reply", ":", "Agreed", ",", "we", "tried", "to", "make", "it", "clearer", "what", "we", "meant", "by", "outliers", ".", "In", "this", "case", ",", "outliers", "were", "mostly", "meant", "to", "mean", "TICKTICK", "unusually", "bad", "predictions", "''", "especially", "of", "the", "object", "position", "in", "the", "pushing", "task", ".", "An", "important", "point", "here", "is", "that", "on", "the", "pushing", "task", "there", "is", "no", "structural", "explanation", "for", "the", "bad", "predictions", "-LRB-", "such", "as", "for", "example", "occlusions", "-RRB-", ".", "Therefore", "we", "do", "not", "think", "that", "they", "actually", "violate", "a", "gaussian", "assumption", "about", "the", "observation", "noise", ".", "On", "the", "question", "of", "how", "the", "method", "handles", "outliers", ":", "The", "idea", "behind", "using", "a", "heteroscedastic", "noise", "model", "is", "that", "it", "allows", "to", "assign", "different", "levels", "of", "noise", "to", "different", "inputs", ".", "For", "example", ",", "if", "the", "object", "is", "occluded", "in", "the", "image", ",", "a", "high", "observation", "noise", "can", "be", "predicted", ".", "This", "flags", "the", "observations", "in", "this", "timestep", "as", "unreliable", ",", "such", "that", "the", "filters", "rely", "more", "on", "the", "process", "model", "prediction", ".", "Such", "outliers", "would", "indeed", "violate", "a", "global", "gaussian", "assumption", "about", "the", "observation", "noise", ".", "To", "alleviate", "this", ",", "our", "method", "instead", "learns", "input-dependent", "TICKTICK", "local", "''", "noise", "distributions", ".", "This", "allows", "it", "to", "capture", "e.g.", "the", "noise", "in", "the", "unoccluded", "case", "with", "one", "distribution", "and", "the", "prediction", "errors", "in", "the", "case", "of", "occlusion", "with", "another", "one", ".", "References", ":", "Rico", "Jonschkowski", ",", "Divyam", "Rastogi", ",", "and", "Oliver", "Brock", ".", "Differentiable", "particle", "filters", ":", "End-to-end", "learning", "with", "algorithmic", "priors", ".", "In", "Proceedings", "of", "Robotics", ":", "Science", "and", "Systems", ",", "Pittsburgh", ",", "USA", ",", "2018", ".", "Alina", "Kloss", ",", "Stefan", "Schaal", ",", "and", "Jeannette", "Bohg", ".", "Combining", "learned", "and", "analytical", "models", "for", "predicting", "action", "effects", ".", "arXiv", "preprint", "arXiv", ":", "1710.04102", ",", "2017", ".", "Subham", "Sahoo", ",", "Christoph", "Lampert", "and", "Georg", "Martius", ".", "Learning", "Equations", "for", "Extrapolation", "and", "Control", ".", "In", "Proceedings", "of", "the", "35th", "International", "Conference", "on", "Machine", "Learning", ",", "PMLR", "80:4442-4450", ",", "2018", "."], "comment_id": "B1enjzWvCm"}, {"rels": [[0, 11, 11, 20, "circumstance"], [0, 20, 20, 796, "elaboration"], [20, 30, 30, 796, "elaboration"], [30, 40, 40, 105, "elaboration"], [40, 60, 60, 105, "elaboration"], [60, 67, 67, 105, "example"], [67, 77, 77, 105, "elaboration"], [77, 78, 78, 105, "elaboration"], [78, 85, 85, 89, "purpose"], [78, 89, 89, 105, "temporal"], [89, 94, 94, 105, "circumstance"], [94, 100, 100, 105, "elaboration"], [30, 105, 105, 796, "elaboration"], [105, 113, 113, 127, "elaboration"], [113, 118, 118, 127, "circumstance"], [105, 127, 127, 796, "elaboration"], [127, 134, 134, 144, "elaboration"], [127, 144, 144, 796, "elaboration"], [144, 153, 153, 796, "list"], [153, 796, 144, 153, "list"], [153, 174, 174, 796, "list"], [153, 172, 172, 174, "elaboration"], [174, 796, 153, 174, "list"], [174, 183, 183, 796, "elaboration"], [183, 188, 188, 796, "textualorganization"], [188, 796, 183, 188, "textualorganization"], [188, 202, 202, 796, "list"], [202, 796, 188, 202, "list"], [202, 221, 221, 796, "list"], [202, 217, 217, 221, "elaboration"], [221, 796, 202, 221, "list"], [221, 247, 247, 272, "list"], [221, 235, 235, 247, "same_unit"], [221, 223, 223, 235, "elaboration"], [235, 247, 221, 235, "same_unit"], [235, 242, 242, 247, "circumstance"], [247, 272, 221, 247, "list"], [247, 264, 264, 272, "purpose"], [221, 272, 272, 796, "elaboration"], [279, 305, 272, 279, "attribution"], [272, 305, 305, 796, "elaboration"], [311, 395, 305, 311, "attribution"], [311, 320, 320, 395, "elaboration"], [320, 328, 328, 395, "list"], [328, 395, 320, 328, "list"], [328, 352, 352, 395, "same_unit"], [328, 335, 335, 352, "elaboration"], [352, 395, 328, 352, "same_unit"], [352, 360, 360, 395, "list"], [360, 395, 352, 360, "list"], [360, 366, 366, 395, "list"], [366, 395, 360, 366, "list"], [366, 376, 376, 395, "purpose"], [305, 395, 395, 796, "elaboration"], [395, 411, 411, 796, "elaboration"], [411, 436, 436, 796, "list"], [411, 418, 418, 436, "list"], [418, 436, 411, 418, "list"], [418, 426, 426, 436, "elaboration"], [436, 796, 411, 436, "list"], [436, 479, 479, 491, "elaboration"], [479, 490, 490, 491, "same_unit"], [479, 487, 487, 490, "elaboration"], [490, 491, 479, 490, "same_unit"], [436, 491, 491, 796, "elaboration"], [491, 501, 501, 796, "elaboration"], [501, 522, 522, 796, "list"], [501, 520, 520, 522, "elaboration"], [522, 796, 501, 522, "list"], [522, 622, 622, 796, "topic"], [522, 532, 532, 534, "same_unit"], [522, 524, 524, 532, "elaboration"], [524, 527, 527, 532, "elaboration"], [532, 534, 522, 532, "same_unit"], [522, 534, 534, 543, "attribution"], [522, 543, 543, 622, "elaboration"], [543, 560, 560, 561, "same_unit"], [543, 555, 555, 560, "elaboration"], [560, 561, 543, 560, "same_unit"], [543, 561, 561, 565, "elaboration"], [543, 565, 565, 622, "elaboration"], [565, 591, 591, 622, "list"], [565, 567, 567, 591, "elaboration"], [567, 569, 569, 591, "purpose"], [569, 574, 574, 591, "same_unit"], [574, 591, 569, 574, "same_unit"], [574, 579, 579, 591, "elaboration"], [579, 585, 585, 591, "circumstance"], [591, 622, 565, 591, "list"], [591, 600, 600, 607, "circumstance"], [600, 606, 606, 607, "same_unit"], [600, 601, 601, 606, "elaboration"], [606, 607, 600, 606, "same_unit"], [591, 607, 607, 622, "elaboration"], [622, 796, 522, 622, "topic"], [622, 641, 641, 796, "list"], [622, 637, 637, 641, "elaboration"], [641, 796, 622, 641, "list"], [641, 654, 654, 669, "same_unit"], [641, 652, 652, 654, "same_unit"], [641, 647, 647, 652, "elaboration"], [652, 654, 641, 652, "same_unit"], [654, 669, 641, 654, "same_unit"], [654, 660, 660, 669, "elaboration"], [641, 669, 669, 796, "elaboration"], [669, 686, 686, 796, "list"], [686, 796, 669, 686, "list"], [690, 713, 686, 690, "attribution"], [690, 702, 702, 713, "same_unit"], [690, 698, 698, 702, "elaboration"], [702, 713, 690, 702, "same_unit"], [702, 706, 706, 713, "elaboration"], [686, 713, 713, 796, "elaboration"], [713, 727, 727, 735, "list"], [727, 735, 713, 727, "list"], [728, 735, 727, 728, "attribution"], [713, 735, 735, 762, "elaboration"], [735, 738, 738, 762, "purpose"], [740, 762, 738, 740, "attribution"], [740, 753, 753, 762, "elaboration"], [753, 754, 754, 762, "elaboration"], [713, 762, 762, 796, "elaboration"], [762, 775, 775, 796, "elaboration"], [775, 783, 783, 796, "elaboration"], [783, 784, 784, 796, "elaboration"]], "tokens": ["The", "present", "paper", "proposes", "a", "fast", "approximation", "to", "the", "softmax", "computation", "when", "the", "number", "of", "classes", "is", "very", "large", ".", "This", "is", "typically", "a", "bottleneck", "in", "deep", "learning", "architectures", ".", "The", "approximation", "is", "a", "sparse", "two-layer", "mixture", "of", "experts", ".", "The", "paper", "lacks", "rigor", "and", "the", "writing", "is", "of", "low", "quality", ",", "both", "in", "its", "clarity", "and", "its", "grammar", ".", "See", "a", "list", "of", "typos", "below", ".", "An", "example", "of", "lack", "of", "mathematical", "rigor", "is", "equation", "4", "in", "which", "the", "same", "variable", "name", "is", "used", "to", "describe", "the", "weights", "before", "and", "after", "pruning", ",", "as", "if", "it", "was", "computer", "code", "instead", "of", "an", "equation", ".", "Also", "pervasive", "is", "the", "use", "of", "the", "asterisk", "to", "denote", "multiplication", ",", "again", "as", "if", "it", "was", "code", "and", "not", "math", ".", "Algorithm", "1", "does", "not", "include", "mitosis", ",", "which", "may", "have", "an", "effect", "on", "the", "resulting", "approximation", ".", "How", "are", "the", "lambda", "and", "threshold", "parameters", "tuned", "?", "The", "authors", "mention", "a", "validation", "set", ",", "are", "they", "just", "exhaustively", "explored", "on", "a", "3D", "grid", "on", "the", "validation", "set", "?", "The", "results", "only", "compare", "with", "Shim", "et", "al.", ".", "Why", "only", "this", "method", "?", "Why", "would", "it", "be", "expected", "to", "be", "faster", "than", "all", "the", "other", "alternatives", "?", "Would", "n't", "similar", "alternatives", "like", "the", "sparsely", "gated", "MoE", ",", "D-softmax", "and", "adaptive-softmax", "have", "chances", "of", "being", "faster", "?", "The", "column", "TICKTICK", "FLOPS", "''", "in", "the", "result", "seems", "to", "measure", "the", "speedup", ",", "whereas", "the", "actual", "FLOPS", "should", "be", "less", "when", "the", "speed", "increases", ".", "Also", ",", "a", "TICKTICK", "1x", "''", "label", "seems", "to", "be", "missing", "in", "for", "the", "full", "softmax", ",", "so", "that", "the", "reference", "is", "clearly", "specified", ".", "All", "in", "all", ",", "the", "results", "show", "that", "the", "proposed", "method", "provides", "a", "significant", "speedup", "with", "respect", "to", "Shim", "et", "al.", ",", "but", "it", "lacks", "comparison", "with", "other", "methods", "in", "the", "literature", ".", "A", "brief", "list", "of", "typos", ":", "TICKTICK", "Sparse", "Mixture", "of", "Sparse", "of", "Sparse", "Experts", "''", "TICKTICK", "if", "we", "only", "search", "right", "answer", "''", "TICKTICK", "it", "might", "also", "like", "appear", "''", "TICKTICK", "which", "is", "to", "design", "to", "choose", "the", "right", "''", "sparsly", "TICKTICK", "will", "only", "consists", "partial", "''", "TICKTICK", "with", "NN", "is", "a", "lasso", "threshold", "''", "TICKTICK", "an", "arbitrarily", "distance", "function", "''", "TICKTICK", "each", "10", "sub", "classes", "are", "belonged", "to", "one", "''", "TICKTICK", "is", "also", "needed", "to", "tune", "to", "achieve", "''", "Dear", "Reviewer", ",", "Thank", "you", "for", "your", "valuable", "comments", ".", "We", "have", "revised", "our", "writing", "in", "the", "revision", ",", "and", "will", "further", "improve", "its", "clarity", ".", "Please", "find", "our", "response", "as", "follows", ".", "-", "Algorithm", "1", "does", "not", "include", "mitosis", ",", "which", "may", "have", "an", "effect", "on", "the", "resulting", "approximation", ".", "Mitosis", "training", "can", "be", "considered", "as", "executing", "Algorithm", "1", "for", "multiple", "times", "with", "an", "increasing", "number", "of", "experts", "and", "inherited", "initialization", "from", "last", "round", "by", "changing", "W", "^", "e", "and", "W", "^", "g.", "Also", ",", "training", "with", "mitosis", "achieves", "similar", "performance", "as", "training", "without", "it", "shown", "in", "Appendix", "B", ",", "Figure", "-LRB-", "a", "-RRB-", ".", "-", "How", "are", "the", "lambda", "and", "threshold", "parameters", "tuned", "?", "The", "authors", "mention", "a", "validation", "set", ",", "are", "they", "just", "exhaustively", "explored", "on", "a", "3D", "grid", "on", "the", "validation", "set", "?", "The", "hyper-parameters", "related", "to", "DS-softmax", "-LRB-", "such", "as", "lambda", "-RRB-", "are", "tuned", "according", "to", "the", "performance", "on", "a", "validation", "dataset", ".", "Also", ",", "as", "we", "mentioned", "in", "the", "paper", ",", "only", "one", "hyper-parameter", "-LRB-", "group", "lasso", "lambda", "-RRB-", "needs", "to", "be", "tuned", ".", "The", "heuristic", "we", "use", "to", "tune", "group", "lasso", "lambda", "is", "to", "increase", "lambda", ",", "starting", "from", "a", "small", "value", ",", "until", "it", "hurts", "the", "performance", ".", "Also", "threshold", "and", "balancing", "lambda", "variables", "are", "kept", "fixed", "as", "-LRB-", "0.01", "and", "10", "-RRB-", ".", "-", "Why", "would", "it", "be", "expected", "to", "be", "faster", "than", "all", "the", "other", "alternatives", "?", "Would", "n't", "similar", "alternatives", "like", "the", "sparsely", "gated", "MoE", ",", "D-softmax", "and", "adaptive-softmax", "have", "chances", "of", "being", "faster", "?", "In", "terms", "of", "baselines", ",", "SVD-softmax", "-LRB-", "NIPS", "'", "17", "-RRB-", "was", "chosen", "since", "it", "is", "a", "recent", "method", "that", "provides", "a", "significant", "inference", "speedup", "for", "softmax", ".", "Other", "alternatives", ",", "such", "as", "D-softmax", "and", "adaptive-softmax", ",", "focus", "on", "training", "instead", "of", "inference", "speedup", ".", "Furthermore", ",", "as", "claimed", "in", "their", "papers", ",", "they", "achieve", "limited", "speedup", "-LRB-", "around", "5x", "-RRB-", "in", "language", "modeling", ",", "which", "is", "much", "worse", "than", "ours", ".", "With", "regards", "to", "Sparsely", "Gated", "MoE", ",", "it", "can", "not", "speed", "up", "inference", ",", "since", "they", "select", "expert", "with", "full", "softmax", ".", "We", "would", "like", "to", "emphasize", "that", "most", "existing", "methods", "for", "inference", "speedup", "focus", "on", "approximating", "trained", "softmax", "layer", ",", "which", "usually", "suffers", "a", "loss", "on", "performance", ".", "Our", "model", "allows", "the", "adaptive", "adjustment", "of", "the", "softmax", "layer", ",", "achieves", "speedup", "through", "capturing", "the", "two-level", "overlapped", "hierarchy", "during", "training", ",", "which", "is", "novel", "and", "does", "not", "suffer", "from", "the", "performance", "loss", "."], "comment_id": "B1e8djk9Tm"}, {"rels": [[0, 10, 10, 16, "elaboration"], [0, 16, 16, 39, "elaboration"], [16, 23, 23, 39, "list"], [23, 39, 16, 23, "list"], [23, 29, 29, 39, "means"], [0, 39, 39, 1789, "elaboration"], [39, 51, 51, 56, "elaboration"], [39, 56, 56, 1789, "elaboration"], [56, 65, 65, 80, "list"], [56, 60, 60, 65, "elaboration"], [65, 80, 56, 65, "list"], [65, 71, 71, 80, "elaboration"], [71, 75, 75, 80, "elaboration"], [56, 80, 80, 1789, "elaboration"], [80, 95, 95, 1789, "elaboration"], [95, 99, 99, 112, "condition"], [103, 112, 99, 103, "condition"], [95, 112, 112, 1789, "elaboration"], [112, 119, 119, 136, "purpose"], [119, 122, 122, 136, "circumstance"], [122, 128, 128, 136, "elaboration"], [112, 136, 136, 1789, "elaboration"], [136, 141, 141, 161, "purpose"], [141, 148, 148, 161, "elaboration"], [148, 152, 152, 161, "elaboration"], [152, 155, 155, 161, "elaboration"], [136, 161, 161, 1789, "elaboration"], [169, 186, 161, 169, "condition"], [169, 182, 182, 186, "purpose"], [161, 186, 186, 1789, "elaboration"], [190, 223, 186, 190, "attribution"], [190, 200, 200, 223, "elaboration"], [200, 217, 217, 218, "same_unit"], [200, 208, 208, 217, "elaboration"], [217, 218, 200, 217, "same_unit"], [200, 218, 218, 223, "elaboration"], [186, 223, 223, 1789, "elaboration"], [223, 232, 232, 242, "purpose"], [232, 237, 237, 242, "elaboration"], [223, 242, 242, 1789, "elaboration"], [242, 245, 245, 259, "purpose"], [245, 251, 251, 259, "circumstance"], [242, 259, 259, 1789, "elaboration"], [259, 263, 263, 293, "purpose"], [263, 273, 273, 293, "elaboration"], [273, 277, 277, 293, "elaboration"], [259, 293, 293, 1789, "elaboration"], [293, 298, 298, 326, "purpose"], [298, 316, 316, 326, "elaboration"], [293, 326, 326, 1789, "elaboration"], [326, 330, 330, 349, "purpose"], [332, 349, 330, 332, "attribution"], [326, 349, 349, 1789, "elaboration"], [361, 373, 349, 361, "attribution"], [349, 373, 373, 1789, "elaboration"], [373, 386, 386, 395, "list"], [386, 395, 373, 386, "list"], [390, 395, 386, 390, "attribution"], [373, 395, 395, 1789, "elaboration"], [395, 400, 400, 434, "list"], [400, 434, 395, 400, "list"], [400, 406, 406, 434, "same_unit"], [400, 404, 404, 406, "elaboration"], [406, 434, 400, 406, "same_unit"], [414, 434, 406, 414, "attribution"], [414, 422, 422, 434, "circumstance"], [422, 426, 426, 434, "list"], [426, 434, 422, 426, "list"], [395, 434, 434, 1789, "elaboration"], [434, 446, 446, 460, "purpose"], [452, 460, 446, 452, "attribution"], [452, 456, 456, 460, "elaboration"], [434, 460, 460, 1789, "elaboration"], [460, 475, 475, 499, "elaboration"], [475, 482, 482, 499, "elaboration"], [482, 491, 491, 499, "elaboration"], [460, 499, 499, 1789, "elaboration"], [499, 514, 514, 1789, "elaboration"], [514, 538, 538, 1789, "list"], [521, 538, 514, 521, "attribution"], [521, 534, 534, 538, "same_unit"], [521, 530, 530, 534, "elaboration"], [534, 538, 521, 534, "same_unit"], [538, 1789, 514, 538, "list"], [538, 548, 548, 1789, "elaboration"], [548, 570, 570, 1789, "list"], [570, 1789, 548, 570, "list"], [576, 609, 570, 576, "attribution"], [576, 592, 592, 609, "list"], [576, 577, 577, 592, "elaboration"], [592, 609, 576, 592, "list"], [592, 597, 597, 609, "elaboration"], [570, 609, 609, 1789, "elaboration"], [609, 625, 625, 635, "list"], [609, 617, 617, 625, "elaboration"], [625, 635, 609, 625, "list"], [609, 635, 635, 1789, "elaboration"], [635, 648, 648, 1789, "list"], [635, 642, 642, 648, "elaboration"], [648, 1789, 635, 648, "list"], [648, 650, 650, 665, "elaboration"], [648, 665, 665, 1789, "elaboration"], [665, 667, 667, 1789, "elaboration"], [667, 668, 668, 1789, "elaboration"], [668, 716, 716, 1789, "topic"], [673, 677, 668, 673, "attribution"], [668, 677, 677, 716, "explanation"], [677, 678, 678, 679, "elaboration"], [677, 679, 679, 716, "elaboration"], [683, 716, 679, 683, "attribution"], [683, 693, 693, 716, "elaboration"], [693, 710, 710, 711, "same_unit"], [693, 701, 701, 710, "elaboration"], [710, 711, 693, 710, "same_unit"], [693, 711, 711, 716, "elaboration"], [716, 1789, 668, 716, "topic"], [716, 935, 935, 1789, "list"], [716, 718, 718, 730, "elaboration"], [718, 723, 723, 730, "elaboration"], [716, 730, 730, 935, "elaboration"], [730, 738, 738, 755, "purpose"], [738, 750, 750, 755, "elaboration"], [730, 755, 755, 767, "elaboration"], [757, 767, 755, 757, "attribution"], [730, 767, 767, 935, "elaboration"], [767, 769, 769, 788, "elaboration"], [769, 778, 778, 788, "purpose"], [778, 783, 783, 788, "elaboration"], [767, 788, 788, 935, "elaboration"], [788, 791, 791, 935, "textualorganization"], [791, 935, 788, 791, "textualorganization"], [791, 807, 807, 935, "contrast"], [797, 807, 791, 797, "attribution"], [807, 935, 791, 807, "contrast"], [807, 813, 813, 822, "elaboration"], [807, 822, 822, 935, "explanation"], [822, 838, 838, 847, "elaboration"], [822, 847, 847, 935, "elaboration"], [847, 848, 848, 849, "elaboration"], [847, 849, 849, 872, "elaboration"], [849, 853, 853, 872, "purpose"], [855, 872, 853, 855, "attribution"], [847, 872, 872, 935, "elaboration"], [872, 874, 874, 885, "elaboration"], [872, 885, 885, 935, "elaboration"], [885, 892, 892, 899, "reason"], [892, 896, 896, 899, "purpose"], [885, 899, 899, 935, "example"], [899, 913, 913, 935, "elaboration"], [913, 920, 920, 935, "elaboration"], [935, 1789, 716, 935, "list"], [935, 937, 937, 1789, "textualorganization"], [937, 1789, 935, 937, "textualorganization"], [937, 942, 942, 976, "list"], [942, 976, 937, 942, "list"], [937, 976, 976, 1789, "elaboration"], [976, 977, 977, 978, "elaboration"], [976, 978, 978, 998, "elaboration"], [976, 998, 998, 1003, "elaboration"], [976, 1003, 1003, 1789, "elaboration"], [1003, 1021, 1021, 1789, "list"], [1003, 1010, 1010, 1021, "elaboration"], [1021, 1789, 1003, 1021, "list"], [1021, 1041, 1041, 1789, "list"], [1021, 1028, 1028, 1041, "elaboration"], [1041, 1789, 1021, 1041, "list"], [1041, 1047, 1047, 1789, "list"], [1047, 1789, 1041, 1047, "list"], [1047, 1048, 1048, 1054, "elaboration"], [1047, 1054, 1054, 1103, "elaboration"], [1063, 1079, 1054, 1063, "attribution"], [1054, 1057, 1057, 1063, "purpose"], [1054, 1079, 1079, 1103, "elaboration"], [1079, 1086, 1086, 1103, "elaboration"], [1086, 1095, 1095, 1103, "elaboration"], [1047, 1103, 1103, 1789, "elaboration"], [1103, 1118, 1118, 1142, "elaboration"], [1125, 1142, 1118, 1125, "attribution"], [1125, 1138, 1138, 1142, "same_unit"], [1125, 1134, 1134, 1138, "elaboration"], [1138, 1142, 1125, 1138, "same_unit"], [1103, 1142, 1142, 1789, "elaboration"], [1142, 1252, 1252, 1789, "list"], [1142, 1152, 1152, 1252, "elaboration"], [1152, 1174, 1174, 1213, "elaboration"], [1152, 1213, 1213, 1239, "elaboration"], [1213, 1229, 1229, 1239, "list"], [1213, 1221, 1221, 1229, "elaboration"], [1229, 1239, 1213, 1229, "list"], [1152, 1239, 1239, 1246, "elaboration"], [1152, 1246, 1246, 1252, "elaboration"], [1252, 1789, 1142, 1252, "list"], [1252, 1254, 1254, 1269, "elaboration"], [1252, 1269, 1269, 1789, "elaboration"], [1269, 1271, 1271, 1789, "elaboration"], [1271, 1272, 1272, 1789, "elaboration"], [1282, 1789, 1272, 1282, "attribution"], [1274, 1282, 1272, 1274, "attribution"], [1277, 1282, 1274, 1277, "attribution"], [1284, 1344, 1282, 1284, "attribution"], [1284, 1288, 1288, 1344, "elaboration"], [1288, 1301, 1301, 1305, "same_unit"], [1301, 1305, 1288, 1301, "same_unit"], [1288, 1305, 1305, 1344, "elaboration"], [1282, 1344, 1344, 1789, "elaboration"], [1344, 1350, 1350, 1789, "textualorganization"], [1350, 1789, 1344, 1350, "textualorganization"], [1350, 1370, 1370, 1789, "elaboration"], [1370, 1379, 1379, 1391, "elaboration"], [1370, 1391, 1391, 1789, "explanation"], [1420, 1789, 1391, 1420, "attribution"], [1391, 1394, 1394, 1420, "purpose"], [1394, 1400, 1400, 1420, "elaboration"], [1400, 1411, 1411, 1420, "list"], [1411, 1420, 1400, 1411, "list"], [1411, 1414, 1414, 1420, "elaboration"], [1420, 1449, 1449, 1460, "elaboration"], [1420, 1460, 1460, 1520, "elaboration"], [1460, 1468, 1468, 1520, "same_unit"], [1460, 1465, 1465, 1468, "elaboration"], [1468, 1520, 1460, 1468, "same_unit"], [1468, 1479, 1479, 1520, "elaboration"], [1479, 1490, 1490, 1520, "elaboration"], [1490, 1501, 1501, 1502, "list"], [1501, 1502, 1490, 1501, "list"], [1490, 1502, 1502, 1520, "elaboration"], [1420, 1520, 1520, 1789, "elaboration"], [1522, 1539, 1520, 1522, "attribution"], [1522, 1528, 1528, 1539, "comparison"], [1528, 1532, 1532, 1539, "list"], [1532, 1539, 1528, 1532, "list"], [1532, 1536, 1536, 1539, "circumstance"], [1520, 1539, 1539, 1789, "elaboration"], [1539, 1540, 1540, 1547, "elaboration"], [1539, 1547, 1547, 1601, "elaboration"], [1547, 1553, 1553, 1577, "purpose"], [1570, 1577, 1553, 1570, "attribution"], [1547, 1577, 1577, 1601, "elaboration"], [1580, 1601, 1577, 1580, "attribution"], [1580, 1589, 1589, 1601, "elaboration"], [1589, 1595, 1595, 1601, "elaboration"], [1539, 1601, 1601, 1789, "elaboration"], [1601, 1610, 1610, 1789, "explanation"], [1610, 1633, 1633, 1789, "elaboration"], [1633, 1643, 1643, 1657, "elaboration"], [1646, 1657, 1643, 1646, "attribution"], [1646, 1647, 1647, 1657, "purpose"], [1647, 1651, 1651, 1657, "list"], [1651, 1657, 1647, 1651, "list"], [1633, 1657, 1657, 1789, "elaboration"], [1661, 1685, 1657, 1661, "attribution"], [1657, 1685, 1685, 1789, "elaboration"], [1693, 1703, 1685, 1693, "attribution"], [1693, 1698, 1698, 1703, "elaboration"], [1685, 1703, 1703, 1789, "elaboration"], [1703, 1735, 1735, 1789, "list"], [1703, 1714, 1714, 1735, "elaboration"], [1735, 1789, 1703, 1735, "list"], [1735, 1745, 1745, 1755, "elaboration"], [1735, 1755, 1755, 1789, "elaboration"], [1755, 1764, 1764, 1777, "elaboration"], [1764, 1772, 1772, 1777, "same_unit"], [1764, 1768, 1768, 1772, "elaboration"], [1772, 1777, 1764, 1772, "same_unit"], [1755, 1777, 1777, 1789, "elaboration"]], "tokens": ["The", "authors", "propose", "an", "extension", "of", "hindsight", "replay", "to", "settings", "where", "the", "goal", "is", "moving", ".", "This", "consists", "in", "taking", "a", "failed", "episode", "and", "constructing", "a", "valid", "moving", "goal", "by", "searching", "prior", "experiences", "for", "a", "compatible", "goal", "trajectory", ".", "Results", "are", "shown", "on", "simulated", "robotic", "grasping", "tasks", "and", "a", "toy", "task", "introduced", "by", "the", "authors", ".", "Authors", "show", "improved", "results", "compared", "to", "other", "baselines", ".", "The", "authors", "also", "show", "a", "demonstration", "of", "transfering", "their", "policies", "to", "the", "real", "world", ".", "The", "algorithm", "appears", "very", "specific", "and", "not", "applicable", "to", "all", "cases", "with", "dynamic", "goals", ".", "It", "would", "be", "good", "if", "the", "authors", "discussed", "when", "it", "can", "and", "can", "not", "be", "applied", ".", "My", "understanding", "is", "it", "would", "be", "hard", "to", "apply", "this", "when", "the", "environment", "changes", "across", "episodes", "as", "there", "needs", "to", "be", "matching", "trajectories", ".", "It", "would", "also", "be", "hard", "to", "apply", "this", "for", "the", "same", "reason", "if", "there", "are", "dynamics", "chaging", "the", "environment", "-LRB-", "besides", "the", "goal", "-RRB-", ".", "If", "the", "goal", "was", "following", "more", "complex", "dynamics", "like", "teleporting", "from", "one", "place", "it", "seems", "it", "would", "again", "be", "rather", "hard", "to", "adapt", "this", ".", "I", "am", "also", "wondering", "if", "for", "most", "practical", "cases", "one", "could", "construct", "a", "heuristic", "for", "making", "the", "goal", "trajectory", "a", "valid", "one", "-LRB-", "not", "necessarily", "relying", "on", "knowing", "exact", "dynamics", "-RRB-", "thus", "avoiding", "the", "matching", "step", ".", "The", "literature", "review", "and", "the", "baselines", "do", "not", "appear", "to", "consider", "any", "other", "methods", "designed", "for", "dynamic", "goals", ".", "The", "paper", "seems", "to", "approach", "the", "dynamic", "goal", "problem", "as", "if", "it", "was", "a", "fresh", "problem", ".", "It", "would", "be", "good", "to", "have", "a", "better", "overview", "of", "this", "field", "and", "baselines", "that", "address", "this", "problem", "as", "it", "has", "certainly", "been", "studied", "in", "robotics", ",", "computer", "vision", ",", "and", "reinforcement", "learning", ".", "I", "find", "this", "paper", "hard", "to", "assess", "without", "a", "more", "appropriate", "context", "for", "this", "problem", "besides", "a", "recently", "proposed", "technique", "for", "sparse", "rewards", "that", "the", "authors", "might", "want", "to", "adapt", "to", "it", ".", "I", "find", "it", "difficult", "to", "believe", "that", "nobody", "has", "studied", "solutions", "to", "this", "problem", "and", "solutions", "specific", "to", "that", "do", "n't", "exist", ".", "The", "writing", "is", "a", "bit", "repetitive", "at", "times", "and", "I", "do", "believe", "the", "algorithm", "can", "be", "more", "tersely", "summarized", "earlier", "in", "the", "paper", ".", "It", "'s", "difficult", "to", "get", "the", "full", "idea", "from", "the", "Algorithm", "block", ".", "Overall", ",", "I", "think", "the", "paper", "is", "borderline", ".", "There", "is", "several", "interesting", "ideas", "and", "a", "new", "dataset", "introduced", ",", "but", "I", "would", "like", "to", "be", "more", "convinced", "that", "the", "problems", "tackled", "are", "indeed", "as", "hard", "as", "the", "authors", "claim", "and", "to", "have", "a", "better", "literature", "review", ".", "We", "thank", "the", "reviewer", "for", "the", "comments", ",", "and", "we", "would", "like", "to", "clarify", "a", "few", "important", "misconceptions", "that", "the", "reviewer", "has", "regarding", "our", "work", ".", "1", "-RRB-", "We", "position", "the", "paper", "in", "the", "context", "of", "RL", "with", "sparse", "rewards", ".", "We", "follow", "the", "goal", "setting", "of", "UVFA", "-LRB-", "Schaul", "et", "al.", ",", "2015a", "-RRB-", "and", "HER", "-LRB-", "Andrychowicz", "et", "al.", ",", "2017", "-RRB-", ".", "The", "dynamic", "goal", "problem", "is", "extended", "from", "this", "setting", ",", "not", "all", "other", "cases", ".", "Please", "see", "paragraph", "3", "in", "Section", "1", "-LRB-", "Introduction", "-RRB-", "and", "paragraph", "1", "in", "Section", "3.1", "-LRB-", "Dynamic", "goals", "-RRB-", "for", "more", "descriptions", ".", "2", "-RRB-", "We", "propose", "a", "new", "experience", "replay", "method", ".", "The", "proposed", "algorithm", "can", "be", "combined", "with", "any", "off-policy", "RL", "algorithms", ",", "similar", "to", "HER", ",", "as", "shown", "in", "Figure", "1", ".", "3", "-RRB-", "The", "motivation", "of", "developing", "algorithms", "which", "can", "learn", "from", "unshaped", "reward", "signals", "is", "that", "it", "does", "not", "need", "domain-specific", "knowledge", "and", "is", "applicable", "in", "situations", "where", "we", "do", "not", "know", "what", "admissible", "behaviour", "may", "look", "like", ".", "The", "similar", "motivation", "is", "also", "mentioned", "in", "HER", "-LRB-", "Andrychowicz", "et", "al.", ",", "2017", "-RRB-", ".", "We", "also", "added", "new", "experimental", "results", "about", "dense", "rewards", ".", "The", "results", "show", "DHER", "works", "better", ".", "See", "Figures", "3", "and", "6", ".", "Q1", ":", "The", "algorithm", "appears", "very", "specific", "and", "not", "applicable", "to", "all", "cases", "with", "dynamic", "goals", ".", "...", "A1", ":", "Please", "see", "1", "-RRB-", "and", "3", "-RRB-", "above", ".", "Q2", ":", "I", "am", "also", "wondering", "if", "for", "most", "practical", "cases", "one", "could", "construct", "a", "heuristic", "for", "making", "the", "goal", "trajectory", "a", "valid", "one", "-LRB-", "not", "necessarily", "relying", "on", "knowing", "exact", "dynamics", "-RRB-", "thus", "avoiding", "the", "matching", "step", ".", "A2", ":", "It", "is", "a", "good", "idea", "to", "take", "domain", "heuristics", "into", "consideration", ".", "However", ",", "in", "our", "paper", ",", "we", "aim", "to", "construct", "a", "model-free", "method", "for", "dynamic", "goals", "to", "avoid", "the", "complexity", "of", "constructing", "goal", "trajectories", ".", "We", "agree", "that", "your", "idea", "worths", "a", "try", "in", "the", "future", ".", "Q3", ":", "The", "literature", "review", "and", "the", "baselines", "do", "not", "appear", "to", "consider", "any", "other", "methods", "designed", "for", "dynamic", "goals", ".", "...", "A3", ":", "We", "do", "not", "want", "to", "claim", "that", "the", "dynamic", "goal", "problem", "is", "a", "fresh", "problem", ".", "However", ",", "there", "is", "little", "work", "addressing", "dynamic", "goals", "in", "the", "sparse", "reward", "setting", ".", "As", "far", "as", "we", "know", ",", "there", "is", "no", "open-source", "RL", "environments", "for", "such", "problems", ".", "-LRB-", "OpenAI", "Gym", "Robotics", "uses", "fixed", "goals", ".", "-RRB-", "Q4", ":", "I", "find", "it", "difficult", "to", "believe", "that", "nobody", "has", "studied", "solutions", "to", "this", "problem", "and", "solutions", "specific", "to", "that", "do", "n't", "exist", ".", "A4", ":", "Our", "paper", "focuses", "on", "addressing", "dynamic", "goals", "with", "sparse", "rewards", ".", "This", "setting", "has", "not", "been", "addressed", "probably", "because", "it", "is", "difficult", "to", "learn", ".", "For", "example", ",", "the", "recently", "developed", "DDPG", "and", "HER", "failed", "in", "our", "tasks", ".", "Moreover", ",", "there", "is", "no", "open-source", "environments", "for", "the", "dynamic", "goals", "and", "sparse", "rewards", ",", "to", "the", "best", "of", "our", "knowledge", ".", "Q5", ":", "There", "is", "several", "interesting", "ideas", "and", "a", "new", "dataset", "introduced", ",", "but", "I", "would", "like", "to", "be", "more", "convinced", "that", "the", "problems", "tackled", "are", "indeed", "as", "hard", "as", "the", "authors", "claim", "and", "to", "have", "a", "better", "literature", "review", ".", "A5", ":", "Except", "for", "sparse", "rewards", ",", "we", "also", "added", "new", "experimental", "results", "about", "dense", "rewards", "for", "the", "dynamic", "goal", "setting", ".", "We", "have", "similar", "results", ".", "Similar", "to", "DDPG", "and", "DDPG+HER", ",", "DDPG", "-LRB-", "dense", "-RRB-", "does", "not", "work", "well", "in", "our", "tasks", ".", "For", "the", "simple", "Dy-Snake", "environment", ",", "DQN", "-LRB-", "dense", "-RRB-", "is", "better", "than", "DQN", "but", "not", "better", "than", "DQN+DHER", ".", "See", "Figures", "3", "and", "6", ".", "Thanks", "for", "your", "response", "and", "clarifications", ".", "I", "would", "like", "to", "comment", "on", "this", "point", ":", "TICKTICK", "1", "-RRB-", "We", "position", "the", "paper", "in", "the", "context", "of", "RL", "with", "sparse", "rewards", ".", "We", "follow", "the", "goal", "setting", "of", "UVFA", "-LRB-", "Schaul", "et", "al.", ",", "2015a", "-RRB-", "and", "HER", "-LRB-", "Andrychowicz", "et", "al.", ",", "2017", "-RRB-", ".", "The", "dynamic", "goal", "problem", "is", "extended", "from", "this", "setting", ",", "not", "all", "other", "cases", ".", "Please", "see", "paragraph", "3", "in", "Section", "1", "-LRB-", "Introduction", "-RRB-", "and", "paragraph", "1", "in", "Section", "3.1", "-LRB-", "Dynamic", "goals", "-RRB-", "for", "more", "descriptions", ".", "2", "-RRB-", "We", "propose", "a", "new", "experience", "replay", "method", ".", "The", "proposed", "algorithm", "can", "be", "combined", "with", "any", "off-policy", "RL", "algorithms", ",", "similar", "to", "HER", ",", "as", "shown", "in", "Figure", "1", ".", "3", "-RRB-", "The", "motivation", "of", "developing", "algorithms", "which", "can", "learn", "from", "unshaped", "reward", "signals", "is", "that", "it", "does", "not", "need", "domain-specific", "knowledge", "and", "is", "applicable", "in", "situations", "where", "we", "do", "not", "know", "what", "admissible", "behaviour", "may", "look", "like", ".", "The", "similar", "motivation", "is", "also", "mentioned", "in", "HER", "-LRB-", "Andrychowicz", "et", "al.", ",", "2017", "-RRB-", ".", "We", "also", "added", "new", "experimental", "results", "about", "dense", "rewards", ".", "The", "results", "show", "DHER", "works", "better", ".", "See", "Figures", "3", "and", "6", ".", "Q1", ":", "The", "algorithm", "appears", "very", "specific", "and", "not", "applicable", "to", "all", "cases", "with", "dynamic", "goals", ".", "...", "A1", ":", "Please", "see", "1", "-RRB-", "and", "3", "-RRB-", "above", ".", "''", "I", "believe", "this", "kind", "of", "motivation", "as", "a", "principled", "approach", "to", "RL", "with", "sparse", "rewards", "and", "no", "domain", "knowledge", "is", "an", "overclaim", ".", "The", "HER", "algorithm", "is", "a", "heuristic", "one", "and", "to", "the", "best", "of", "my", "understanding", "requires", "a", "domain", "specific", "knowledge", "of", "how", "to", "set", "fake", "goals", ",", "which", "is", "natural", "in", "many", "settings", "such", "as", "grid", "worlds", "for", "example", ".", "The", "moving", "goal", "case", "described", "here", "requires", "even", "more", "domain", "specific", "knowledge", "and", "I", "am", "not", "convinced", "is", "truly", "TICKTICK", "model-free", "''", "in", "most", "cases", ".", "To", "the", "best", "of", "my", "understanding", "the", "matching", "phase", "of", "your", "method", "requires", "a", "domain", "specific", "understanding", "of", "goal", "similarity", ".", "Is", "it", "possible", "to", "provide", "a", "dynamic", "goal", "example", "that", "is", "not", "just", "a", "simple", "and", "short", "trajectory", "in", "space", "and", "makes", "sense", "to", "be", "applied", "with", "DHER", "?", "Could", "the", "authors", "for", "example", "explain", "how", "the", "algorithm", "would", "be", "applicable", "in", "a", "case", "of", "an", "Atari", "style", "game", "where", "a", "goal", "would", "teleport", "or", "have", "long", "trajectories", "-LRB-", "non-trivial", "to", "match", "without", "a", "complex", "matching", "heuristic", "-RRB-", ".", "It", "seems", "in", "this", "case", "-LRB-", "a", "-RRB-", "one", "would", "have", "to", "obtain", "precise", "coordinate", "positions", "of", "the", "goal", "-LRB-", "this", "would", "mean", "one", "ca", "n't", "just", "solve", "the", "problem", "based", "on", "pure", "pixels", "and", "must", "rely", "on", "domain", "knowledge", "-RRB-", "and", "-LRB-", "b", "-RRB-", "the", "matching", "algorithm", "itself", "would", "need", "to", "be", "heavily", "crafted", "with", "domain", "specific", "knowledge", ".", "I", "think", "the", "method", "might", "be", "more", "specific", "than", "the", "authors", "claim", "and", "should", "be", "presented", "as", "such", ".", "Thanks", "for", "discussing", "the", "limitation", "of", "DHER", ".", "Similar", "to", "HER", ",", "we", "need", "to", "have", "the", "definition", "of", "goals", "and", "know", "the", "similarity", "metric", "between", "goals", "in", "order", "to", "construct", "TICKTICK", "success", "''", "from", "failed", "experiences", ".", "We", "had", "provided", "how", "to", "use", "and", "define", "goals", "in", "Section", "3.1", "--", "and", "we", "made", "addition", "revisions", "to", "make", "it", "more", "clear", ".", "See", "Sections", "1", "and", "3.1", "for", "the", "discussions", ".", "Because", "we", "have", "the", "same", "multi-goal", "assumption", "as", "HER", ",", "we", "did", "not", "claim", "our", "method", "can", "be", "used", "for", "every", "case", ".", "However", ",", "it", "still", "can", "be", "applied", "to", "many", "domains", "if", "we", "know", "how", "to", "define", "the", "goals", "and", "if", "their", "trajectories", "intersect", ".", "For", "a", "game", ",", "if", "its", "goals", "can", "be", "used", "as", "part", "of", "the", "observation", "and", "do", "not", "affect", "the", "environment", "dynamics", ",", "our", "algorithm", "will", "work", ".", "Regarding", "the", "Atari", "games", ",", "we", "did", "find", "that", "there", "is", "no", "game", "satisfying", "the", "multi-goal", "assumption", ".", "However", ",", "our", "approach", "can", "be", "potentially", "used", "for", "other", "games", "where", "we", "know", "the", "similarity", "of", "goals", ",", "for", "example", ",", "hunting", "for", "food", "in", "a", "Minecraft-like", "grid", "world", "mini-game", ".", "The", "Dy-Snake", "game", "in", "our", "work", "serves", "as", "a", "reference", "for", "which", "types", "of", "games", "our", "approach", "can", "benefit", ".", "The", "algorithm", "is", "very", "natural", "for", "many", "manipulation", "tasks", "because", "we", "can", "access", "-LRB-", "sometimes", "noisy", "-RRB-", "object", "positions", "in", "manipulation", ".", "The", "starting", "point", "of", "this", "work", "is", "actually", "for", "manipulation", "controls", "."], "comment_id": "B1eDAUxO6m"}]